{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HX8hsK5ddBdB"
      },
      "source": [
        "## Predicting RBP Binding with CNN and Transformer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WYJOhs-vc-3U"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kFpO4H-hZzGh"
      },
      "outputs": [],
      "source": [
        "import os \n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.utils.data\n",
        "from torch.nn.modules.pooling import MaxPool2d\n",
        "\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "import pickle\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import random\n",
        "\n",
        "assert(torch.cuda.is_available())\n",
        "device = \"cuda\" "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_3vwX7OaRnI0",
        "outputId": "28b302bd-cea8-44f3-fdc9-3f9e40e50dfa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch\n",
            "  Downloading torch-1.11.0-cp37-cp37m-manylinux1_x86_64.whl (750.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.7/site-packages (from torch) (4.1.1)\n",
            "Installing collected packages: torch\n",
            "Successfully installed torch-1.11.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7FH9HhWRnI0",
        "outputId": "3b5cc7aa-0643-43d0-e812-57ac55043fc7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  datasets.zip\n",
            "  inflating: datasets/ENCODE/encode_eclip_idr.bed.gz  \n",
            "  inflating: datasets/rnbs_HNRNPK/HNRNPK_20.fasta.gz  \n",
            "  inflating: datasets/rnbs_HNRNPK/HNRNPK_5.fasta.gz  \n",
            "  inflating: datasets/rnbs_HNRNPK/HNRNPK_80.fasta.gz  \n",
            "  inflating: datasets/rnbs_HNRNPK/HNRNPK_1300.fasta.gz  \n",
            "  inflating: datasets/rnbs_HNRNPK/HNRNPK_0.fasta.gz  \n",
            "  inflating: datasets/rnbs_HNRNPK/HNRNPK_320.fasta.gz  \n"
          ]
        }
      ],
      "source": [
        "!unzip datasets "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJyn042lmshX"
      },
      "source": [
        "### Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vre2dMwum3gN"
      },
      "source": [
        "##### ENCODE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSFSN7UQnim6"
      },
      "outputs": [],
      "source": [
        "root_dir = '/content/drive/MyDrive/ML4FG/Project' "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "fB6PXnGJOrTZ",
        "outputId": "7f45f015-5e56-4e63-a426-b2c36e9da5b8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>chr</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>strand</th>\n",
              "      <th>fold</th>\n",
              "      <th>nlog10p</th>\n",
              "      <th>cell</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>565739</th>\n",
              "      <td>chr1</td>\n",
              "      <td>15922</td>\n",
              "      <td>15985</td>\n",
              "      <td>-</td>\n",
              "      <td>4.336078</td>\n",
              "      <td>6.512251</td>\n",
              "      <td>K562</td>\n",
              "      <td>AQR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494169</th>\n",
              "      <td>chr1</td>\n",
              "      <td>16230</td>\n",
              "      <td>16331</td>\n",
              "      <td>-</td>\n",
              "      <td>3.344423</td>\n",
              "      <td>6.274660</td>\n",
              "      <td>K562</td>\n",
              "      <td>BUD13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562861</th>\n",
              "      <td>chr1</td>\n",
              "      <td>16250</td>\n",
              "      <td>16319</td>\n",
              "      <td>-</td>\n",
              "      <td>4.045827</td>\n",
              "      <td>7.122894</td>\n",
              "      <td>K562</td>\n",
              "      <td>AQR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558839</th>\n",
              "      <td>chr1</td>\n",
              "      <td>16462</td>\n",
              "      <td>16510</td>\n",
              "      <td>-</td>\n",
              "      <td>5.292347</td>\n",
              "      <td>6.083708</td>\n",
              "      <td>K562</td>\n",
              "      <td>AQR</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278941</th>\n",
              "      <td>chr1</td>\n",
              "      <td>17451</td>\n",
              "      <td>17573</td>\n",
              "      <td>-</td>\n",
              "      <td>3.361457</td>\n",
              "      <td>4.291127</td>\n",
              "      <td>K562</td>\n",
              "      <td>CSTF2T</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438950</th>\n",
              "      <td>chrY</td>\n",
              "      <td>19744401</td>\n",
              "      <td>19744473</td>\n",
              "      <td>-</td>\n",
              "      <td>3.464966</td>\n",
              "      <td>8.168405</td>\n",
              "      <td>HepG2</td>\n",
              "      <td>BCLAF1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191326</th>\n",
              "      <td>chrY</td>\n",
              "      <td>19744489</td>\n",
              "      <td>19744548</td>\n",
              "      <td>-</td>\n",
              "      <td>3.048818</td>\n",
              "      <td>4.066013</td>\n",
              "      <td>HepG2</td>\n",
              "      <td>PPIG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>671368</th>\n",
              "      <td>chrY</td>\n",
              "      <td>20579772</td>\n",
              "      <td>20579892</td>\n",
              "      <td>+</td>\n",
              "      <td>4.660723</td>\n",
              "      <td>5.507490</td>\n",
              "      <td>HepG2</td>\n",
              "      <td>U2AF2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159170</th>\n",
              "      <td>chrY</td>\n",
              "      <td>20580800</td>\n",
              "      <td>20580864</td>\n",
              "      <td>+</td>\n",
              "      <td>4.144179</td>\n",
              "      <td>3.393384</td>\n",
              "      <td>HepG2</td>\n",
              "      <td>QKI</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161385</th>\n",
              "      <td>chrY</td>\n",
              "      <td>20580896</td>\n",
              "      <td>20580961</td>\n",
              "      <td>+</td>\n",
              "      <td>4.380346</td>\n",
              "      <td>4.105902</td>\n",
              "      <td>HepG2</td>\n",
              "      <td>QKI</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>848077 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         chr     start       end strand      fold   nlog10p   cell  target\n",
              "565739  chr1     15922     15985      -  4.336078  6.512251   K562     AQR\n",
              "494169  chr1     16230     16331      -  3.344423  6.274660   K562   BUD13\n",
              "562861  chr1     16250     16319      -  4.045827  7.122894   K562     AQR\n",
              "558839  chr1     16462     16510      -  5.292347  6.083708   K562     AQR\n",
              "278941  chr1     17451     17573      -  3.361457  4.291127   K562  CSTF2T\n",
              "...      ...       ...       ...    ...       ...       ...    ...     ...\n",
              "438950  chrY  19744401  19744473      -  3.464966  8.168405  HepG2  BCLAF1\n",
              "191326  chrY  19744489  19744548      -  3.048818  4.066013  HepG2    PPIG\n",
              "671368  chrY  20579772  20579892      +  4.660723  5.507490  HepG2   U2AF2\n",
              "159170  chrY  20580800  20580864      +  4.144179  3.393384  HepG2     QKI\n",
              "161385  chrY  20580896  20580961      +  4.380346  4.105902  HepG2     QKI\n",
              "\n",
              "[848077 rows x 8 columns]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "encode_dir = Path('datasets/ENCODE')\n",
        "\n",
        "encode_df = pd.read_csv(encode_dir / 'encode_eclip_idr.bed.gz', sep = '\\t')\n",
        "encode_df = encode_df.sort_values(['chr', 'start']).drop_duplicates()\n",
        "encode_df "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jLP-JkVTriB2"
      },
      "outputs": [],
      "source": [
        "target_set = set(encode_df['target'])\n",
        "target_to_idx = dict(zip(target_set, list(range(len(target_set)))))\n",
        "idx_to_target = dict(zip(list(range(len(target_set))), target_set)) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DZCQgjiAm9f9"
      },
      "source": [
        "##### rnbs_HNRNPK"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "Ls_2QE3ZqSYO",
        "outputId": "82f9cb31-ee90-4561-a5ed-0e2ddffb13e2"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sequence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AGGACCTGACCATACGATGA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ACTAAATCTCATGCAGGATA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TTATAGCCCGATTAGGAGGG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ATCGCCAATTGTCTTCAGAT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>CATTATCGCTTTATACAACT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11509893</th>\n",
              "      <td>ACAGTCTGGTTTCGAACGCG</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11509894</th>\n",
              "      <td>ACGAAATCTAGAGTAACTTA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11509895</th>\n",
              "      <td>GCCATGAGATCATACGTCTT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11509896</th>\n",
              "      <td>ACTCCACCGTTAGTATCCTT</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11509897</th>\n",
              "      <td>TTACCGTGAGTTAAGGATAC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11509898 rows × 1 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      Sequence\n",
              "0         AGGACCTGACCATACGATGA\n",
              "1         ACTAAATCTCATGCAGGATA\n",
              "2         TTATAGCCCGATTAGGAGGG\n",
              "3         ATCGCCAATTGTCTTCAGAT\n",
              "4         CATTATCGCTTTATACAACT\n",
              "...                        ...\n",
              "11509893  ACAGTCTGGTTTCGAACGCG\n",
              "11509894  ACGAAATCTAGAGTAACTTA\n",
              "11509895  GCCATGAGATCATACGTCTT\n",
              "11509896  ACTCCACCGTTAGTATCCTT\n",
              "11509897  TTACCGTGAGTTAAGGATAC\n",
              "\n",
              "[11509898 rows x 1 columns]"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rnbs_HNRNPK_dir = Path('datasets/rnbs_HNRNPK')\n",
        "\n",
        "HNRNPK_0 = pd.read_csv(rnbs_HNRNPK_dir / 'HNRNPK_0.fasta.gz', header=None, names = ['Sequence'], sep = '\\t')\n",
        "HNRNPK_0 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpQhBD8_KIbU"
      },
      "source": [
        "##### hg38"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgBJ7n0dk17Y"
      },
      "outputs": [],
      "source": [
        "genome = pickle.load(open('hg38.pkl',\"rb\")) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWvDdbq3ON7X"
      },
      "source": [
        "### Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R2yOCXBptAum"
      },
      "outputs": [],
      "source": [
        "def train_val_test_split(df):\n",
        "  chr_set = set(df['chr'])\n",
        "  valtest_chr_set = set(['chr1', 'chr2', 'chr3'])\n",
        "  train_chr_set = chr_set - valtest_chr_set\n",
        "\n",
        "  train_df = df.loc[df['chr'].isin(train_chr_set)]\n",
        "  val_df = df.loc[df['chr'].isin(['chr2', 'chr3'])]\n",
        "  test_df = df.loc[df['chr'] == 'chr1']\n",
        "\n",
        "  return train_df, val_df, test_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghexGR_ltEtM"
      },
      "outputs": [],
      "source": [
        "encode_train, encode_val, encode_test = train_val_test_split(encode_df) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UGxWdy5N0vEP"
      },
      "outputs": [],
      "source": [
        "def get_longest_seq_len(df):\n",
        "  start_lst = list(df['start'])\n",
        "  end_lst = list(df['end'])\n",
        "  seq_len = [end - start for start, end in zip(start_lst, end_lst)] \n",
        "  max_seq_len = list(set(seq_len))[-1]\n",
        "\n",
        "  return max_seq_len\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JBLhXhOx0O_P"
      },
      "outputs": [],
      "source": [
        "max_seq_len = get_longest_seq_len(encode_df) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pk2_CxYnsLo"
      },
      "outputs": [],
      "source": [
        "def one_hot(seq):\n",
        "  d = {'A': 0, 'C': 1, 'G': 2, 'T': 3}\n",
        "\n",
        "  one_hot_enc = np.zeros((4, len(seq)))\n",
        "\n",
        "  for i in range(len(seq)):\n",
        "    el = seq[i]\n",
        "    if el != 'N':\n",
        "      one_hot_enc[d[el], i] = 1.0\n",
        "\n",
        "  return one_hot_enc \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKvfZtva2j3c"
      },
      "outputs": [],
      "source": [
        "def pad_enc(one_hot_enc, max_seq_len):\n",
        "  padded_enc = np.zeros((4, max_seq_len))\n",
        "  padded_enc[:, 0:one_hot_enc.shape[1]] = one_hot_enc\n",
        "  \n",
        "  return padded_enc \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N-lJd88OOPsy"
      },
      "outputs": [],
      "source": [
        "# convert negative strand to its positive equivalence\n",
        "def strand_normalize(seq):\n",
        "  d = {'A': 'T', 'T': 'A', 'C': 'G', 'G': 'C', 'N':'N'}\n",
        "\n",
        "  modified_seq =''\n",
        "\n",
        "  for el in seq:\n",
        "    modified_seq += d[el]\n",
        "\n",
        "  return modified_seq \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNAFk7kCoAN9"
      },
      "outputs": [],
      "source": [
        "def collect_positive_samples(df):\n",
        "  start_lst = list(df['start'])\n",
        "  end_lst = list(df['end'])\n",
        "  chr_lst = list(df['chr'])\n",
        "  strand_lst = list(df['strand'])\n",
        "\n",
        "  positive_samples = list()\n",
        "\n",
        "  for i in range(df.shape[0]):\n",
        "    current_start, current_end = start_lst[i], end_lst[i]\n",
        "\n",
        "    if i == 0:\n",
        "      positive_samples.append([chr_lst[i], (start_lst[i], end_lst[i]), strand_lst[i]])\n",
        "\n",
        "    else:\n",
        "      previous_start, previous_end = positive_samples[-1][1]\n",
        "\n",
        "      if previous_end < current_start or chr_lst[i-1] != chr_lst[i]:\n",
        "        positive_samples.append([chr_lst[i], (current_start, current_end), strand_lst[i]])\n",
        "\n",
        "      else:\n",
        "        positions = [previous_start, previous_end, current_start, current_end]\n",
        "        positions.sort()\n",
        "\n",
        "        positive_samples[-1] = [chr_lst[i-1], (positions[0], positions[-1]), strand_lst[i-1]]\n",
        "\n",
        "  return positive_samples \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsfUvu8t_uN9"
      },
      "outputs": [],
      "source": [
        "train_positive_samples = collect_positive_samples(encode_train)  \n",
        "val_positive_samples = collect_positive_samples(encode_val)\n",
        "test_positive_samples = collect_positive_samples(encode_test) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ3S1fysRnI3",
        "outputId": "a0ed01dd-91f5-4a72-a742-e8fa0d9a0b0d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['chr10', (135545, 135676), '+'],\n",
              " ['chr10', (135729, 135801), '+'],\n",
              " ['chr10', (135816, 136082), '+'],\n",
              " ['chr10', (136291, 136342), '+'],\n",
              " ['chr10', (136353, 136441), '+'],\n",
              " ['chr10', (136541, 136609), '+'],\n",
              " ['chr10', (136647, 136717), '+'],\n",
              " ['chr10', (153358, 153406), '+'],\n",
              " ['chr10', (160419, 160479), '+'],\n",
              " ['chr10', (164259, 164406), '+'],\n",
              " ['chr10', (165435, 165593), '+'],\n",
              " ['chr10', (174516, 174642), '+'],\n",
              " ['chr10', (179976, 180049), '+'],\n",
              " ['chr10', (180059, 180127), '+'],\n",
              " ['chr10', (184656, 184768), '+'],\n",
              " ['chr10', (199226, 199385), '+'],\n",
              " ['chr10', (211483, 211592), '+'],\n",
              " ['chr10', (221619, 221704), '+'],\n",
              " ['chr10', (254444, 254558), '+'],\n",
              " ['chr10', (282044, 282111), '-'],\n",
              " ['chr10', (321293, 321386), '-'],\n",
              " ['chr10', (321425, 321556), '-'],\n",
              " ['chr10', (322940, 322988), '-'],\n",
              " ['chr10', (323237, 323281), '-'],\n",
              " ['chr10', (323483, 323515), '-'],\n",
              " ['chr10', (323981, 324107), '-'],\n",
              " ['chr10', (326933, 327055), '-'],\n",
              " ['chr10', (336738, 336925), '-'],\n",
              " ['chr10', (337174, 337413), '-'],\n",
              " ['chr10', (337427, 337528), '-'],\n",
              " ['chr10', (337581, 337787), '-'],\n",
              " ['chr10', (337802, 337946), '-'],\n",
              " ['chr10', (344767, 344832), '-'],\n",
              " ['chr10', (345451, 345570), '-'],\n",
              " ['chr10', (347934, 348045), '-'],\n",
              " ['chr10', (366237, 366299), '-'],\n",
              " ['chr10', (378278, 378943), '-'],\n",
              " ['chr10', (379118, 379187), '-'],\n",
              " ['chr10', (390695, 390776), '-'],\n",
              " ['chr10', (423355, 423691), '-'],\n",
              " ['chr10', (477096, 477317), '-'],\n",
              " ['chr10', (478176, 478219), '-'],\n",
              " ['chr10', (486458, 486487), '-'],\n",
              " ['chr10', (516269, 516351), '-'],\n",
              " ['chr10', (516992, 517197), '-'],\n",
              " ['chr10', (517402, 517444), '-'],\n",
              " ['chr10', (518560, 518650), '-'],\n",
              " ['chr10', (532204, 532283), '-'],\n",
              " ['chr10', (541357, 541479), '-'],\n",
              " ['chr10', (541592, 541675), '-'],\n",
              " ['chr10', (542015, 542100), '-'],\n",
              " ['chr10', (548495, 548699), '-'],\n",
              " ['chr10', (551154, 551256), '-'],\n",
              " ['chr10', (555428, 555488), '-'],\n",
              " ['chr10', (555623, 555684), '-'],\n",
              " ['chr10', (555786, 555846), '-'],\n",
              " ['chr10', (555932, 555985), '-'],\n",
              " ['chr10', (556005, 556083), '-'],\n",
              " ['chr10', (556109, 556196), '-'],\n",
              " ['chr10', (556416, 556488), '-'],\n",
              " ['chr10', (556538, 556572), '-'],\n",
              " ['chr10', (556851, 556913), '-'],\n",
              " ['chr10', (557160, 557258), '-'],\n",
              " ['chr10', (557452, 557500), '-'],\n",
              " ['chr10', (558262, 558313), '-'],\n",
              " ['chr10', (558480, 558609), '-'],\n",
              " ['chr10', (558878, 558952), '-'],\n",
              " ['chr10', (559292, 559367), '-'],\n",
              " ['chr10', (559656, 559763), '-'],\n",
              " ['chr10', (559925, 559980), '-'],\n",
              " ['chr10', (563604, 563659), '-'],\n",
              " ['chr10', (571416, 571545), '-'],\n",
              " ['chr10', (585201, 585273), '-'],\n",
              " ['chr10', (590123, 590237), '-'],\n",
              " ['chr10', (590823, 590887), '-'],\n",
              " ['chr10', (593537, 593594), '-'],\n",
              " ['chr10', (597310, 597397), '-'],\n",
              " ['chr10', (598194, 598244), '-'],\n",
              " ['chr10', (598271, 598323), '-'],\n",
              " ['chr10', (598507, 598604), '-'],\n",
              " ['chr10', (600480, 600622), '-'],\n",
              " ['chr10', (603776, 604027), '-'],\n",
              " ['chr10', (606055, 606087), '-'],\n",
              " ['chr10', (606190, 606265), '-'],\n",
              " ['chr10', (606910, 606963), '-'],\n",
              " ['chr10', (607916, 607955), '-'],\n",
              " ['chr10', (607971, 608143), '-'],\n",
              " ['chr10', (608286, 608352), '-'],\n",
              " ['chr10', (614441, 614476), '-'],\n",
              " ['chr10', (615036, 615084), '-'],\n",
              " ['chr10', (615870, 615932), '-'],\n",
              " ['chr10', (616526, 616599), '-'],\n",
              " ['chr10', (617065, 617159), '-'],\n",
              " ['chr10', (617448, 617682), '-'],\n",
              " ['chr10', (619354, 619459), '-'],\n",
              " ['chr10', (621267, 621319), '-'],\n",
              " ['chr10', (621477, 621552), '-'],\n",
              " ['chr10', (622163, 622285), '-'],\n",
              " ['chr10', (622587, 622627), '-'],\n",
              " ['chr10', (623082, 623136), '-'],\n",
              " ['chr10', (623194, 623300), '-'],\n",
              " ['chr10', (623335, 623395), '-'],\n",
              " ['chr10', (623404, 623765), '-'],\n",
              " ['chr10', (624009, 624085), '-'],\n",
              " ['chr10', (624091, 624158), '-'],\n",
              " ['chr10', (624185, 624249), '-'],\n",
              " ['chr10', (624299, 624363), '-'],\n",
              " ['chr10', (624547, 624579), '-'],\n",
              " ['chr10', (624949, 624977), '-'],\n",
              " ['chr10', (626342, 626497), '-'],\n",
              " ['chr10', (626987, 627063), '-'],\n",
              " ['chr10', (627195, 627256), '-'],\n",
              " ['chr10', (627860, 627919), '-'],\n",
              " ['chr10', (628558, 628649), '-'],\n",
              " ['chr10', (636469, 636562), '-'],\n",
              " ['chr10', (636887, 636960), '-'],\n",
              " ['chr10', (637252, 637322), '-'],\n",
              " ['chr10', (637952, 637999), '-'],\n",
              " ['chr10', (639178, 639252), '-'],\n",
              " ['chr10', (639282, 639327), '-'],\n",
              " ['chr10', (639785, 639830), '-'],\n",
              " ['chr10', (639931, 640046), '-'],\n",
              " ['chr10', (640211, 640267), '-'],\n",
              " ['chr10', (640542, 640727), '-'],\n",
              " ['chr10', (642639, 642732), '-'],\n",
              " ['chr10', (643631, 643803), '-'],\n",
              " ['chr10', (644562, 644627), '-'],\n",
              " ['chr10', (644693, 644864), '-'],\n",
              " ['chr10', (646148, 646220), '-'],\n",
              " ['chr10', (646238, 646406), '-'],\n",
              " ['chr10', (646505, 646654), '-'],\n",
              " ['chr10', (646865, 646922), '-'],\n",
              " ['chr10', (646992, 647058), '-'],\n",
              " ['chr10', (647138, 647155), '-'],\n",
              " ['chr10', (647218, 647260), '-'],\n",
              " ['chr10', (647432, 647468), '-'],\n",
              " ['chr10', (647470, 647525), '-'],\n",
              " ['chr10', (647669, 647717), '-'],\n",
              " ['chr10', (647943, 647987), '-'],\n",
              " ['chr10', (648092, 648137), '-'],\n",
              " ['chr10', (648188, 648245), '-'],\n",
              " ['chr10', (648367, 648406), '-'],\n",
              " ['chr10', (648412, 648488), '-'],\n",
              " ['chr10', (648533, 648606), '-'],\n",
              " ['chr10', (648685, 648713), '-'],\n",
              " ['chr10', (648955, 649022), '-'],\n",
              " ['chr10', (649128, 649181), '-'],\n",
              " ['chr10', (649421, 649485), '-'],\n",
              " ['chr10', (650183, 650235), '-'],\n",
              " ['chr10', (650681, 650744), '-'],\n",
              " ['chr10', (650965, 651087), '-'],\n",
              " ['chr10', (651232, 651285), '-'],\n",
              " ['chr10', (651796, 651846), '-'],\n",
              " ['chr10', (652556, 652610), '-'],\n",
              " ['chr10', (652979, 653053), '-'],\n",
              " ['chr10', (653691, 653806), '-'],\n",
              " ['chr10', (658835, 659181), '+'],\n",
              " ['chr10', (659246, 659327), '+'],\n",
              " ['chr10', (659332, 659442), '+'],\n",
              " ['chr10', (665606, 665763), '-'],\n",
              " ['chr10', (666426, 666471), '-'],\n",
              " ['chr10', (667283, 667399), '-'],\n",
              " ['chr10', (667416, 668183), '+'],\n",
              " ['chr10', (668191, 668305), '+'],\n",
              " ['chr10', (668309, 668679), '+'],\n",
              " ['chr10', (668894, 668945), '-'],\n",
              " ['chr10', (670203, 670280), '-'],\n",
              " ['chr10', (676069, 676152), '-'],\n",
              " ['chr10', (677920, 677997), '-'],\n",
              " ['chr10', (678183, 678193), '-'],\n",
              " ['chr10', (678264, 678362), '-'],\n",
              " ['chr10', (678395, 678643), '-'],\n",
              " ['chr10', (678749, 678838), '-'],\n",
              " ['chr10', (679185, 679222), '-'],\n",
              " ['chr10', (679253, 679315), '-'],\n",
              " ['chr10', (679346, 679404), '-'],\n",
              " ['chr10', (679429, 679505), '-'],\n",
              " ['chr10', (679602, 679902), '-'],\n",
              " ['chr10', (679923, 679996), '-'],\n",
              " ['chr10', (680009, 680374), '-'],\n",
              " ['chr10', (681234, 681349), '-'],\n",
              " ['chr10', (681410, 681457), '-'],\n",
              " ['chr10', (681477, 681524), '-'],\n",
              " ['chr10', (681528, 681575), '-'],\n",
              " ['chr10', (682197, 682293), '-'],\n",
              " ['chr10', (686290, 686479), '-'],\n",
              " ['chr10', (688138, 688184), '-'],\n",
              " ['chr10', (688809, 688959), '-'],\n",
              " ['chr10', (689009, 689195), '-'],\n",
              " ['chr10', (689220, 689283), '-'],\n",
              " ['chr10', (689462, 689614), '-'],\n",
              " ['chr10', (809426, 809508), '-'],\n",
              " ['chr10', (809712, 809777), '-'],\n",
              " ['chr10', (809806, 809897), '-'],\n",
              " ['chr10', (811120, 811179), '-'],\n",
              " ['chr10', (811227, 811262), '-'],\n",
              " ['chr10', (811286, 811440), '-'],\n",
              " ['chr10', (811917, 811970), '-'],\n",
              " ['chr10', (812156, 812262), '-'],\n",
              " ['chr10', (812379, 812436), '-'],\n",
              " ['chr10', (814451, 814626), '-'],\n",
              " ['chr10', (814739, 814810), '-'],\n",
              " ['chr10', (815052, 815138), '-'],\n",
              " ['chr10', (817581, 817624), '-'],\n",
              " ['chr10', (817649, 817734), '-'],\n",
              " ['chr10', (817846, 817980), '-'],\n",
              " ['chr10', (820748, 821041), '-'],\n",
              " ['chr10', (822157, 822258), '-'],\n",
              " ['chr10', (822327, 822511), '-'],\n",
              " ['chr10', (825012, 825066), '-'],\n",
              " ['chr10', (825169, 825232), '-'],\n",
              " ['chr10', (825359, 825415), '-'],\n",
              " ['chr10', (825685, 825760), '-'],\n",
              " ['chr10', (826339, 826441), '-'],\n",
              " ['chr10', (827567, 827632), '-'],\n",
              " ['chr10', (827648, 827687), '-'],\n",
              " ['chr10', (828084, 828144), '-'],\n",
              " ['chr10', (828498, 828552), '-'],\n",
              " ['chr10', (829404, 829477), '-'],\n",
              " ['chr10', (829676, 829703), '-'],\n",
              " ['chr10', (829950, 830019), '-'],\n",
              " ['chr10', (830068, 830115), '-'],\n",
              " ['chr10', (830865, 830981), '-'],\n",
              " ['chr10', (831091, 831164), '-'],\n",
              " ['chr10', (832056, 832125), '-'],\n",
              " ['chr10', (836067, 836129), '-'],\n",
              " ['chr10', (836401, 836449), '-'],\n",
              " ['chr10', (836455, 836520), '-'],\n",
              " ['chr10', (837139, 837250), '-'],\n",
              " ['chr10', (837548, 837614), '-'],\n",
              " ['chr10', (837626, 837753), '-'],\n",
              " ['chr10', (837828, 837885), '-'],\n",
              " ['chr10', (838093, 838141), '-'],\n",
              " ['chr10', (838229, 838270), '-'],\n",
              " ['chr10', (838554, 838590), '-'],\n",
              " ['chr10', (839810, 839962), '-'],\n",
              " ['chr10', (842812, 842888), '-'],\n",
              " ['chr10', (842960, 843108), '-'],\n",
              " ['chr10', (843821, 843872), '-'],\n",
              " ['chr10', (844523, 844602), '-'],\n",
              " ['chr10', (844855, 845099), '-'],\n",
              " ['chr10', (846476, 846601), '-'],\n",
              " ['chr10', (846708, 846897), '-'],\n",
              " ['chr10', (847047, 847114), '-'],\n",
              " ['chr10', (847175, 847245), '-'],\n",
              " ['chr10', (847373, 847425), '-'],\n",
              " ['chr10', (848158, 848252), '-'],\n",
              " ['chr10', (849079, 849166), '-'],\n",
              " ['chr10', (852329, 852465), '-'],\n",
              " ['chr10', (853458, 853505), '-'],\n",
              " ['chr10', (857031, 857151), '-'],\n",
              " ['chr10', (857162, 857260), '-'],\n",
              " ['chr10', (858486, 858563), '-'],\n",
              " ['chr10', (863739, 863775), '-'],\n",
              " ['chr10', (863813, 863926), '-'],\n",
              " ['chr10', (863968, 864232), '-'],\n",
              " ['chr10', (865827, 865922), '-'],\n",
              " ['chr10', (871379, 871437), '-'],\n",
              " ['chr10', (871467, 871516), '-'],\n",
              " ['chr10', (872730, 872790), '-'],\n",
              " ['chr10', (872934, 872990), '-'],\n",
              " ['chr10', (873289, 873354), '-'],\n",
              " ['chr10', (885649, 885858), '-'],\n",
              " ['chr10', (889313, 889424), '-'],\n",
              " ['chr10', (899276, 899333), '-'],\n",
              " ['chr10', (899451, 899570), '-'],\n",
              " ['chr10', (899624, 899803), '-'],\n",
              " ['chr10', (912814, 912864), '-'],\n",
              " ['chr10', (913680, 913749), '-'],\n",
              " ['chr10', (915280, 915293), '-'],\n",
              " ['chr10', (915996, 916067), '-'],\n",
              " ['chr10', (921974, 922038), '-'],\n",
              " ['chr10', (923069, 923076), '-'],\n",
              " ['chr10', (924029, 924068), '-'],\n",
              " ['chr10', (924954, 925008), '-'],\n",
              " ['chr10', (926803, 926857), '-'],\n",
              " ['chr10', (927197, 927326), '-'],\n",
              " ['chr10', (928426, 928484), '-'],\n",
              " ['chr10', (930071, 930123), '-'],\n",
              " ['chr10', (930125, 930177), '-'],\n",
              " ['chr10', (930541, 930592), '-'],\n",
              " ['chr10', (930606, 930697), '-'],\n",
              " ['chr10', (930715, 930872), '-'],\n",
              " ['chr10', (930912, 931189), '-'],\n",
              " ['chr10', (931193, 931305), '-'],\n",
              " ['chr10', (931362, 931691), '-'],\n",
              " ['chr10', (988436, 988493), '+'],\n",
              " ['chr10', (988502, 988629), '+'],\n",
              " ['chr10', (992488, 992527), '+'],\n",
              " ['chr10', (996113, 996291), '+'],\n",
              " ['chr10', (996568, 996649), '+'],\n",
              " ['chr10', (996660, 996712), '+'],\n",
              " ['chr10', (997183, 997309), '+'],\n",
              " ['chr10', (997359, 997406), '+'],\n",
              " ['chr10', (997464, 997505), '+'],\n",
              " ['chr10', (997556, 997638), '+'],\n",
              " ['chr10', (1000672, 1001033), '+'],\n",
              " ['chr10', (1001259, 1001339), '+'],\n",
              " ['chr10', (1001364, 1001470), '+'],\n",
              " ['chr10', (1003013, 1003176), '+'],\n",
              " ['chr10', (1003602, 1003661), '+'],\n",
              " ['chr10', (1003665, 1003833), '+'],\n",
              " ['chr10', (1003885, 1003939), '+'],\n",
              " ['chr10', (1005480, 1005540), '+'],\n",
              " ['chr10', (1005816, 1005926), '+'],\n",
              " ['chr10', (1005982, 1006032), '+'],\n",
              " ['chr10', (1006961, 1007015), '+'],\n",
              " ['chr10', (1007016, 1007061), '+'],\n",
              " ['chr10', (1007064, 1007174), '+'],\n",
              " ['chr10', (1007445, 1007509), '+'],\n",
              " ['chr10', (1008812, 1008898), '+'],\n",
              " ['chr10', (1008945, 1009079), '+'],\n",
              " ['chr10', (1009474, 1009634), '+'],\n",
              " ['chr10', (1010252, 1010347), '+'],\n",
              " ['chr10', (1010419, 1010521), '+'],\n",
              " ['chr10', (1010530, 1010609), '+'],\n",
              " ['chr10', (1010630, 1010675), '+'],\n",
              " ['chr10', (1010776, 1010842), '+'],\n",
              " ['chr10', (1010869, 1011140), '+'],\n",
              " ['chr10', (1011161, 1011225), '+'],\n",
              " ['chr10', (1011395, 1011436), '+'],\n",
              " ['chr10', (1011444, 1011496), '+'],\n",
              " ['chr10', (1012460, 1012707), '+'],\n",
              " ['chr10', (1014244, 1014355), '+'],\n",
              " ['chr10', (1015478, 1015577), '+'],\n",
              " ['chr10', (1015746, 1015859), '+'],\n",
              " ['chr10', (1015880, 1015952), '+'],\n",
              " ['chr10', (1017070, 1017441), '+'],\n",
              " ['chr10', (1017470, 1017579), '+'],\n",
              " ['chr10', (1019706, 1019796), '+'],\n",
              " ['chr10', (1040065, 1040232), '-'],\n",
              " ['chr10', (1040291, 1040567), '-'],\n",
              " ['chr10', (1040650, 1040707), '-'],\n",
              " ['chr10', (1040779, 1040875), '-'],\n",
              " ['chr10', (1041309, 1041480), '-'],\n",
              " ['chr10', (1042733, 1042789), '-'],\n",
              " ['chr10', (1043259, 1043301), '-'],\n",
              " ['chr10', (1043395, 1043404), '-'],\n",
              " ['chr10', (1043986, 1044094), '-'],\n",
              " ['chr10', (1044136, 1044203), '-'],\n",
              " ['chr10', (1045792, 1045951), '-'],\n",
              " ['chr10', (1046363, 1046501), '-'],\n",
              " ['chr10', (1047604, 1047750), '-'],\n",
              " ['chr10', (1048572, 1048897), '-'],\n",
              " ['chr10', (1050152, 1050245), '+'],\n",
              " ['chr10', (1056878, 1056990), '+'],\n",
              " ['chr10', (1057056, 1057160), '+'],\n",
              " ['chr10', (1057322, 1057408), '+'],\n",
              " ['chr10', (1062023, 1062121), '+'],\n",
              " ['chr10', (1063672, 1063738), '+'],\n",
              " ['chr10', (1064337, 1064413), '+'],\n",
              " ['chr10', (1065184, 1065253), '+'],\n",
              " ['chr10', (1065461, 1065535), '+'],\n",
              " ['chr10', (1065629, 1065705), '+'],\n",
              " ['chr10', (1077915, 1077984), '+'],\n",
              " ['chr10', (1078003, 1078078), '+'],\n",
              " ['chr10', (1080345, 1080457), '+'],\n",
              " ['chr10', (1081774, 1081851), '+'],\n",
              " ['chr10', (1082905, 1082954), '+'],\n",
              " ['chr10', (1084450, 1084543), '+'],\n",
              " ['chr10', (1086285, 1086349), '+'],\n",
              " ['chr10', (1086357, 1086525), '+'],\n",
              " ['chr10', (1086570, 1086661), '+'],\n",
              " ['chr10', (1087617, 1087657), '+'],\n",
              " ['chr10', (1088464, 1088523), '+'],\n",
              " ['chr10', (1089028, 1089101), '+'],\n",
              " ['chr10', (1089122, 1089257), '+'],\n",
              " ['chr10', (1093181, 1093412), '+'],\n",
              " ['chr10', (1093442, 1093522), '+'],\n",
              " ['chr10', (1095743, 1095837), '+'],\n",
              " ['chr10', (1096121, 1096183), '+'],\n",
              " ['chr10', (1096237, 1096346), '+'],\n",
              " ['chr10', (1096720, 1096788), '+'],\n",
              " ['chr10', (1098019, 1098066), '+'],\n",
              " ['chr10', (1100263, 1100367), '+'],\n",
              " ['chr10', (1103072, 1103133), '+'],\n",
              " ['chr10', (1103189, 1103332), '+'],\n",
              " ['chr10', (1103574, 1103625), '+'],\n",
              " ['chr10', (1107572, 1107644), '+'],\n",
              " ['chr10', (1107826, 1108038), '+'],\n",
              " ['chr10', (1108903, 1108996), '+'],\n",
              " ['chr10', (1109015, 1109132), '+'],\n",
              " ['chr10', (1109152, 1109217), '+'],\n",
              " ['chr10', (1110157, 1110244), '+'],\n",
              " ['chr10', (1110571, 1110659), '+'],\n",
              " ['chr10', (1110851, 1110903), '+'],\n",
              " ['chr10', (1116128, 1116330), '+'],\n",
              " ['chr10', (1120842, 1121015), '+'],\n",
              " ['chr10', (1123664, 1123841), '+'],\n",
              " ['chr10', (1124685, 1124768), '+'],\n",
              " ['chr10', (1131688, 1131842), '+'],\n",
              " ['chr10', (1164129, 1164223), '+'],\n",
              " ['chr10', (1164443, 1164536), '+'],\n",
              " ['chr10', (1220236, 1220281), '-'],\n",
              " ['chr10', (3067548, 3067635), '+'],\n",
              " ['chr10', (3067826, 3068003), '+'],\n",
              " ['chr10', (3099284, 3099353), '+'],\n",
              " ['chr10', (3099458, 3099550), '+'],\n",
              " ['chr10', (3099720, 3100148), '+'],\n",
              " ['chr10', (3101361, 3101413), '+'],\n",
              " ['chr10', (3101509, 3101552), '+'],\n",
              " ['chr10', (3103097, 3103276), '+'],\n",
              " ['chr10', (3103929, 3103938), '+'],\n",
              " ['chr10', (3103944, 3103987), '+'],\n",
              " ['chr10', (3105067, 3105212), '+'],\n",
              " ['chr10', (3105213, 3105283), '+'],\n",
              " ['chr10', (3105319, 3105473), '+'],\n",
              " ['chr10', (3105500, 3105543), '+'],\n",
              " ['chr10', (3106981, 3107182), '+'],\n",
              " ['chr10', (3107242, 3107300), '+'],\n",
              " ['chr10', (3107334, 3107394), '+'],\n",
              " ['chr10', (3108654, 3108747), '+'],\n",
              " ['chr10', (3108762, 3108794), '+'],\n",
              " ['chr10', (3109352, 3109455), '+'],\n",
              " ['chr10', (3109480, 3109523), '+'],\n",
              " ['chr10', (3109835, 3109985), '+'],\n",
              " ['chr10', (3110679, 3110775), '+'],\n",
              " ['chr10', (3110843, 3111134), '+'],\n",
              " ['chr10', (3111138, 3111423), '+'],\n",
              " ['chr10', (3112153, 3112205), '+'],\n",
              " ['chr10', (3112223, 3112287), '+'],\n",
              " ['chr10', (3112295, 3112323), '+'],\n",
              " ['chr10', (3113118, 3113188), '+'],\n",
              " ['chr10', (3113371, 3113427), '+'],\n",
              " ['chr10', (3113744, 3113850), '+'],\n",
              " ['chr10', (3115485, 3115641), '+'],\n",
              " ['chr10', (3116471, 3116526), '+'],\n",
              " ['chr10', (3116792, 3116885), '+'],\n",
              " ['chr10', (3119915, 3119933), '+'],\n",
              " ['chr10', (3119938, 3119954), '+'],\n",
              " ['chr10', (3120044, 3120113), '+'],\n",
              " ['chr10', (3120376, 3120438), '+'],\n",
              " ['chr10', (3120854, 3120907), '+'],\n",
              " ['chr10', (3121830, 3121925), '+'],\n",
              " ['chr10', (3122134, 3122215), '+'],\n",
              " ['chr10', (3122283, 3122336), '+'],\n",
              " ['chr10', (3122559, 3122628), '+'],\n",
              " ['chr10', (3122791, 3122908), '+'],\n",
              " ['chr10', (3123470, 3123573), '+'],\n",
              " ['chr10', (3123686, 3123775), '+'],\n",
              " ['chr10', (3124039, 3124075), '+'],\n",
              " ['chr10', (3124306, 3124361), '+'],\n",
              " ['chr10', (3124439, 3124624), '+'],\n",
              " ['chr10', (3124674, 3125218), '+'],\n",
              " ['chr10', (3125771, 3125801), '+'],\n",
              " ['chr10', (3128785, 3128843), '+'],\n",
              " ['chr10', (3129062, 3129124), '+'],\n",
              " ['chr10', (3129158, 3129233), '+'],\n",
              " ['chr10', (3129921, 3129985), '+'],\n",
              " ['chr10', (3132378, 3132395), '+'],\n",
              " ['chr10', (3133339, 3133432), '+'],\n",
              " ['chr10', (3134224, 3134310), '+'],\n",
              " ['chr10', (3134535, 3134627), '+'],\n",
              " ['chr10', (3135735, 3135785), '+'],\n",
              " ['chr10', (3136467, 3136500), '+'],\n",
              " ['chr10', (3136558, 3136777), '+'],\n",
              " ['chr10', (3137833, 3137976), '-'],\n",
              " ['chr10', (3138635, 3138700), '-'],\n",
              " ['chr10', (3138785, 3138839), '-'],\n",
              " ['chr10', (3140778, 3140862), '-'],\n",
              " ['chr10', (3143828, 3143896), '-'],\n",
              " ['chr10', (3144139, 3144229), '-'],\n",
              " ['chr10', (3144235, 3144348), '-'],\n",
              " ['chr10', (3145538, 3145598), '-'],\n",
              " ['chr10', (3147211, 3147264), '-'],\n",
              " ['chr10', (3147527, 3147572), '-'],\n",
              " ['chr10', (3147696, 3147749), '-'],\n",
              " ['chr10', (3147837, 3147985), '-'],\n",
              " ['chr10', (3148015, 3148054), '-'],\n",
              " ['chr10', (3148190, 3148254), '-'],\n",
              " ['chr10', (3149528, 3149616), '-'],\n",
              " ['chr10', (3151244, 3151341), '-'],\n",
              " ['chr10', (3156257, 3156322), '-'],\n",
              " ['chr10', (3156685, 3156732), '-'],\n",
              " ['chr10', (3157447, 3157516), '-'],\n",
              " ['chr10', (3157938, 3158018), '-'],\n",
              " ['chr10', (3163752, 3163862), '-'],\n",
              " ['chr10', (3165377, 3165444), '-'],\n",
              " ['chr10', (3166852, 3166935), '-'],\n",
              " ['chr10', (3166972, 3167041), '-'],\n",
              " ['chr10', (3170103, 3170209), '-'],\n",
              " ['chr10', (3172714, 3172777), '-'],\n",
              " ['chr10', (3776448, 3776547), '-'],\n",
              " ['chr10', (3776571, 3776624), '-'],\n",
              " ['chr10', (3777773, 3777834), '-'],\n",
              " ['chr10', (3777960, 3777999), '-'],\n",
              " ['chr10', (3778570, 3778630), '-'],\n",
              " ['chr10', (3778851, 3779049), '-'],\n",
              " ['chr10', (3779068, 3779149), '-'],\n",
              " ['chr10', (3779161, 3779261), '-'],\n",
              " ['chr10', (3779291, 3779680), '-'],\n",
              " ['chr10', (3779984, 3780119), '-'],\n",
              " ['chr10', (3780166, 3780301), '-'],\n",
              " ['chr10', (3781537, 3781676), '-'],\n",
              " ['chr10', (3781711, 3781959), '-'],\n",
              " ['chr10', (3781972, 3782032), '-'],\n",
              " ['chr10', (3782162, 3782376), '-'],\n",
              " ['chr10', (3784778, 3784913), '-'],\n",
              " ['chr10', (3785035, 3785106), '-'],\n",
              " ['chr10', (3785118, 3785218), '-'],\n",
              " ['chr10', (4827201, 4827417), '+'],\n",
              " ['chr10', (4833349, 4833446), '+'],\n",
              " ['chr10', (4963416, 4963529), '+'],\n",
              " ['chr10', (4963616, 4963787), '+'],\n",
              " ['chr10', (4965702, 4965752), '+'],\n",
              " ['chr10', (4965840, 4965951), '+'],\n",
              " ['chr10', (4966125, 4966179), '+'],\n",
              " ['chr10', (4966544, 4966659), '+'],\n",
              " ['chr10', (4966881, 4966974), '+'],\n",
              " ['chr10', (4967075, 4967169), '+'],\n",
              " ['chr10', (4968346, 4968395), '+'],\n",
              " ['chr10', (4968673, 4968921), '+'],\n",
              " ['chr10', (4971813, 4971877), '+'],\n",
              " ['chr10', (4972510, 4972577), '+'],\n",
              " ['chr10', (4972654, 4972725), '+'],\n",
              " ['chr10', (4974447, 4974520), '+'],\n",
              " ['chr10', (4974559, 4974605), '+'],\n",
              " ['chr10', (4974636, 4974799), '+'],\n",
              " ['chr10', (4974866, 4975006), '+'],\n",
              " ['chr10', (4977738, 4977912), '+'],\n",
              " ['chr10', (4979326, 4979410), '+'],\n",
              " ['chr10', (4980885, 4980946), '+'],\n",
              " ['chr10', (4981833, 4981875), '+'],\n",
              " ['chr10', (4982120, 4982278), '+'],\n",
              " ['chr10', (4982309, 4982377), '+'],\n",
              " ['chr10', (4983034, 4983206), '+'],\n",
              " ['chr10', (4985314, 4985460), '+'],\n",
              " ['chr10', (4986071, 4986156), '+'],\n",
              " ['chr10', (4986624, 4986707), '+'],\n",
              " ['chr10', (4989839, 4989998), '-'],\n",
              " ['chr10', (4992698, 4992799), '+'],\n",
              " ['chr10', (4998643, 4998802), '-'],\n",
              " ['chr10', (4999197, 4999232), '-'],\n",
              " ['chr10', (4999365, 4999418), '-'],\n",
              " ['chr10', (5000395, 5000516), '-'],\n",
              " ['chr10', (5001538, 5001627), '-'],\n",
              " ['chr10', (5001644, 5001679), '-'],\n",
              " ['chr10', (5001683, 5001695), '-'],\n",
              " ['chr10', (5003500, 5003565), '-'],\n",
              " ['chr10', (5003582, 5003675), '-'],\n",
              " ['chr10', (5096428, 5096489), '+'],\n",
              " ['chr10', (5096503, 5096686), '+'],\n",
              " ['chr10', (5097497, 5097609), '+'],\n",
              " ['chr10', (5098269, 5098357), '+'],\n",
              " ['chr10', (5098757, 5098840), '+'],\n",
              " ['chr10', (5098859, 5098913), '+'],\n",
              " ['chr10', (5099324, 5099425), '+'],\n",
              " ['chr10', (5099440, 5099501), '+'],\n",
              " ['chr10', (5102073, 5102149), '+'],\n",
              " ['chr10', (5102242, 5102345), '+'],\n",
              " ['chr10', (5102484, 5102512), '+'],\n",
              " ['chr10', (5104922, 5104970), '+'],\n",
              " ['chr10', (5105244, 5105286), '+'],\n",
              " ['chr10', (5105344, 5105404), '+'],\n",
              " ['chr10', (5105594, 5105681), '+'],\n",
              " ['chr10', (5105721, 5105775), '+'],\n",
              " ['chr10', (5106181, 5106258), '+'],\n",
              " ['chr10', (5107460, 5107489), '+'],\n",
              " ['chr10', (5107492, 5107585), '+'],\n",
              " ['chr10', (5107588, 5107659), '+'],\n",
              " ['chr10', (5412587, 5412677), '+'],\n",
              " ['chr10', (5413037, 5413105), '+'],\n",
              " ['chr10', (5417679, 5417751), '+'],\n",
              " ['chr10', (5426763, 5426837), '+'],\n",
              " ['chr10', (5433943, 5433996), '+'],\n",
              " ['chr10', (5434250, 5434353), '+'],\n",
              " ['chr10', (5444547, 5444680), '+'],\n",
              " ['chr10', (5444930, 5445031), '+'],\n",
              " ['chr10', (5445048, 5445155), '+'],\n",
              " ['chr10', (5446617, 5446815), '+'],\n",
              " ['chr10', (5446821, 5446843), '+'],\n",
              " ['chr10', (5446969, 5447044), '+'],\n",
              " ['chr10', (5447092, 5447154), '+'],\n",
              " ['chr10', (5447170, 5447217), '+'],\n",
              " ['chr10', (5447519, 5447625), '+'],\n",
              " ['chr10', (5447638, 5447676), '+'],\n",
              " ['chr10', (5448382, 5448524), '+'],\n",
              " ['chr10', (5451787, 5451860), '+'],\n",
              " ['chr10', (5451901, 5451928), '+'],\n",
              " ['chr10', (5451951, 5451979), '+'],\n",
              " ['chr10', (5452196, 5452257), '+'],\n",
              " ['chr10', (5452323, 5452420), '+'],\n",
              " ['chr10', (5452524, 5452577), '+'],\n",
              " ['chr10', (5452916, 5452966), '+'],\n",
              " ['chr10', (5453201, 5453397), '+'],\n",
              " ['chr10', (5453442, 5453651), '+'],\n",
              " ['chr10', (5454252, 5454295), '+'],\n",
              " ['chr10', (5454375, 5454480), '+'],\n",
              " ['chr10', (5454521, 5454673), '+'],\n",
              " ['chr10', (5454911, 5454931), '+'],\n",
              " ['chr10', (5454987, 5455175), '+'],\n",
              " ['chr10', (5456104, 5456194), '+'],\n",
              " ['chr10', (5456273, 5456336), '+'],\n",
              " ['chr10', (5456592, 5456657), '+'],\n",
              " ['chr10', (5456699, 5456795), '+'],\n",
              " ['chr10', (5456866, 5456905), '+'],\n",
              " ['chr10', (5456962, 5456991), '+'],\n",
              " ['chr10', (5456994, 5457106), '+'],\n",
              " ['chr10', (5457150, 5457194), '+'],\n",
              " ['chr10', (5457256, 5457344), '+'],\n",
              " ['chr10', (5457608, 5457727), '+'],\n",
              " ['chr10', (5457761, 5457819), '+'],\n",
              " ['chr10', (5458276, 5458322), '+'],\n",
              " ['chr10', (5458327, 5458432), '+'],\n",
              " ['chr10', (5638972, 5639033), '-'],\n",
              " ['chr10', (5659606, 5659677), '-'],\n",
              " ['chr10', (5661132, 5661247), '-'],\n",
              " ['chr10', (5663153, 5663238), '-'],\n",
              " ['chr10', (5684851, 5685268), '+'],\n",
              " ['chr10', (5685294, 5685491), '+'],\n",
              " ['chr10', (5685502, 5685588), '+'],\n",
              " ['chr10', (5685600, 5685696), '+'],\n",
              " ['chr10', (5686105, 5686149), '+'],\n",
              " ['chr10', (5688584, 5688658), '+'],\n",
              " ['chr10', (5688724, 5688787), '+'],\n",
              " ['chr10', (5689620, 5689751), '+'],\n",
              " ['chr10', (5689784, 5689852), '+'],\n",
              " ['chr10', (5690176, 5690236), '+'],\n",
              " ['chr10', (5692433, 5692590), '+'],\n",
              " ['chr10', (5692680, 5692755), '+'],\n",
              " ['chr10', (5692954, 5693030), '+'],\n",
              " ['chr10', (5693076, 5693140), '+'],\n",
              " ['chr10', (5693157, 5693272), '+'],\n",
              " ['chr10', (5694998, 5695067), '+'],\n",
              " ['chr10', (5695765, 5695829), '+'],\n",
              " ['chr10', (5695882, 5696024), '+'],\n",
              " ['chr10', (5696045, 5696122), '+'],\n",
              " ['chr10', (5696147, 5696221), '+'],\n",
              " ['chr10', (5696369, 5696423), '+'],\n",
              " ['chr10', (5696536, 5696623), '+'],\n",
              " ['chr10', (5697024, 5697117), '+'],\n",
              " ['chr10', (5697501, 5697615), '+'],\n",
              " ['chr10', (5699328, 5699440), '+'],\n",
              " ['chr10', (5700027, 5700155), '+'],\n",
              " ['chr10', (5700495, 5700524), '+'],\n",
              " ['chr10', (5700756, 5700864), '+'],\n",
              " ['chr10', (5701008, 5701054), '+'],\n",
              " ['chr10', (5701061, 5701144), '+'],\n",
              " ['chr10', (5701169, 5701215), '+'],\n",
              " ['chr10', (5701255, 5701325), '+'],\n",
              " ['chr10', (5701333, 5701374), '+'],\n",
              " ['chr10', (5701495, 5701567), '+'],\n",
              " ['chr10', (5701753, 5701785), '+'],\n",
              " ['chr10', (5701854, 5701915), '+'],\n",
              " ['chr10', (5703825, 5703923), '+'],\n",
              " ['chr10', (5704479, 5704536), '+'],\n",
              " ['chr10', (5704621, 5704726), '+'],\n",
              " ['chr10', (5705207, 5705422), '+'],\n",
              " ['chr10', (5707411, 5707439), '+'],\n",
              " ['chr10', (5707530, 5707637), '+'],\n",
              " ['chr10', (5707654, 5707940), '+'],\n",
              " ['chr10', (5708191, 5708230), '+'],\n",
              " ['chr10', (5708567, 5708620), '+'],\n",
              " ['chr10', (5708652, 5708747), '+'],\n",
              " ['chr10', (5709022, 5709048), '+'],\n",
              " ['chr10', (5709513, 5709578), '+'],\n",
              " ['chr10', (5712802, 5712851), '+'],\n",
              " ['chr10', (5714257, 5714350), '+'],\n",
              " ['chr10', (5717204, 5717266), '+'],\n",
              " ['chr10', (5717557, 5717659), '+'],\n",
              " ['chr10', (5717709, 5717823), '+'],\n",
              " ['chr10', (5719237, 5719318), '+'],\n",
              " ['chr10', (5719882, 5719902), '+'],\n",
              " ['chr10', (5720255, 5720428), '+'],\n",
              " ['chr10', (5720526, 5720628), '+'],\n",
              " ['chr10', (5720709, 5720789), '+'],\n",
              " ['chr10', (5720813, 5720920), '+'],\n",
              " ['chr10', (5722135, 5722198), '+'],\n",
              " ['chr10', (5723729, 5723774), '+'],\n",
              " ['chr10', (5725003, 5725124), '+'],\n",
              " ['chr10', (5725909, 5725983), '+'],\n",
              " ['chr10', (5726026, 5726077), '+'],\n",
              " ['chr10', (5726679, 5726729), '+'],\n",
              " ['chr10', (5727060, 5727086), '+'],\n",
              " ['chr10', (5727099, 5727123), '+'],\n",
              " ['chr10', (5727162, 5727220), '+'],\n",
              " ['chr10', (5730328, 5730405), '+'],\n",
              " ['chr10', (5730617, 5730752), '+'],\n",
              " ['chr10', (5730793, 5730886), '+'],\n",
              " ['chr10', (5731004, 5731060), '+'],\n",
              " ['chr10', (5735398, 5735533), '+'],\n",
              " ['chr10', (5739724, 5739782), '+'],\n",
              " ['chr10', (5739826, 5739928), '+'],\n",
              " ['chr10', (5740037, 5740063), '+'],\n",
              " ['chr10', (5740206, 5740329), '+'],\n",
              " ['chr10', (5740345, 5740496), '+'],\n",
              " ['chr10', (5742416, 5742519), '+'],\n",
              " ['chr10', (5746209, 5746319), '+'],\n",
              " ['chr10', (5746333, 5746391), '+'],\n",
              " ['chr10', (5747596, 5747643), '+'],\n",
              " ['chr10', (5747868, 5747923), '+'],\n",
              " ['chr10', (5748785, 5748853), '+'],\n",
              " ['chr10', (5749026, 5749086), '+'],\n",
              " ['chr10', (5749817, 5749921), '+'],\n",
              " ['chr10', (5749983, 5750018), '+'],\n",
              " ['chr10', (5757544, 5757757), '+'],\n",
              " ['chr10', (5758916, 5758991), '+'],\n",
              " ['chr10', (5758992, 5759069), '+'],\n",
              " ['chr10', (5761289, 5761408), '+'],\n",
              " ['chr10', (5762560, 5762640), '+'],\n",
              " ['chr10', (5763272, 5763361), '+'],\n",
              " ['chr10', (5763654, 5763703), '+'],\n",
              " ['chr10', (5765313, 5765489), '-'],\n",
              " ['chr10', (5765494, 5765548), '-'],\n",
              " ['chr10', (5765564, 5765612), '-'],\n",
              " ['chr10', (5765642, 5765764), '-'],\n",
              " ['chr10', (5765802, 5766098), '-'],\n",
              " ['chr10', (5766115, 5766136), '-'],\n",
              " ['chr10', (5766258, 5766292), '-'],\n",
              " ['chr10', (5766532, 5766638), '-'],\n",
              " ['chr10', (5768322, 5768385), '-'],\n",
              " ['chr10', (5771274, 5771355), '-'],\n",
              " ['chr10', (5773587, 5773815), '-'],\n",
              " ['chr10', (5773840, 5773932), '-'],\n",
              " ['chr10', (5774020, 5774135), '-'],\n",
              " ['chr10', (5774862, 5774922), '-'],\n",
              " ['chr10', (5775502, 5775585), '-'],\n",
              " ['chr10', (5775642, 5775723), '-'],\n",
              " ['chr10', (5775846, 5775892), '-'],\n",
              " ['chr10', (5775934, 5776109), '-'],\n",
              " ['chr10', (5776200, 5776298), '-'],\n",
              " ['chr10', (5776337, 5776400), '-'],\n",
              " ['chr10', (5776412, 5776499), '-'],\n",
              " ['chr10', (5777034, 5777066), '-'],\n",
              " ['chr10', (5778814, 5779051), '-'],\n",
              " ['chr10', (5779877, 5779946), '-'],\n",
              " ['chr10', (5780392, 5780445), '-'],\n",
              " ['chr10', (5780539, 5780759), '-'],\n",
              " ['chr10', (5780813, 5780859), '-'],\n",
              " ['chr10', (5781035, 5781150), '-'],\n",
              " ['chr10', (5782194, 5782249), '-'],\n",
              " ['chr10', (5783059, 5783158), '-'],\n",
              " ['chr10', (5783704, 5783756), '-'],\n",
              " ['chr10', (5784335, 5784445), '-'],\n",
              " ['chr10', (5784800, 5784853), '-'],\n",
              " ['chr10', (5785024, 5785273), '-'],\n",
              " ['chr10', (5785850, 5785917), '-'],\n",
              " ['chr10', (5785973, 5786035), '-'],\n",
              " ['chr10', (5794902, 5794963), '-'],\n",
              " ['chr10', (5795007, 5795019), '-'],\n",
              " ['chr10', (5796762, 5796862), '-'],\n",
              " ['chr10', (5800596, 5800743), '-'],\n",
              " ['chr10', (5800762, 5800842), '-'],\n",
              " ['chr10', (5801613, 5801698), '-'],\n",
              " ['chr10', (5801741, 5801824), '-'],\n",
              " ['chr10', (5802285, 5802345), '-'],\n",
              " ['chr10', (5807288, 5807336), '-'],\n",
              " ['chr10', (5807573, 5807649), '-'],\n",
              " ['chr10', (5807693, 5807804), '-'],\n",
              " ['chr10', (5811442, 5811643), '-'],\n",
              " ['chr10', (5812763, 5812877), '-'],\n",
              " ['chr10', (5812934, 5813116), '-'],\n",
              " ['chr10', (5813209, 5813250), '-'],\n",
              " ['chr10', (5813301, 5813378), '-'],\n",
              " ['chr10', (5866740, 5866999), '-'],\n",
              " ['chr10', (5874867, 5874929), '-'],\n",
              " ['chr10', (5875517, 5875597), '-'],\n",
              " ['chr10', (5877912, 5878026), '-'],\n",
              " ['chr10', (5883133, 5883187), '-'],\n",
              " ['chr10', (5883968, 5884024), '-'],\n",
              " ['chr10', (5887800, 5887901), '-'],\n",
              " ['chr10', (5888000, 5888066), '-'],\n",
              " ['chr10', (5889040, 5889095), '-'],\n",
              " ['chr10', (5890235, 5890684), '+'],\n",
              " ['chr10', (5890785, 5890931), '+'],\n",
              " ['chr10', (5891017, 5891089), '+'],\n",
              " ['chr10', (5891133, 5891191), '+'],\n",
              " ['chr10', (5892050, 5892229), '+'],\n",
              " ['chr10', (5892276, 5892378), '+'],\n",
              " ['chr10', (5892396, 5892469), '+'],\n",
              " ['chr10', (5892483, 5892515), '+'],\n",
              " ['chr10', (5892654, 5892693), '+'],\n",
              " ['chr10', (5892792, 5892886), '+'],\n",
              " ['chr10', (5893424, 5893509), '+'],\n",
              " ['chr10', (5893618, 5893852), '+'],\n",
              " ['chr10', (5894048, 5894175), '+'],\n",
              " ['chr10', (5894833, 5894938), '+'],\n",
              " ['chr10', (5896237, 5896288), '+'],\n",
              " ['chr10', (5900496, 5900545), '+'],\n",
              " ['chr10', (5903019, 5903302), '+'],\n",
              " ['chr10', (5905879, 5905941), '+'],\n",
              " ['chr10', (5905975, 5906095), '+'],\n",
              " ['chr10', (5906486, 5906548), '+'],\n",
              " ['chr10', (5906587, 5906632), '+'],\n",
              " ['chr10', (5908924, 5909053), '+'],\n",
              " ['chr10', (5909161, 5909471), '+'],\n",
              " ['chr10', (5910888, 5910963), '+'],\n",
              " ['chr10', (5911126, 5911180), '+'],\n",
              " ['chr10', (5912857, 5913096), '+'],\n",
              " ['chr10', (5913844, 5913926), '+'],\n",
              " ['chr10', (5914238, 5914314), '+'],\n",
              " ['chr10', (5915477, 5915562), '+'],\n",
              " ['chr10', (5916262, 5916310), '+'],\n",
              " ['chr10', (5916367, 5916439), '+'],\n",
              " ['chr10', (5916726, 5916877), '+'],\n",
              " ['chr10', (5916890, 5916935), '+'],\n",
              " ['chr10', (5917420, 5917545), '+'],\n",
              " ['chr10', (5917620, 5917680), '+'],\n",
              " ['chr10', (5918478, 5918520), '+'],\n",
              " ['chr10', (5921454, 5921633), '+'],\n",
              " ['chr10', (5923629, 5923746), '+'],\n",
              " ['chr10', (5924335, 5924556), '+'],\n",
              " ['chr10', (5925319, 5925403), '+'],\n",
              " ['chr10', (5925433, 5925490), '+'],\n",
              " ['chr10', (5925569, 5925617), '+'],\n",
              " ['chr10', (5927462, 5927512), '+'],\n",
              " ['chr10', (5927524, 5927583), '+'],\n",
              " ['chr10', (5936455, 5936580), '+'],\n",
              " ['chr10', (5936585, 5936634), '+'],\n",
              " ['chr10', (5937365, 5937506), '+'],\n",
              " ['chr10', (5952721, 5952917), '-'],\n",
              " ['chr10', (5960366, 5960563), '-'],\n",
              " ['chr10', (6089032, 6089316), '+'],\n",
              " ['chr10', (6089422, 6089611), '+'],\n",
              " ['chr10', (6091625, 6091787), '+'],\n",
              " ['chr10', (6096206, 6096280), '+'],\n",
              " ['chr10', (6096984, 6097188), '+'],\n",
              " ['chr10', (6101284, 6101423), '+'],\n",
              " ['chr10', (6104073, 6104156), '+'],\n",
              " ['chr10', (6104929, 6104947), '+'],\n",
              " ['chr10', (6105073, 6105100), '+'],\n",
              " ['chr10', (6105824, 6105875), '+'],\n",
              " ['chr10', (6105959, 6106044), '+'],\n",
              " ['chr10', (6106140, 6106248), '+'],\n",
              " ['chr10', (6106444, 6106491), '+'],\n",
              " ['chr10', (6108008, 6108116), '+'],\n",
              " ['chr10', (6108373, 6108476), '+'],\n",
              " ['chr10', (6108595, 6108854), '+'],\n",
              " ['chr10', (6109999, 6110061), '+'],\n",
              " ['chr10', (6112165, 6112409), '+'],\n",
              " ['chr10', (6112459, 6112550), '+'],\n",
              " ['chr10', (6113451, 6113624), '+'],\n",
              " ['chr10', (6113902, 6113966), '+'],\n",
              " ['chr10', (6114028, 6114148), '+'],\n",
              " ['chr10', (6114212, 6114280), '+'],\n",
              " ['chr10', (6115079, 6115165), '+'],\n",
              " ['chr10', (6115188, 6115358), '+'],\n",
              " ['chr10', (6115446, 6115561), '+'],\n",
              " ['chr10', (6145280, 6145445), '+'],\n",
              " ['chr10', (6146038, 6146172), '+'],\n",
              " ['chr10', (6146175, 6146421), '+'],\n",
              " ['chr10', (6149672, 6149725), '+'],\n",
              " ['chr10', (6154738, 6154884), '+'],\n",
              " ['chr10', (6163872, 6163993), '+'],\n",
              " ['chr10', (6164018, 6164307), '+'],\n",
              " ['chr10', (6166516, 6166652), '+'],\n",
              " ['chr10', (6169428, 6169487), '+'],\n",
              " ['chr10', (6169579, 6169646), '+'],\n",
              " ['chr10', (6169651, 6169693), '+'],\n",
              " ['chr10', (6169745, 6169783), '+'],\n",
              " ['chr10', (6172009, 6172099), '+'],\n",
              " ['chr10', (6172278, 6172351), '+'],\n",
              " ['chr10', (6174205, 6174244), '+'],\n",
              " ['chr10', (6174309, 6174353), '+'],\n",
              " ['chr10', (6174376, 6174435), '+'],\n",
              " ['chr10', (6174499, 6174547), '+'],\n",
              " ['chr10', (6174579, 6174656), '+'],\n",
              " ['chr10', (6175381, 6175498), '+'],\n",
              " ['chr10', (6175924, 6176028), '+'],\n",
              " ['chr10', (6176282, 6176388), '+'],\n",
              " ['chr10', (6176733, 6176804), '+'],\n",
              " ['chr10', (6177702, 6177768), '+'],\n",
              " ['chr10', (6177861, 6178119), '+'],\n",
              " ['chr10', (6178270, 6178325), '+'],\n",
              " ['chr10', (6179573, 6179636), '+'],\n",
              " ['chr10', (6201260, 6201322), '+'],\n",
              " ['chr10', (6202392, 6202459), '+'],\n",
              " ['chr10', (6203817, 6203962), '+'],\n",
              " ['chr10', (6213715, 6213784), '+'],\n",
              " ['chr10', (6216187, 6216230), '+'],\n",
              " ['chr10', (6217191, 6217275), '+'],\n",
              " ['chr10', (6219550, 6219717), '+'],\n",
              " ['chr10', (6221643, 6221706), '+'],\n",
              " ['chr10', (6222876, 6222957), '+'],\n",
              " ['chr10', (6224190, 6224254), '+'],\n",
              " ['chr10', (6226407, 6226562), '+'],\n",
              " ['chr10', (6232985, 6233211), '+'],\n",
              " ['chr10', (6233368, 6233441), '+'],\n",
              " ['chr10', (6233505, 6233569), '+'],\n",
              " ['chr10', (6233620, 6233681), '+'],\n",
              " ['chr10', (6234365, 6234446), '+'],\n",
              " ['chr10', (6234703, 6234785), '+'],\n",
              " ['chr10', (6234896, 6234924), '+'],\n",
              " ['chr10', (6235035, 6235087), '+'],\n",
              " ['chr10', (6235136, 6235190), '+'],\n",
              " ['chr10', (6235323, 6235437), '+'],\n",
              " ['chr10', (6235485, 6235529), '+'],\n",
              " ['chr10', (6427161, 6427239), '-'],\n",
              " ['chr10', (6510998, 6511124), '-'],\n",
              " ['chr10', (6570408, 6570459), '-'],\n",
              " ['chr10', (6577716, 6577818), '-'],\n",
              " ['chr10', (6580494, 6580653), '+'],\n",
              " ['chr10', (6581028, 6581141), '+'],\n",
              " ['chr10', (6583728, 6583870), '+'],\n",
              " ['chr10', (7160979, 7161038), '-'],\n",
              " ['chr10', (7163249, 7163335), '-'],\n",
              " ['chr10', (7163401, 7163523), '-'],\n",
              " ['chr10', (7163543, 7163607), '-'],\n",
              " ['chr10', (7164688, 7164765), '-'],\n",
              " ['chr10', (7171851, 7171894), '-'],\n",
              " ['chr10', (7172443, 7172493), '-'],\n",
              " ['chr10', (7205770, 7205864), '-'],\n",
              " ['chr10', (7205893, 7205944), '-'],\n",
              " ['chr10', (7207317, 7207391), '-'],\n",
              " ['chr10', (7219891, 7220049), '-'],\n",
              " ['chr10', (7220526, 7220588), '-'],\n",
              " ['chr10', (7223039, 7223114), '-'],\n",
              " ['chr10', (7227883, 7227938), '-'],\n",
              " ['chr10', (7235163, 7235205), '-'],\n",
              " ['chr10', (7235452, 7235648), '-'],\n",
              " ['chr10', (7236276, 7236336), '-'],\n",
              " ['chr10', (7237910, 7238025), '-'],\n",
              " ['chr10', (7275430, 7275518), '-'],\n",
              " ['chr10', (7276832, 7276989), '-'],\n",
              " ['chr10', (7283374, 7283487), '-'],\n",
              " ['chr10', (7283794, 7283852), '-'],\n",
              " ['chr10', (7284211, 7284322), '-'],\n",
              " ['chr10', (7284353, 7284433), '-'],\n",
              " ['chr10', (7285178, 7285258), '-'],\n",
              " ['chr10', (7285857, 7285950), '-'],\n",
              " ['chr10', (7285990, 7286102), '-'],\n",
              " ['chr10', (7297804, 7297872), '-'],\n",
              " ['chr10', (7298518, 7298748), '-'],\n",
              " ['chr10', (7314863, 7314945), '-'],\n",
              " ['chr10', (7316549, 7316656), '-'],\n",
              " ['chr10', (7316843, 7316906), '-'],\n",
              " ['chr10', (7319614, 7319749), '-'],\n",
              " ['chr10', (7319778, 7320038), '-'],\n",
              " ['chr10', (7324050, 7324176), '-'],\n",
              " ['chr10', (7335492, 7335604), '-'],\n",
              " ['chr10', (7336607, 7336668), '-'],\n",
              " ['chr10', (7350249, 7350362), '-'],\n",
              " ['chr10', (7350435, 7350519), '-'],\n",
              " ['chr10', (7354454, 7354518), '-'],\n",
              " ['chr10', (7354538, 7354710), '-'],\n",
              " ['chr10', (7355353, 7355448), '-'],\n",
              " ['chr10', (7358139, 7358275), '-'],\n",
              " ['chr10', (7364360, 7364440), '-'],\n",
              " ['chr10', (7366081, 7366198), '-'],\n",
              " ['chr10', (7367646, 7367822), '-'],\n",
              " ['chr10', (7367825, 7367890), '-'],\n",
              " ['chr10', (7370277, 7370376), '-'],\n",
              " ['chr10', (7370827, 7370915), '-'],\n",
              " ['chr10', (7375701, 7375774), '-'],\n",
              " ['chr10', (7375814, 7375840), '-'],\n",
              " ['chr10', (7375872, 7375919), '-'],\n",
              " ['chr10', (7376019, 7376111), '-'],\n",
              " ['chr10', (7376183, 7376321), '-'],\n",
              " ['chr10', (7376378, 7376433), '-'],\n",
              " ['chr10', (7376665, 7376701), '-'],\n",
              " ['chr10', (7376815, 7376860), '-'],\n",
              " ['chr10', (7377773, 7378165), '-'],\n",
              " ['chr10', (7378536, 7378672), '-'],\n",
              " ['chr10', (7378703, 7379088), '-'],\n",
              " ['chr10', (7379320, 7379360), '-'],\n",
              " ['chr10', (7379513, 7379586), '-'],\n",
              " ['chr10', (7379607, 7379654), '-'],\n",
              " ['chr10', (7379789, 7379852), '-'],\n",
              " ['chr10', (7381009, 7381106), '-'],\n",
              " ['chr10', (7381798, 7381945), '-'],\n",
              " ['chr10', (7407614, 7407678), '-'],\n",
              " ['chr10', (7407843, 7407899), '-'],\n",
              " ['chr10', (7407938, 7407989), '-'],\n",
              " ['chr10', (7408309, 7408387), '-'],\n",
              " ['chr10', (7408734, 7408817), '-'],\n",
              " ['chr10', (7408934, 7409014), '-'],\n",
              " ['chr10', (7409281, 7409348), '-'],\n",
              " ['chr10', (7409559, 7409644), '-'],\n",
              " ['chr10', (7409884, 7409967), '-'],\n",
              " ['chr10', (7410276, 7410330), '-'],\n",
              " ['chr10', (7410632, 7410690), '-'],\n",
              " ['chr10', (7410862, 7411019), '-'],\n",
              " ['chr10', (7628428, 7628549), '-'],\n",
              " ['chr10', (7666837, 7666983), '-'],\n",
              " ['chr10', (7703338, 7703442), '+'],\n",
              " ['chr10', (7705110, 7705149), '+'],\n",
              " ['chr10', (7705152, 7705210), '+'],\n",
              " ['chr10', (7707180, 7707235), '+'],\n",
              " ['chr10', (7708886, 7708918), '+'],\n",
              " ['chr10', (7709056, 7709144), '+'],\n",
              " ['chr10', (7709187, 7709191), '+'],\n",
              " ['chr10', (7713181, 7713209), '+'],\n",
              " ['chr10', (7713224, 7713257), '+'],\n",
              " ['chr10', (7713259, 7713285), '+'],\n",
              " ['chr10', (7713331, 7713400), '+'],\n",
              " ['chr10', (7717563, 7717622), '+'],\n",
              " ['chr10', (7717625, 7717647), '+'],\n",
              " ['chr10', (7717671, 7717830), '+'],\n",
              " ['chr10', (7717847, 7717897), '+'],\n",
              " ['chr10', (7718669, 7718721), '+'],\n",
              " ['chr10', (7718729, 7718775), '+'],\n",
              " ['chr10', (7718894, 7718952), '+'],\n",
              " ['chr10', (7720124, 7720249), '+'],\n",
              " ['chr10', (7720855, 7720863), '+'],\n",
              " ['chr10', (7720879, 7720885), '+'],\n",
              " ['chr10', (7720945, 7720963), '+'],\n",
              " ['chr10', (7721542, 7721596), '+'],\n",
              " ['chr10', (7721625, 7721642), '+'],\n",
              " ['chr10', (7721648, 7721679), '+'],\n",
              " ['chr10', (7721690, 7721736), '+'],\n",
              " ...]"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_positive_samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLI-8O4pRnI3"
      },
      "outputs": [],
      "source": [
        "def collect_negative_samples(positive_samples):\n",
        "    negative_samples = list()\n",
        "    for i in range(len(positive_samples)-1):\n",
        "        if positive_samples[i][0] == positive_samples[i+1][0]:\n",
        "            start = positive_samples[i][1][1]\n",
        "            end = positive_samples[i+1][1][0]\n",
        "            \n",
        "            chrom = positive_samples[i][0]\n",
        "            negative_samples.append([chrom, (start, end)])\n",
        "        \n",
        "    return negative_samples \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "igpU20f_RnI4"
      },
      "outputs": [],
      "source": [
        "train_negative_samples = collect_negative_samples(train_positive_samples) \n",
        "val_negative_samples = collect_negative_samples(val_positive_samples)\n",
        "test_negative_samples = collect_negative_samples(test_positive_samples) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3bxv_L-RnI4",
        "outputId": "9857b4dd-b6ae-42fc-bb2c-3768f7fc3cb4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[['chr10', (135676, 135729)],\n",
              " ['chr10', (135801, 135816)],\n",
              " ['chr10', (136082, 136291)],\n",
              " ['chr10', (136342, 136353)],\n",
              " ['chr10', (136441, 136541)],\n",
              " ['chr10', (136609, 136647)],\n",
              " ['chr10', (136717, 153358)],\n",
              " ['chr10', (153406, 160419)],\n",
              " ['chr10', (160479, 164259)],\n",
              " ['chr10', (164406, 165435)],\n",
              " ['chr10', (165593, 174516)],\n",
              " ['chr10', (174642, 179976)],\n",
              " ['chr10', (180049, 180059)],\n",
              " ['chr10', (180127, 184656)],\n",
              " ['chr10', (184768, 199226)],\n",
              " ['chr10', (199385, 211483)],\n",
              " ['chr10', (211592, 221619)],\n",
              " ['chr10', (221704, 254444)],\n",
              " ['chr10', (254558, 282044)],\n",
              " ['chr10', (282111, 321293)],\n",
              " ['chr10', (321386, 321425)],\n",
              " ['chr10', (321556, 322940)],\n",
              " ['chr10', (322988, 323237)],\n",
              " ['chr10', (323281, 323483)],\n",
              " ['chr10', (323515, 323981)],\n",
              " ['chr10', (324107, 326933)],\n",
              " ['chr10', (327055, 336738)],\n",
              " ['chr10', (336925, 337174)],\n",
              " ['chr10', (337413, 337427)],\n",
              " ['chr10', (337528, 337581)],\n",
              " ['chr10', (337787, 337802)],\n",
              " ['chr10', (337946, 344767)],\n",
              " ['chr10', (344832, 345451)],\n",
              " ['chr10', (345570, 347934)],\n",
              " ['chr10', (348045, 366237)],\n",
              " ['chr10', (366299, 378278)],\n",
              " ['chr10', (378943, 379118)],\n",
              " ['chr10', (379187, 390695)],\n",
              " ['chr10', (390776, 423355)],\n",
              " ['chr10', (423691, 477096)],\n",
              " ['chr10', (477317, 478176)],\n",
              " ['chr10', (478219, 486458)],\n",
              " ['chr10', (486487, 516269)],\n",
              " ['chr10', (516351, 516992)],\n",
              " ['chr10', (517197, 517402)],\n",
              " ['chr10', (517444, 518560)],\n",
              " ['chr10', (518650, 532204)],\n",
              " ['chr10', (532283, 541357)],\n",
              " ['chr10', (541479, 541592)],\n",
              " ['chr10', (541675, 542015)],\n",
              " ['chr10', (542100, 548495)],\n",
              " ['chr10', (548699, 551154)],\n",
              " ['chr10', (551256, 555428)],\n",
              " ['chr10', (555488, 555623)],\n",
              " ['chr10', (555684, 555786)],\n",
              " ['chr10', (555846, 555932)],\n",
              " ['chr10', (555985, 556005)],\n",
              " ['chr10', (556083, 556109)],\n",
              " ['chr10', (556196, 556416)],\n",
              " ['chr10', (556488, 556538)],\n",
              " ['chr10', (556572, 556851)],\n",
              " ['chr10', (556913, 557160)],\n",
              " ['chr10', (557258, 557452)],\n",
              " ['chr10', (557500, 558262)],\n",
              " ['chr10', (558313, 558480)],\n",
              " ['chr10', (558609, 558878)],\n",
              " ['chr10', (558952, 559292)],\n",
              " ['chr10', (559367, 559656)],\n",
              " ['chr10', (559763, 559925)],\n",
              " ['chr10', (559980, 563604)],\n",
              " ['chr10', (563659, 571416)],\n",
              " ['chr10', (571545, 585201)],\n",
              " ['chr10', (585273, 590123)],\n",
              " ['chr10', (590237, 590823)],\n",
              " ['chr10', (590887, 593537)],\n",
              " ['chr10', (593594, 597310)],\n",
              " ['chr10', (597397, 598194)],\n",
              " ['chr10', (598244, 598271)],\n",
              " ['chr10', (598323, 598507)],\n",
              " ['chr10', (598604, 600480)],\n",
              " ['chr10', (600622, 603776)],\n",
              " ['chr10', (604027, 606055)],\n",
              " ['chr10', (606087, 606190)],\n",
              " ['chr10', (606265, 606910)],\n",
              " ['chr10', (606963, 607916)],\n",
              " ['chr10', (607955, 607971)],\n",
              " ['chr10', (608143, 608286)],\n",
              " ['chr10', (608352, 614441)],\n",
              " ['chr10', (614476, 615036)],\n",
              " ['chr10', (615084, 615870)],\n",
              " ['chr10', (615932, 616526)],\n",
              " ['chr10', (616599, 617065)],\n",
              " ['chr10', (617159, 617448)],\n",
              " ['chr10', (617682, 619354)],\n",
              " ['chr10', (619459, 621267)],\n",
              " ['chr10', (621319, 621477)],\n",
              " ['chr10', (621552, 622163)],\n",
              " ['chr10', (622285, 622587)],\n",
              " ['chr10', (622627, 623082)],\n",
              " ['chr10', (623136, 623194)],\n",
              " ['chr10', (623300, 623335)],\n",
              " ['chr10', (623395, 623404)],\n",
              " ['chr10', (623765, 624009)],\n",
              " ['chr10', (624085, 624091)],\n",
              " ['chr10', (624158, 624185)],\n",
              " ['chr10', (624249, 624299)],\n",
              " ['chr10', (624363, 624547)],\n",
              " ['chr10', (624579, 624949)],\n",
              " ['chr10', (624977, 626342)],\n",
              " ['chr10', (626497, 626987)],\n",
              " ['chr10', (627063, 627195)],\n",
              " ['chr10', (627256, 627860)],\n",
              " ['chr10', (627919, 628558)],\n",
              " ['chr10', (628649, 636469)],\n",
              " ['chr10', (636562, 636887)],\n",
              " ['chr10', (636960, 637252)],\n",
              " ['chr10', (637322, 637952)],\n",
              " ['chr10', (637999, 639178)],\n",
              " ['chr10', (639252, 639282)],\n",
              " ['chr10', (639327, 639785)],\n",
              " ['chr10', (639830, 639931)],\n",
              " ['chr10', (640046, 640211)],\n",
              " ['chr10', (640267, 640542)],\n",
              " ['chr10', (640727, 642639)],\n",
              " ['chr10', (642732, 643631)],\n",
              " ['chr10', (643803, 644562)],\n",
              " ['chr10', (644627, 644693)],\n",
              " ['chr10', (644864, 646148)],\n",
              " ['chr10', (646220, 646238)],\n",
              " ['chr10', (646406, 646505)],\n",
              " ['chr10', (646654, 646865)],\n",
              " ['chr10', (646922, 646992)],\n",
              " ['chr10', (647058, 647138)],\n",
              " ['chr10', (647155, 647218)],\n",
              " ['chr10', (647260, 647432)],\n",
              " ['chr10', (647468, 647470)],\n",
              " ['chr10', (647525, 647669)],\n",
              " ['chr10', (647717, 647943)],\n",
              " ['chr10', (647987, 648092)],\n",
              " ['chr10', (648137, 648188)],\n",
              " ['chr10', (648245, 648367)],\n",
              " ['chr10', (648406, 648412)],\n",
              " ['chr10', (648488, 648533)],\n",
              " ['chr10', (648606, 648685)],\n",
              " ['chr10', (648713, 648955)],\n",
              " ['chr10', (649022, 649128)],\n",
              " ['chr10', (649181, 649421)],\n",
              " ['chr10', (649485, 650183)],\n",
              " ['chr10', (650235, 650681)],\n",
              " ['chr10', (650744, 650965)],\n",
              " ['chr10', (651087, 651232)],\n",
              " ['chr10', (651285, 651796)],\n",
              " ['chr10', (651846, 652556)],\n",
              " ['chr10', (652610, 652979)],\n",
              " ['chr10', (653053, 653691)],\n",
              " ['chr10', (653806, 658835)],\n",
              " ['chr10', (659181, 659246)],\n",
              " ['chr10', (659327, 659332)],\n",
              " ['chr10', (659442, 665606)],\n",
              " ['chr10', (665763, 666426)],\n",
              " ['chr10', (666471, 667283)],\n",
              " ['chr10', (667399, 667416)],\n",
              " ['chr10', (668183, 668191)],\n",
              " ['chr10', (668305, 668309)],\n",
              " ['chr10', (668679, 668894)],\n",
              " ['chr10', (668945, 670203)],\n",
              " ['chr10', (670280, 676069)],\n",
              " ['chr10', (676152, 677920)],\n",
              " ['chr10', (677997, 678183)],\n",
              " ['chr10', (678193, 678264)],\n",
              " ['chr10', (678362, 678395)],\n",
              " ['chr10', (678643, 678749)],\n",
              " ['chr10', (678838, 679185)],\n",
              " ['chr10', (679222, 679253)],\n",
              " ['chr10', (679315, 679346)],\n",
              " ['chr10', (679404, 679429)],\n",
              " ['chr10', (679505, 679602)],\n",
              " ['chr10', (679902, 679923)],\n",
              " ['chr10', (679996, 680009)],\n",
              " ['chr10', (680374, 681234)],\n",
              " ['chr10', (681349, 681410)],\n",
              " ['chr10', (681457, 681477)],\n",
              " ['chr10', (681524, 681528)],\n",
              " ['chr10', (681575, 682197)],\n",
              " ['chr10', (682293, 686290)],\n",
              " ['chr10', (686479, 688138)],\n",
              " ['chr10', (688184, 688809)],\n",
              " ['chr10', (688959, 689009)],\n",
              " ['chr10', (689195, 689220)],\n",
              " ['chr10', (689283, 689462)],\n",
              " ['chr10', (689614, 809426)],\n",
              " ['chr10', (809508, 809712)],\n",
              " ['chr10', (809777, 809806)],\n",
              " ['chr10', (809897, 811120)],\n",
              " ['chr10', (811179, 811227)],\n",
              " ['chr10', (811262, 811286)],\n",
              " ['chr10', (811440, 811917)],\n",
              " ['chr10', (811970, 812156)],\n",
              " ['chr10', (812262, 812379)],\n",
              " ['chr10', (812436, 814451)],\n",
              " ['chr10', (814626, 814739)],\n",
              " ['chr10', (814810, 815052)],\n",
              " ['chr10', (815138, 817581)],\n",
              " ['chr10', (817624, 817649)],\n",
              " ['chr10', (817734, 817846)],\n",
              " ['chr10', (817980, 820748)],\n",
              " ['chr10', (821041, 822157)],\n",
              " ['chr10', (822258, 822327)],\n",
              " ['chr10', (822511, 825012)],\n",
              " ['chr10', (825066, 825169)],\n",
              " ['chr10', (825232, 825359)],\n",
              " ['chr10', (825415, 825685)],\n",
              " ['chr10', (825760, 826339)],\n",
              " ['chr10', (826441, 827567)],\n",
              " ['chr10', (827632, 827648)],\n",
              " ['chr10', (827687, 828084)],\n",
              " ['chr10', (828144, 828498)],\n",
              " ['chr10', (828552, 829404)],\n",
              " ['chr10', (829477, 829676)],\n",
              " ['chr10', (829703, 829950)],\n",
              " ['chr10', (830019, 830068)],\n",
              " ['chr10', (830115, 830865)],\n",
              " ['chr10', (830981, 831091)],\n",
              " ['chr10', (831164, 832056)],\n",
              " ['chr10', (832125, 836067)],\n",
              " ['chr10', (836129, 836401)],\n",
              " ['chr10', (836449, 836455)],\n",
              " ['chr10', (836520, 837139)],\n",
              " ['chr10', (837250, 837548)],\n",
              " ['chr10', (837614, 837626)],\n",
              " ['chr10', (837753, 837828)],\n",
              " ['chr10', (837885, 838093)],\n",
              " ['chr10', (838141, 838229)],\n",
              " ['chr10', (838270, 838554)],\n",
              " ['chr10', (838590, 839810)],\n",
              " ['chr10', (839962, 842812)],\n",
              " ['chr10', (842888, 842960)],\n",
              " ['chr10', (843108, 843821)],\n",
              " ['chr10', (843872, 844523)],\n",
              " ['chr10', (844602, 844855)],\n",
              " ['chr10', (845099, 846476)],\n",
              " ['chr10', (846601, 846708)],\n",
              " ['chr10', (846897, 847047)],\n",
              " ['chr10', (847114, 847175)],\n",
              " ['chr10', (847245, 847373)],\n",
              " ['chr10', (847425, 848158)],\n",
              " ['chr10', (848252, 849079)],\n",
              " ['chr10', (849166, 852329)],\n",
              " ['chr10', (852465, 853458)],\n",
              " ['chr10', (853505, 857031)],\n",
              " ['chr10', (857151, 857162)],\n",
              " ['chr10', (857260, 858486)],\n",
              " ['chr10', (858563, 863739)],\n",
              " ['chr10', (863775, 863813)],\n",
              " ['chr10', (863926, 863968)],\n",
              " ['chr10', (864232, 865827)],\n",
              " ['chr10', (865922, 871379)],\n",
              " ['chr10', (871437, 871467)],\n",
              " ['chr10', (871516, 872730)],\n",
              " ['chr10', (872790, 872934)],\n",
              " ['chr10', (872990, 873289)],\n",
              " ['chr10', (873354, 885649)],\n",
              " ['chr10', (885858, 889313)],\n",
              " ['chr10', (889424, 899276)],\n",
              " ['chr10', (899333, 899451)],\n",
              " ['chr10', (899570, 899624)],\n",
              " ['chr10', (899803, 912814)],\n",
              " ['chr10', (912864, 913680)],\n",
              " ['chr10', (913749, 915280)],\n",
              " ['chr10', (915293, 915996)],\n",
              " ['chr10', (916067, 921974)],\n",
              " ['chr10', (922038, 923069)],\n",
              " ['chr10', (923076, 924029)],\n",
              " ['chr10', (924068, 924954)],\n",
              " ['chr10', (925008, 926803)],\n",
              " ['chr10', (926857, 927197)],\n",
              " ['chr10', (927326, 928426)],\n",
              " ['chr10', (928484, 930071)],\n",
              " ['chr10', (930123, 930125)],\n",
              " ['chr10', (930177, 930541)],\n",
              " ['chr10', (930592, 930606)],\n",
              " ['chr10', (930697, 930715)],\n",
              " ['chr10', (930872, 930912)],\n",
              " ['chr10', (931189, 931193)],\n",
              " ['chr10', (931305, 931362)],\n",
              " ['chr10', (931691, 988436)],\n",
              " ['chr10', (988493, 988502)],\n",
              " ['chr10', (988629, 992488)],\n",
              " ['chr10', (992527, 996113)],\n",
              " ['chr10', (996291, 996568)],\n",
              " ['chr10', (996649, 996660)],\n",
              " ['chr10', (996712, 997183)],\n",
              " ['chr10', (997309, 997359)],\n",
              " ['chr10', (997406, 997464)],\n",
              " ['chr10', (997505, 997556)],\n",
              " ['chr10', (997638, 1000672)],\n",
              " ['chr10', (1001033, 1001259)],\n",
              " ['chr10', (1001339, 1001364)],\n",
              " ['chr10', (1001470, 1003013)],\n",
              " ['chr10', (1003176, 1003602)],\n",
              " ['chr10', (1003661, 1003665)],\n",
              " ['chr10', (1003833, 1003885)],\n",
              " ['chr10', (1003939, 1005480)],\n",
              " ['chr10', (1005540, 1005816)],\n",
              " ['chr10', (1005926, 1005982)],\n",
              " ['chr10', (1006032, 1006961)],\n",
              " ['chr10', (1007015, 1007016)],\n",
              " ['chr10', (1007061, 1007064)],\n",
              " ['chr10', (1007174, 1007445)],\n",
              " ['chr10', (1007509, 1008812)],\n",
              " ['chr10', (1008898, 1008945)],\n",
              " ['chr10', (1009079, 1009474)],\n",
              " ['chr10', (1009634, 1010252)],\n",
              " ['chr10', (1010347, 1010419)],\n",
              " ['chr10', (1010521, 1010530)],\n",
              " ['chr10', (1010609, 1010630)],\n",
              " ['chr10', (1010675, 1010776)],\n",
              " ['chr10', (1010842, 1010869)],\n",
              " ['chr10', (1011140, 1011161)],\n",
              " ['chr10', (1011225, 1011395)],\n",
              " ['chr10', (1011436, 1011444)],\n",
              " ['chr10', (1011496, 1012460)],\n",
              " ['chr10', (1012707, 1014244)],\n",
              " ['chr10', (1014355, 1015478)],\n",
              " ['chr10', (1015577, 1015746)],\n",
              " ['chr10', (1015859, 1015880)],\n",
              " ['chr10', (1015952, 1017070)],\n",
              " ['chr10', (1017441, 1017470)],\n",
              " ['chr10', (1017579, 1019706)],\n",
              " ['chr10', (1019796, 1040065)],\n",
              " ['chr10', (1040232, 1040291)],\n",
              " ['chr10', (1040567, 1040650)],\n",
              " ['chr10', (1040707, 1040779)],\n",
              " ['chr10', (1040875, 1041309)],\n",
              " ['chr10', (1041480, 1042733)],\n",
              " ['chr10', (1042789, 1043259)],\n",
              " ['chr10', (1043301, 1043395)],\n",
              " ['chr10', (1043404, 1043986)],\n",
              " ['chr10', (1044094, 1044136)],\n",
              " ['chr10', (1044203, 1045792)],\n",
              " ['chr10', (1045951, 1046363)],\n",
              " ['chr10', (1046501, 1047604)],\n",
              " ['chr10', (1047750, 1048572)],\n",
              " ['chr10', (1048897, 1050152)],\n",
              " ['chr10', (1050245, 1056878)],\n",
              " ['chr10', (1056990, 1057056)],\n",
              " ['chr10', (1057160, 1057322)],\n",
              " ['chr10', (1057408, 1062023)],\n",
              " ['chr10', (1062121, 1063672)],\n",
              " ['chr10', (1063738, 1064337)],\n",
              " ['chr10', (1064413, 1065184)],\n",
              " ['chr10', (1065253, 1065461)],\n",
              " ['chr10', (1065535, 1065629)],\n",
              " ['chr10', (1065705, 1077915)],\n",
              " ['chr10', (1077984, 1078003)],\n",
              " ['chr10', (1078078, 1080345)],\n",
              " ['chr10', (1080457, 1081774)],\n",
              " ['chr10', (1081851, 1082905)],\n",
              " ['chr10', (1082954, 1084450)],\n",
              " ['chr10', (1084543, 1086285)],\n",
              " ['chr10', (1086349, 1086357)],\n",
              " ['chr10', (1086525, 1086570)],\n",
              " ['chr10', (1086661, 1087617)],\n",
              " ['chr10', (1087657, 1088464)],\n",
              " ['chr10', (1088523, 1089028)],\n",
              " ['chr10', (1089101, 1089122)],\n",
              " ['chr10', (1089257, 1093181)],\n",
              " ['chr10', (1093412, 1093442)],\n",
              " ['chr10', (1093522, 1095743)],\n",
              " ['chr10', (1095837, 1096121)],\n",
              " ['chr10', (1096183, 1096237)],\n",
              " ['chr10', (1096346, 1096720)],\n",
              " ['chr10', (1096788, 1098019)],\n",
              " ['chr10', (1098066, 1100263)],\n",
              " ['chr10', (1100367, 1103072)],\n",
              " ['chr10', (1103133, 1103189)],\n",
              " ['chr10', (1103332, 1103574)],\n",
              " ['chr10', (1103625, 1107572)],\n",
              " ['chr10', (1107644, 1107826)],\n",
              " ['chr10', (1108038, 1108903)],\n",
              " ['chr10', (1108996, 1109015)],\n",
              " ['chr10', (1109132, 1109152)],\n",
              " ['chr10', (1109217, 1110157)],\n",
              " ['chr10', (1110244, 1110571)],\n",
              " ['chr10', (1110659, 1110851)],\n",
              " ['chr10', (1110903, 1116128)],\n",
              " ['chr10', (1116330, 1120842)],\n",
              " ['chr10', (1121015, 1123664)],\n",
              " ['chr10', (1123841, 1124685)],\n",
              " ['chr10', (1124768, 1131688)],\n",
              " ['chr10', (1131842, 1164129)],\n",
              " ['chr10', (1164223, 1164443)],\n",
              " ['chr10', (1164536, 1220236)],\n",
              " ['chr10', (1220281, 3067548)],\n",
              " ['chr10', (3067635, 3067826)],\n",
              " ['chr10', (3068003, 3099284)],\n",
              " ['chr10', (3099353, 3099458)],\n",
              " ['chr10', (3099550, 3099720)],\n",
              " ['chr10', (3100148, 3101361)],\n",
              " ['chr10', (3101413, 3101509)],\n",
              " ['chr10', (3101552, 3103097)],\n",
              " ['chr10', (3103276, 3103929)],\n",
              " ['chr10', (3103938, 3103944)],\n",
              " ['chr10', (3103987, 3105067)],\n",
              " ['chr10', (3105212, 3105213)],\n",
              " ['chr10', (3105283, 3105319)],\n",
              " ['chr10', (3105473, 3105500)],\n",
              " ['chr10', (3105543, 3106981)],\n",
              " ['chr10', (3107182, 3107242)],\n",
              " ['chr10', (3107300, 3107334)],\n",
              " ['chr10', (3107394, 3108654)],\n",
              " ['chr10', (3108747, 3108762)],\n",
              " ['chr10', (3108794, 3109352)],\n",
              " ['chr10', (3109455, 3109480)],\n",
              " ['chr10', (3109523, 3109835)],\n",
              " ['chr10', (3109985, 3110679)],\n",
              " ['chr10', (3110775, 3110843)],\n",
              " ['chr10', (3111134, 3111138)],\n",
              " ['chr10', (3111423, 3112153)],\n",
              " ['chr10', (3112205, 3112223)],\n",
              " ['chr10', (3112287, 3112295)],\n",
              " ['chr10', (3112323, 3113118)],\n",
              " ['chr10', (3113188, 3113371)],\n",
              " ['chr10', (3113427, 3113744)],\n",
              " ['chr10', (3113850, 3115485)],\n",
              " ['chr10', (3115641, 3116471)],\n",
              " ['chr10', (3116526, 3116792)],\n",
              " ['chr10', (3116885, 3119915)],\n",
              " ['chr10', (3119933, 3119938)],\n",
              " ['chr10', (3119954, 3120044)],\n",
              " ['chr10', (3120113, 3120376)],\n",
              " ['chr10', (3120438, 3120854)],\n",
              " ['chr10', (3120907, 3121830)],\n",
              " ['chr10', (3121925, 3122134)],\n",
              " ['chr10', (3122215, 3122283)],\n",
              " ['chr10', (3122336, 3122559)],\n",
              " ['chr10', (3122628, 3122791)],\n",
              " ['chr10', (3122908, 3123470)],\n",
              " ['chr10', (3123573, 3123686)],\n",
              " ['chr10', (3123775, 3124039)],\n",
              " ['chr10', (3124075, 3124306)],\n",
              " ['chr10', (3124361, 3124439)],\n",
              " ['chr10', (3124624, 3124674)],\n",
              " ['chr10', (3125218, 3125771)],\n",
              " ['chr10', (3125801, 3128785)],\n",
              " ['chr10', (3128843, 3129062)],\n",
              " ['chr10', (3129124, 3129158)],\n",
              " ['chr10', (3129233, 3129921)],\n",
              " ['chr10', (3129985, 3132378)],\n",
              " ['chr10', (3132395, 3133339)],\n",
              " ['chr10', (3133432, 3134224)],\n",
              " ['chr10', (3134310, 3134535)],\n",
              " ['chr10', (3134627, 3135735)],\n",
              " ['chr10', (3135785, 3136467)],\n",
              " ['chr10', (3136500, 3136558)],\n",
              " ['chr10', (3136777, 3137833)],\n",
              " ['chr10', (3137976, 3138635)],\n",
              " ['chr10', (3138700, 3138785)],\n",
              " ['chr10', (3138839, 3140778)],\n",
              " ['chr10', (3140862, 3143828)],\n",
              " ['chr10', (3143896, 3144139)],\n",
              " ['chr10', (3144229, 3144235)],\n",
              " ['chr10', (3144348, 3145538)],\n",
              " ['chr10', (3145598, 3147211)],\n",
              " ['chr10', (3147264, 3147527)],\n",
              " ['chr10', (3147572, 3147696)],\n",
              " ['chr10', (3147749, 3147837)],\n",
              " ['chr10', (3147985, 3148015)],\n",
              " ['chr10', (3148054, 3148190)],\n",
              " ['chr10', (3148254, 3149528)],\n",
              " ['chr10', (3149616, 3151244)],\n",
              " ['chr10', (3151341, 3156257)],\n",
              " ['chr10', (3156322, 3156685)],\n",
              " ['chr10', (3156732, 3157447)],\n",
              " ['chr10', (3157516, 3157938)],\n",
              " ['chr10', (3158018, 3163752)],\n",
              " ['chr10', (3163862, 3165377)],\n",
              " ['chr10', (3165444, 3166852)],\n",
              " ['chr10', (3166935, 3166972)],\n",
              " ['chr10', (3167041, 3170103)],\n",
              " ['chr10', (3170209, 3172714)],\n",
              " ['chr10', (3172777, 3776448)],\n",
              " ['chr10', (3776547, 3776571)],\n",
              " ['chr10', (3776624, 3777773)],\n",
              " ['chr10', (3777834, 3777960)],\n",
              " ['chr10', (3777999, 3778570)],\n",
              " ['chr10', (3778630, 3778851)],\n",
              " ['chr10', (3779049, 3779068)],\n",
              " ['chr10', (3779149, 3779161)],\n",
              " ['chr10', (3779261, 3779291)],\n",
              " ['chr10', (3779680, 3779984)],\n",
              " ['chr10', (3780119, 3780166)],\n",
              " ['chr10', (3780301, 3781537)],\n",
              " ['chr10', (3781676, 3781711)],\n",
              " ['chr10', (3781959, 3781972)],\n",
              " ['chr10', (3782032, 3782162)],\n",
              " ['chr10', (3782376, 3784778)],\n",
              " ['chr10', (3784913, 3785035)],\n",
              " ['chr10', (3785106, 3785118)],\n",
              " ['chr10', (3785218, 4827201)],\n",
              " ['chr10', (4827417, 4833349)],\n",
              " ['chr10', (4833446, 4963416)],\n",
              " ['chr10', (4963529, 4963616)],\n",
              " ['chr10', (4963787, 4965702)],\n",
              " ['chr10', (4965752, 4965840)],\n",
              " ['chr10', (4965951, 4966125)],\n",
              " ['chr10', (4966179, 4966544)],\n",
              " ['chr10', (4966659, 4966881)],\n",
              " ['chr10', (4966974, 4967075)],\n",
              " ['chr10', (4967169, 4968346)],\n",
              " ['chr10', (4968395, 4968673)],\n",
              " ['chr10', (4968921, 4971813)],\n",
              " ['chr10', (4971877, 4972510)],\n",
              " ['chr10', (4972577, 4972654)],\n",
              " ['chr10', (4972725, 4974447)],\n",
              " ['chr10', (4974520, 4974559)],\n",
              " ['chr10', (4974605, 4974636)],\n",
              " ['chr10', (4974799, 4974866)],\n",
              " ['chr10', (4975006, 4977738)],\n",
              " ['chr10', (4977912, 4979326)],\n",
              " ['chr10', (4979410, 4980885)],\n",
              " ['chr10', (4980946, 4981833)],\n",
              " ['chr10', (4981875, 4982120)],\n",
              " ['chr10', (4982278, 4982309)],\n",
              " ['chr10', (4982377, 4983034)],\n",
              " ['chr10', (4983206, 4985314)],\n",
              " ['chr10', (4985460, 4986071)],\n",
              " ['chr10', (4986156, 4986624)],\n",
              " ['chr10', (4986707, 4989839)],\n",
              " ['chr10', (4989998, 4992698)],\n",
              " ['chr10', (4992799, 4998643)],\n",
              " ['chr10', (4998802, 4999197)],\n",
              " ['chr10', (4999232, 4999365)],\n",
              " ['chr10', (4999418, 5000395)],\n",
              " ['chr10', (5000516, 5001538)],\n",
              " ['chr10', (5001627, 5001644)],\n",
              " ['chr10', (5001679, 5001683)],\n",
              " ['chr10', (5001695, 5003500)],\n",
              " ['chr10', (5003565, 5003582)],\n",
              " ['chr10', (5003675, 5096428)],\n",
              " ['chr10', (5096489, 5096503)],\n",
              " ['chr10', (5096686, 5097497)],\n",
              " ['chr10', (5097609, 5098269)],\n",
              " ['chr10', (5098357, 5098757)],\n",
              " ['chr10', (5098840, 5098859)],\n",
              " ['chr10', (5098913, 5099324)],\n",
              " ['chr10', (5099425, 5099440)],\n",
              " ['chr10', (5099501, 5102073)],\n",
              " ['chr10', (5102149, 5102242)],\n",
              " ['chr10', (5102345, 5102484)],\n",
              " ['chr10', (5102512, 5104922)],\n",
              " ['chr10', (5104970, 5105244)],\n",
              " ['chr10', (5105286, 5105344)],\n",
              " ['chr10', (5105404, 5105594)],\n",
              " ['chr10', (5105681, 5105721)],\n",
              " ['chr10', (5105775, 5106181)],\n",
              " ['chr10', (5106258, 5107460)],\n",
              " ['chr10', (5107489, 5107492)],\n",
              " ['chr10', (5107585, 5107588)],\n",
              " ['chr10', (5107659, 5412587)],\n",
              " ['chr10', (5412677, 5413037)],\n",
              " ['chr10', (5413105, 5417679)],\n",
              " ['chr10', (5417751, 5426763)],\n",
              " ['chr10', (5426837, 5433943)],\n",
              " ['chr10', (5433996, 5434250)],\n",
              " ['chr10', (5434353, 5444547)],\n",
              " ['chr10', (5444680, 5444930)],\n",
              " ['chr10', (5445031, 5445048)],\n",
              " ['chr10', (5445155, 5446617)],\n",
              " ['chr10', (5446815, 5446821)],\n",
              " ['chr10', (5446843, 5446969)],\n",
              " ['chr10', (5447044, 5447092)],\n",
              " ['chr10', (5447154, 5447170)],\n",
              " ['chr10', (5447217, 5447519)],\n",
              " ['chr10', (5447625, 5447638)],\n",
              " ['chr10', (5447676, 5448382)],\n",
              " ['chr10', (5448524, 5451787)],\n",
              " ['chr10', (5451860, 5451901)],\n",
              " ['chr10', (5451928, 5451951)],\n",
              " ['chr10', (5451979, 5452196)],\n",
              " ['chr10', (5452257, 5452323)],\n",
              " ['chr10', (5452420, 5452524)],\n",
              " ['chr10', (5452577, 5452916)],\n",
              " ['chr10', (5452966, 5453201)],\n",
              " ['chr10', (5453397, 5453442)],\n",
              " ['chr10', (5453651, 5454252)],\n",
              " ['chr10', (5454295, 5454375)],\n",
              " ['chr10', (5454480, 5454521)],\n",
              " ['chr10', (5454673, 5454911)],\n",
              " ['chr10', (5454931, 5454987)],\n",
              " ['chr10', (5455175, 5456104)],\n",
              " ['chr10', (5456194, 5456273)],\n",
              " ['chr10', (5456336, 5456592)],\n",
              " ['chr10', (5456657, 5456699)],\n",
              " ['chr10', (5456795, 5456866)],\n",
              " ['chr10', (5456905, 5456962)],\n",
              " ['chr10', (5456991, 5456994)],\n",
              " ['chr10', (5457106, 5457150)],\n",
              " ['chr10', (5457194, 5457256)],\n",
              " ['chr10', (5457344, 5457608)],\n",
              " ['chr10', (5457727, 5457761)],\n",
              " ['chr10', (5457819, 5458276)],\n",
              " ['chr10', (5458322, 5458327)],\n",
              " ['chr10', (5458432, 5638972)],\n",
              " ['chr10', (5639033, 5659606)],\n",
              " ['chr10', (5659677, 5661132)],\n",
              " ['chr10', (5661247, 5663153)],\n",
              " ['chr10', (5663238, 5684851)],\n",
              " ['chr10', (5685268, 5685294)],\n",
              " ['chr10', (5685491, 5685502)],\n",
              " ['chr10', (5685588, 5685600)],\n",
              " ['chr10', (5685696, 5686105)],\n",
              " ['chr10', (5686149, 5688584)],\n",
              " ['chr10', (5688658, 5688724)],\n",
              " ['chr10', (5688787, 5689620)],\n",
              " ['chr10', (5689751, 5689784)],\n",
              " ['chr10', (5689852, 5690176)],\n",
              " ['chr10', (5690236, 5692433)],\n",
              " ['chr10', (5692590, 5692680)],\n",
              " ['chr10', (5692755, 5692954)],\n",
              " ['chr10', (5693030, 5693076)],\n",
              " ['chr10', (5693140, 5693157)],\n",
              " ['chr10', (5693272, 5694998)],\n",
              " ['chr10', (5695067, 5695765)],\n",
              " ['chr10', (5695829, 5695882)],\n",
              " ['chr10', (5696024, 5696045)],\n",
              " ['chr10', (5696122, 5696147)],\n",
              " ['chr10', (5696221, 5696369)],\n",
              " ['chr10', (5696423, 5696536)],\n",
              " ['chr10', (5696623, 5697024)],\n",
              " ['chr10', (5697117, 5697501)],\n",
              " ['chr10', (5697615, 5699328)],\n",
              " ['chr10', (5699440, 5700027)],\n",
              " ['chr10', (5700155, 5700495)],\n",
              " ['chr10', (5700524, 5700756)],\n",
              " ['chr10', (5700864, 5701008)],\n",
              " ['chr10', (5701054, 5701061)],\n",
              " ['chr10', (5701144, 5701169)],\n",
              " ['chr10', (5701215, 5701255)],\n",
              " ['chr10', (5701325, 5701333)],\n",
              " ['chr10', (5701374, 5701495)],\n",
              " ['chr10', (5701567, 5701753)],\n",
              " ['chr10', (5701785, 5701854)],\n",
              " ['chr10', (5701915, 5703825)],\n",
              " ['chr10', (5703923, 5704479)],\n",
              " ['chr10', (5704536, 5704621)],\n",
              " ['chr10', (5704726, 5705207)],\n",
              " ['chr10', (5705422, 5707411)],\n",
              " ['chr10', (5707439, 5707530)],\n",
              " ['chr10', (5707637, 5707654)],\n",
              " ['chr10', (5707940, 5708191)],\n",
              " ['chr10', (5708230, 5708567)],\n",
              " ['chr10', (5708620, 5708652)],\n",
              " ['chr10', (5708747, 5709022)],\n",
              " ['chr10', (5709048, 5709513)],\n",
              " ['chr10', (5709578, 5712802)],\n",
              " ['chr10', (5712851, 5714257)],\n",
              " ['chr10', (5714350, 5717204)],\n",
              " ['chr10', (5717266, 5717557)],\n",
              " ['chr10', (5717659, 5717709)],\n",
              " ['chr10', (5717823, 5719237)],\n",
              " ['chr10', (5719318, 5719882)],\n",
              " ['chr10', (5719902, 5720255)],\n",
              " ['chr10', (5720428, 5720526)],\n",
              " ['chr10', (5720628, 5720709)],\n",
              " ['chr10', (5720789, 5720813)],\n",
              " ['chr10', (5720920, 5722135)],\n",
              " ['chr10', (5722198, 5723729)],\n",
              " ['chr10', (5723774, 5725003)],\n",
              " ['chr10', (5725124, 5725909)],\n",
              " ['chr10', (5725983, 5726026)],\n",
              " ['chr10', (5726077, 5726679)],\n",
              " ['chr10', (5726729, 5727060)],\n",
              " ['chr10', (5727086, 5727099)],\n",
              " ['chr10', (5727123, 5727162)],\n",
              " ['chr10', (5727220, 5730328)],\n",
              " ['chr10', (5730405, 5730617)],\n",
              " ['chr10', (5730752, 5730793)],\n",
              " ['chr10', (5730886, 5731004)],\n",
              " ['chr10', (5731060, 5735398)],\n",
              " ['chr10', (5735533, 5739724)],\n",
              " ['chr10', (5739782, 5739826)],\n",
              " ['chr10', (5739928, 5740037)],\n",
              " ['chr10', (5740063, 5740206)],\n",
              " ['chr10', (5740329, 5740345)],\n",
              " ['chr10', (5740496, 5742416)],\n",
              " ['chr10', (5742519, 5746209)],\n",
              " ['chr10', (5746319, 5746333)],\n",
              " ['chr10', (5746391, 5747596)],\n",
              " ['chr10', (5747643, 5747868)],\n",
              " ['chr10', (5747923, 5748785)],\n",
              " ['chr10', (5748853, 5749026)],\n",
              " ['chr10', (5749086, 5749817)],\n",
              " ['chr10', (5749921, 5749983)],\n",
              " ['chr10', (5750018, 5757544)],\n",
              " ['chr10', (5757757, 5758916)],\n",
              " ['chr10', (5758991, 5758992)],\n",
              " ['chr10', (5759069, 5761289)],\n",
              " ['chr10', (5761408, 5762560)],\n",
              " ['chr10', (5762640, 5763272)],\n",
              " ['chr10', (5763361, 5763654)],\n",
              " ['chr10', (5763703, 5765313)],\n",
              " ['chr10', (5765489, 5765494)],\n",
              " ['chr10', (5765548, 5765564)],\n",
              " ['chr10', (5765612, 5765642)],\n",
              " ['chr10', (5765764, 5765802)],\n",
              " ['chr10', (5766098, 5766115)],\n",
              " ['chr10', (5766136, 5766258)],\n",
              " ['chr10', (5766292, 5766532)],\n",
              " ['chr10', (5766638, 5768322)],\n",
              " ['chr10', (5768385, 5771274)],\n",
              " ['chr10', (5771355, 5773587)],\n",
              " ['chr10', (5773815, 5773840)],\n",
              " ['chr10', (5773932, 5774020)],\n",
              " ['chr10', (5774135, 5774862)],\n",
              " ['chr10', (5774922, 5775502)],\n",
              " ['chr10', (5775585, 5775642)],\n",
              " ['chr10', (5775723, 5775846)],\n",
              " ['chr10', (5775892, 5775934)],\n",
              " ['chr10', (5776109, 5776200)],\n",
              " ['chr10', (5776298, 5776337)],\n",
              " ['chr10', (5776400, 5776412)],\n",
              " ['chr10', (5776499, 5777034)],\n",
              " ['chr10', (5777066, 5778814)],\n",
              " ['chr10', (5779051, 5779877)],\n",
              " ['chr10', (5779946, 5780392)],\n",
              " ['chr10', (5780445, 5780539)],\n",
              " ['chr10', (5780759, 5780813)],\n",
              " ['chr10', (5780859, 5781035)],\n",
              " ['chr10', (5781150, 5782194)],\n",
              " ['chr10', (5782249, 5783059)],\n",
              " ['chr10', (5783158, 5783704)],\n",
              " ['chr10', (5783756, 5784335)],\n",
              " ['chr10', (5784445, 5784800)],\n",
              " ['chr10', (5784853, 5785024)],\n",
              " ['chr10', (5785273, 5785850)],\n",
              " ['chr10', (5785917, 5785973)],\n",
              " ['chr10', (5786035, 5794902)],\n",
              " ['chr10', (5794963, 5795007)],\n",
              " ['chr10', (5795019, 5796762)],\n",
              " ['chr10', (5796862, 5800596)],\n",
              " ['chr10', (5800743, 5800762)],\n",
              " ['chr10', (5800842, 5801613)],\n",
              " ['chr10', (5801698, 5801741)],\n",
              " ['chr10', (5801824, 5802285)],\n",
              " ['chr10', (5802345, 5807288)],\n",
              " ['chr10', (5807336, 5807573)],\n",
              " ['chr10', (5807649, 5807693)],\n",
              " ['chr10', (5807804, 5811442)],\n",
              " ['chr10', (5811643, 5812763)],\n",
              " ['chr10', (5812877, 5812934)],\n",
              " ['chr10', (5813116, 5813209)],\n",
              " ['chr10', (5813250, 5813301)],\n",
              " ['chr10', (5813378, 5866740)],\n",
              " ['chr10', (5866999, 5874867)],\n",
              " ['chr10', (5874929, 5875517)],\n",
              " ['chr10', (5875597, 5877912)],\n",
              " ['chr10', (5878026, 5883133)],\n",
              " ['chr10', (5883187, 5883968)],\n",
              " ['chr10', (5884024, 5887800)],\n",
              " ['chr10', (5887901, 5888000)],\n",
              " ['chr10', (5888066, 5889040)],\n",
              " ['chr10', (5889095, 5890235)],\n",
              " ['chr10', (5890684, 5890785)],\n",
              " ['chr10', (5890931, 5891017)],\n",
              " ['chr10', (5891089, 5891133)],\n",
              " ['chr10', (5891191, 5892050)],\n",
              " ['chr10', (5892229, 5892276)],\n",
              " ['chr10', (5892378, 5892396)],\n",
              " ['chr10', (5892469, 5892483)],\n",
              " ['chr10', (5892515, 5892654)],\n",
              " ['chr10', (5892693, 5892792)],\n",
              " ['chr10', (5892886, 5893424)],\n",
              " ['chr10', (5893509, 5893618)],\n",
              " ['chr10', (5893852, 5894048)],\n",
              " ['chr10', (5894175, 5894833)],\n",
              " ['chr10', (5894938, 5896237)],\n",
              " ['chr10', (5896288, 5900496)],\n",
              " ['chr10', (5900545, 5903019)],\n",
              " ['chr10', (5903302, 5905879)],\n",
              " ['chr10', (5905941, 5905975)],\n",
              " ['chr10', (5906095, 5906486)],\n",
              " ['chr10', (5906548, 5906587)],\n",
              " ['chr10', (5906632, 5908924)],\n",
              " ['chr10', (5909053, 5909161)],\n",
              " ['chr10', (5909471, 5910888)],\n",
              " ['chr10', (5910963, 5911126)],\n",
              " ['chr10', (5911180, 5912857)],\n",
              " ['chr10', (5913096, 5913844)],\n",
              " ['chr10', (5913926, 5914238)],\n",
              " ['chr10', (5914314, 5915477)],\n",
              " ['chr10', (5915562, 5916262)],\n",
              " ['chr10', (5916310, 5916367)],\n",
              " ['chr10', (5916439, 5916726)],\n",
              " ['chr10', (5916877, 5916890)],\n",
              " ['chr10', (5916935, 5917420)],\n",
              " ['chr10', (5917545, 5917620)],\n",
              " ['chr10', (5917680, 5918478)],\n",
              " ['chr10', (5918520, 5921454)],\n",
              " ['chr10', (5921633, 5923629)],\n",
              " ['chr10', (5923746, 5924335)],\n",
              " ['chr10', (5924556, 5925319)],\n",
              " ['chr10', (5925403, 5925433)],\n",
              " ['chr10', (5925490, 5925569)],\n",
              " ['chr10', (5925617, 5927462)],\n",
              " ['chr10', (5927512, 5927524)],\n",
              " ['chr10', (5927583, 5936455)],\n",
              " ['chr10', (5936580, 5936585)],\n",
              " ['chr10', (5936634, 5937365)],\n",
              " ['chr10', (5937506, 5952721)],\n",
              " ['chr10', (5952917, 5960366)],\n",
              " ['chr10', (5960563, 6089032)],\n",
              " ['chr10', (6089316, 6089422)],\n",
              " ['chr10', (6089611, 6091625)],\n",
              " ['chr10', (6091787, 6096206)],\n",
              " ['chr10', (6096280, 6096984)],\n",
              " ['chr10', (6097188, 6101284)],\n",
              " ['chr10', (6101423, 6104073)],\n",
              " ['chr10', (6104156, 6104929)],\n",
              " ['chr10', (6104947, 6105073)],\n",
              " ['chr10', (6105100, 6105824)],\n",
              " ['chr10', (6105875, 6105959)],\n",
              " ['chr10', (6106044, 6106140)],\n",
              " ['chr10', (6106248, 6106444)],\n",
              " ['chr10', (6106491, 6108008)],\n",
              " ['chr10', (6108116, 6108373)],\n",
              " ['chr10', (6108476, 6108595)],\n",
              " ['chr10', (6108854, 6109999)],\n",
              " ['chr10', (6110061, 6112165)],\n",
              " ['chr10', (6112409, 6112459)],\n",
              " ['chr10', (6112550, 6113451)],\n",
              " ['chr10', (6113624, 6113902)],\n",
              " ['chr10', (6113966, 6114028)],\n",
              " ['chr10', (6114148, 6114212)],\n",
              " ['chr10', (6114280, 6115079)],\n",
              " ['chr10', (6115165, 6115188)],\n",
              " ['chr10', (6115358, 6115446)],\n",
              " ['chr10', (6115561, 6145280)],\n",
              " ['chr10', (6145445, 6146038)],\n",
              " ['chr10', (6146172, 6146175)],\n",
              " ['chr10', (6146421, 6149672)],\n",
              " ['chr10', (6149725, 6154738)],\n",
              " ['chr10', (6154884, 6163872)],\n",
              " ['chr10', (6163993, 6164018)],\n",
              " ['chr10', (6164307, 6166516)],\n",
              " ['chr10', (6166652, 6169428)],\n",
              " ['chr10', (6169487, 6169579)],\n",
              " ['chr10', (6169646, 6169651)],\n",
              " ['chr10', (6169693, 6169745)],\n",
              " ['chr10', (6169783, 6172009)],\n",
              " ['chr10', (6172099, 6172278)],\n",
              " ['chr10', (6172351, 6174205)],\n",
              " ['chr10', (6174244, 6174309)],\n",
              " ['chr10', (6174353, 6174376)],\n",
              " ['chr10', (6174435, 6174499)],\n",
              " ['chr10', (6174547, 6174579)],\n",
              " ['chr10', (6174656, 6175381)],\n",
              " ['chr10', (6175498, 6175924)],\n",
              " ['chr10', (6176028, 6176282)],\n",
              " ['chr10', (6176388, 6176733)],\n",
              " ['chr10', (6176804, 6177702)],\n",
              " ['chr10', (6177768, 6177861)],\n",
              " ['chr10', (6178119, 6178270)],\n",
              " ['chr10', (6178325, 6179573)],\n",
              " ['chr10', (6179636, 6201260)],\n",
              " ['chr10', (6201322, 6202392)],\n",
              " ['chr10', (6202459, 6203817)],\n",
              " ['chr10', (6203962, 6213715)],\n",
              " ['chr10', (6213784, 6216187)],\n",
              " ['chr10', (6216230, 6217191)],\n",
              " ['chr10', (6217275, 6219550)],\n",
              " ['chr10', (6219717, 6221643)],\n",
              " ['chr10', (6221706, 6222876)],\n",
              " ['chr10', (6222957, 6224190)],\n",
              " ['chr10', (6224254, 6226407)],\n",
              " ['chr10', (6226562, 6232985)],\n",
              " ['chr10', (6233211, 6233368)],\n",
              " ['chr10', (6233441, 6233505)],\n",
              " ['chr10', (6233569, 6233620)],\n",
              " ['chr10', (6233681, 6234365)],\n",
              " ['chr10', (6234446, 6234703)],\n",
              " ['chr10', (6234785, 6234896)],\n",
              " ['chr10', (6234924, 6235035)],\n",
              " ['chr10', (6235087, 6235136)],\n",
              " ['chr10', (6235190, 6235323)],\n",
              " ['chr10', (6235437, 6235485)],\n",
              " ['chr10', (6235529, 6427161)],\n",
              " ['chr10', (6427239, 6510998)],\n",
              " ['chr10', (6511124, 6570408)],\n",
              " ['chr10', (6570459, 6577716)],\n",
              " ['chr10', (6577818, 6580494)],\n",
              " ['chr10', (6580653, 6581028)],\n",
              " ['chr10', (6581141, 6583728)],\n",
              " ['chr10', (6583870, 7160979)],\n",
              " ['chr10', (7161038, 7163249)],\n",
              " ['chr10', (7163335, 7163401)],\n",
              " ['chr10', (7163523, 7163543)],\n",
              " ['chr10', (7163607, 7164688)],\n",
              " ['chr10', (7164765, 7171851)],\n",
              " ['chr10', (7171894, 7172443)],\n",
              " ['chr10', (7172493, 7205770)],\n",
              " ['chr10', (7205864, 7205893)],\n",
              " ['chr10', (7205944, 7207317)],\n",
              " ['chr10', (7207391, 7219891)],\n",
              " ['chr10', (7220049, 7220526)],\n",
              " ['chr10', (7220588, 7223039)],\n",
              " ['chr10', (7223114, 7227883)],\n",
              " ['chr10', (7227938, 7235163)],\n",
              " ['chr10', (7235205, 7235452)],\n",
              " ['chr10', (7235648, 7236276)],\n",
              " ['chr10', (7236336, 7237910)],\n",
              " ['chr10', (7238025, 7275430)],\n",
              " ['chr10', (7275518, 7276832)],\n",
              " ['chr10', (7276989, 7283374)],\n",
              " ['chr10', (7283487, 7283794)],\n",
              " ['chr10', (7283852, 7284211)],\n",
              " ['chr10', (7284322, 7284353)],\n",
              " ['chr10', (7284433, 7285178)],\n",
              " ['chr10', (7285258, 7285857)],\n",
              " ['chr10', (7285950, 7285990)],\n",
              " ['chr10', (7286102, 7297804)],\n",
              " ['chr10', (7297872, 7298518)],\n",
              " ['chr10', (7298748, 7314863)],\n",
              " ['chr10', (7314945, 7316549)],\n",
              " ['chr10', (7316656, 7316843)],\n",
              " ['chr10', (7316906, 7319614)],\n",
              " ['chr10', (7319749, 7319778)],\n",
              " ['chr10', (7320038, 7324050)],\n",
              " ['chr10', (7324176, 7335492)],\n",
              " ['chr10', (7335604, 7336607)],\n",
              " ['chr10', (7336668, 7350249)],\n",
              " ['chr10', (7350362, 7350435)],\n",
              " ['chr10', (7350519, 7354454)],\n",
              " ['chr10', (7354518, 7354538)],\n",
              " ['chr10', (7354710, 7355353)],\n",
              " ['chr10', (7355448, 7358139)],\n",
              " ['chr10', (7358275, 7364360)],\n",
              " ['chr10', (7364440, 7366081)],\n",
              " ['chr10', (7366198, 7367646)],\n",
              " ['chr10', (7367822, 7367825)],\n",
              " ['chr10', (7367890, 7370277)],\n",
              " ['chr10', (7370376, 7370827)],\n",
              " ['chr10', (7370915, 7375701)],\n",
              " ['chr10', (7375774, 7375814)],\n",
              " ['chr10', (7375840, 7375872)],\n",
              " ['chr10', (7375919, 7376019)],\n",
              " ['chr10', (7376111, 7376183)],\n",
              " ['chr10', (7376321, 7376378)],\n",
              " ['chr10', (7376433, 7376665)],\n",
              " ['chr10', (7376701, 7376815)],\n",
              " ['chr10', (7376860, 7377773)],\n",
              " ['chr10', (7378165, 7378536)],\n",
              " ['chr10', (7378672, 7378703)],\n",
              " ['chr10', (7379088, 7379320)],\n",
              " ['chr10', (7379360, 7379513)],\n",
              " ['chr10', (7379586, 7379607)],\n",
              " ['chr10', (7379654, 7379789)],\n",
              " ['chr10', (7379852, 7381009)],\n",
              " ['chr10', (7381106, 7381798)],\n",
              " ['chr10', (7381945, 7407614)],\n",
              " ['chr10', (7407678, 7407843)],\n",
              " ['chr10', (7407899, 7407938)],\n",
              " ['chr10', (7407989, 7408309)],\n",
              " ['chr10', (7408387, 7408734)],\n",
              " ['chr10', (7408817, 7408934)],\n",
              " ['chr10', (7409014, 7409281)],\n",
              " ['chr10', (7409348, 7409559)],\n",
              " ['chr10', (7409644, 7409884)],\n",
              " ['chr10', (7409967, 7410276)],\n",
              " ['chr10', (7410330, 7410632)],\n",
              " ['chr10', (7410690, 7410862)],\n",
              " ['chr10', (7411019, 7628428)],\n",
              " ['chr10', (7628549, 7666837)],\n",
              " ['chr10', (7666983, 7703338)],\n",
              " ['chr10', (7703442, 7705110)],\n",
              " ['chr10', (7705149, 7705152)],\n",
              " ['chr10', (7705210, 7707180)],\n",
              " ['chr10', (7707235, 7708886)],\n",
              " ['chr10', (7708918, 7709056)],\n",
              " ['chr10', (7709144, 7709187)],\n",
              " ['chr10', (7709191, 7713181)],\n",
              " ['chr10', (7713209, 7713224)],\n",
              " ['chr10', (7713257, 7713259)],\n",
              " ['chr10', (7713285, 7713331)],\n",
              " ['chr10', (7713400, 7717563)],\n",
              " ['chr10', (7717622, 7717625)],\n",
              " ['chr10', (7717647, 7717671)],\n",
              " ['chr10', (7717830, 7717847)],\n",
              " ['chr10', (7717897, 7718669)],\n",
              " ['chr10', (7718721, 7718729)],\n",
              " ['chr10', (7718775, 7718894)],\n",
              " ['chr10', (7718952, 7720124)],\n",
              " ['chr10', (7720249, 7720855)],\n",
              " ['chr10', (7720863, 7720879)],\n",
              " ['chr10', (7720885, 7720945)],\n",
              " ['chr10', (7720963, 7721542)],\n",
              " ['chr10', (7721596, 7721625)],\n",
              " ['chr10', (7721642, 7721648)],\n",
              " ['chr10', (7721679, 7721690)],\n",
              " ['chr10', (7721736, 7721756)],\n",
              " ...]"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_negative_samples "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j-wzSxrmRnI4"
      },
      "outputs": [],
      "source": [
        "def get_negative_sample(negative_samples, context_length):\n",
        "    idx = random.randint(0, len(negative_samples)-1)\n",
        "    sample = negative_samples[idx]\n",
        "    \n",
        "    chrom = sample[0]\n",
        "    start, end = sample[1]\n",
        "    \n",
        "    if start < end-context_length+1:\n",
        "        rand_start = random.randint(start, end-context_length+1)\n",
        "        return [chrom, (rand_start, rand_start+context_length)]  \n",
        "    else:\n",
        "        midpoint = int(.5 * (start + end))\n",
        "        return [chrom, (midpoint - context_length//2, midpoint + context_length//2)] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo4V9vfeRnI4"
      },
      "outputs": [],
      "source": [
        "def get_positive_label(target, target_to_idx):\n",
        "    return target_to_idx[target] \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3pFtL5TLShWr"
      },
      "outputs": [],
      "source": [
        "def mtx_to_idx_label(mtx):\n",
        "  indices = torch.zeros(mtx.shape[0], dtype=torch.int)\n",
        "  for i in range(mtx.shape[0]):\n",
        "    row = mtx[i,:]\n",
        "    indices[i] = list(row).index(1)\n",
        "\n",
        "  return indices \n",
        "  "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Multiclass Classification"
      ],
      "metadata": {
        "id": "XBdcJkIwSYbi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaGdhdkn_-sW"
      },
      "source": [
        "### Base Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sRnVGzTIADFe"
      },
      "outputs": [],
      "source": [
        "class BedPeaksDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "    def __init__(self, eclip_data, genome, context_length, target_to_idx):\n",
        "        super(BedPeaksDataset, self).__init__()\n",
        "        self.eclip_data = eclip_data\n",
        "        self.genome = genome\n",
        "        self.context_length = context_length\n",
        "        self.target_to_idx = target_to_idx \n",
        "\n",
        "    def __iter__(self): \n",
        "        for i,row in enumerate(self.eclip_data.itertuples()):\n",
        "            midpoint = int(.5 * (row.start + row.end))\n",
        "            seq = self.genome[row.chr][midpoint - self.context_length//2:midpoint + self.context_length//2]\n",
        "            if row.strand == '-':\n",
        "              seq = strand_normalize(seq)\n",
        "            yield(one_hot(seq), get_positive_label(row.target, self.target_to_idx)) \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.eclip_data.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Bz_vZWJqAIr"
      },
      "outputs": [],
      "source": [
        "context_length = 100\n",
        "\n",
        "encode_train_dataset = BedPeaksDataset(encode_train, genome, context_length, target_to_idx)\n",
        "encode_train_dataloader = torch.utils.data.DataLoader(encode_train_dataset, batch_size=1028, num_workers = 0) \n",
        "\n",
        "encode_val_dataset = BedPeaksDataset(encode_val, genome, context_length, target_to_idx)\n",
        "encode_val_dataloader = torch.utils.data.DataLoader(encode_val_dataset, batch_size=1028)\n",
        "\n",
        "encode_test_dataset = BedPeaksDataset(encode_test, genome, context_length, target_to_idx)\n",
        "encodetest_dataloader = torch.utils.data.DataLoader(encode_test_dataset, batch_size=1028) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOxSXNpYl8ET"
      },
      "source": [
        "### Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BeMqz06vl2Ht"
      },
      "outputs": [],
      "source": [
        "class ConvBasicNet(nn.Module): \n",
        "\n",
        "    def __init__(self, padding=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.padding = padding\n",
        "        self.conv_model = self.get_conv_layers()\n",
        "        self.final_max_pool = self.final_pool_layer()\n",
        "        self.fc_model = self.get_fc_layers()\n",
        "\n",
        "    def get_conv_layers(self):\n",
        "        \n",
        "        layers = nn.Sequential(\n",
        "            nn.Conv1d(4, 32, 5),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.MaxPool1d(2, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 16, 5),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.MaxPool1d(2, 2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def final_pool_layer(self):\n",
        "        \n",
        "        layer = nn.MaxPool1d(2, 2) \n",
        "        \n",
        "        return layer\n",
        "\n",
        "    def get_fc_layers(self):\n",
        "        \n",
        "        if self.padding==False:\n",
        "          layers = nn.Sequential(\n",
        "              nn.Linear(176, 512),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(512, 1024),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(1024, 150)\n",
        "          )\n",
        "\n",
        "        elif self.padding:\n",
        "          layers = nn.Sequential(\n",
        "              nn.Linear(912, 1024),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(1024, 2048),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(2048, 150)\n",
        "          )\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def register_grad_hook(self, grad):\n",
        "        self.grad = grad \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_model(x) \n",
        "        h = x.register_hook(self.register_grad_hook)\n",
        "\n",
        "        x = self.final_max_pool(x)\n",
        "        x = nn.Flatten()(x) \n",
        "        x = self.fc_model(x)\n",
        "\n",
        "        return x    \n",
        "\n",
        "    def get_gradient_activations(self):\n",
        "        return self.grad\n",
        "\n",
        "    def get_final_conv_layer(self, x):\n",
        "        return self.conv_model(x) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrDgdrh-l8av"
      },
      "outputs": [],
      "source": [
        "class Classifier():\n",
        "\n",
        "    def __init__(self, name, model, dataloaders, class_names, use_cuda=False):\n",
        "        \n",
        "        '''\n",
        "        @name: Experiment name. Will define stored results etc. \n",
        "        @model: GradBasicNet()\n",
        "        @dataloaders: Dictionary with keys train, val and test and corresponding dataloaders\n",
        "        @class_names: list of classes, where the idx of class name corresponds to the label used for it in the data\n",
        "        @use_cuda: whether or not to use cuda\n",
        "        '''\n",
        "        \n",
        "        self.name = name\n",
        "        if use_cuda and not torch.cuda.is_available():\n",
        "            raise Exception(\"Asked for CUDA but GPU not found\")\n",
        "            \n",
        "        self.use_cuda = use_cuda\n",
        "        self.model = model.to('cuda' if use_cuda else 'cpu')\n",
        "\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.optim = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "        self.dataloaders = dataloaders \n",
        "        self.class_names = class_names\n",
        "        self.activations_path = os.path.join('activations', self.name)\n",
        "        self.kernel_path = os.path.join('kernel_viz', self.name)\n",
        "\n",
        "        save_path = os.path.join(os.getcwd(), 'models', self.name)\n",
        "        if not os.path.exists(save_path):\n",
        "            os.makedirs(save_path)\n",
        "\n",
        "        if not os.path.exists(self.activations_path):\n",
        "            os.makedirs(self.activations_path)\n",
        "\n",
        "        if not os.path.exists(self.kernel_path):\n",
        "            os.makedirs(self.kernel_path)\n",
        "            \n",
        "        self.save_path = save_path\n",
        "\n",
        "    def train(self, epochs, save=True):\n",
        "        '''\n",
        "        @epochs: number of epochs to train\n",
        "        @save: whether or not to save the checkpoints\n",
        "        '''\n",
        "\n",
        "        self.epoch_accuracies = list()\n",
        "\n",
        "        best_val_accuracy = - math.inf\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "\n",
        "            self.model.train()\n",
        "\n",
        "            batches_in_pass = len(self.dataloaders['train'])\n",
        "            \n",
        "            epoch_loss = 0.0 # Record the total loss for each epoch\n",
        "            \n",
        "            for idx, data in enumerate(self.dataloaders['train']):\n",
        "               \n",
        "              inputs, labels = data\n",
        "            \n",
        "              inputs = inputs.to('cuda', dtype=torch.float if self.use_cuda else 'cpu') \n",
        "              labels = labels.to('cuda', dtype=torch.int64 if self.use_cuda else 'cpu')\n",
        "            \n",
        "              outputs = self.model(inputs)            \n",
        "              train_loss = self.criterion(outputs, labels)\n",
        "\n",
        "              epoch_loss += train_loss \n",
        "\n",
        "              self.optim.zero_grad()\n",
        "              train_loss.backward() \n",
        "              self.optim.step()\n",
        "\n",
        "            '''Give validation'''\n",
        "            epoch_loss /= batches_in_pass\n",
        "\n",
        "            self.model.eval()\n",
        "            \n",
        "            #DO NOT modify this part\n",
        "            correct = 0.0\n",
        "            total = 0.0\n",
        "            for idx, data in enumerate(self.dataloaders['val']):\n",
        "\n",
        "                inputs, labels = data\n",
        "                \n",
        "                inputs = inputs.to('cuda', dtype=torch.float if self.use_cuda else 'cpu')\n",
        "                labels = labels.to('cuda', dtype=torch.int64 if self.use_cuda else 'cpu')\n",
        "\n",
        "                outputs = self.model(inputs)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "                total += labels.shape[0]\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "            epoch_accuracy = 100 * correct / total\n",
        "            \n",
        "            self.epoch_accuracies.append(epoch_accuracy)\n",
        "            \n",
        "            print(f'Train Epoch Loss (Avg): {epoch_loss}')\n",
        "            print(f'Validation Epoch Accuracy:{epoch_accuracy}')\n",
        "            \n",
        "            if save:\n",
        "                \n",
        "                torch.save(self.model.state_dict(), os.path.join(self.save_path, f'epoch_{epoch}.pt'))\n",
        "                \n",
        "                if epoch_accuracy > best_val_accuracy:\n",
        "\n",
        "                    torch.save(self.model.state_dict(), os.path.join(self.save_path, 'best.pt'))\n",
        "                    print('save model', os.path.join(self.save_path, f'epoch_{epoch}.pt'))\n",
        "                    best_val_accuracy = epoch_accuracy\n",
        "\n",
        "        print('Finish training!')                       \n",
        "\n",
        "    \n",
        "    def evaluate(self):\n",
        "        \n",
        "        try:\n",
        "            assert os.path.exists(os.path.join(self.save_path, 'best.pt'))\n",
        "            \n",
        "        except:\n",
        "            print('It appears you are testing the model without training. Please train first')\n",
        "            return\n",
        "        \n",
        "        self.model.load_state_dict(torch.load(os.path.join(self.save_path, 'best.pt')))\n",
        "        self.model.eval()\n",
        "\n",
        "        total = len(self.dataloaders['test'])\n",
        "        \n",
        "        correct = 0.0\n",
        "        total = 0.0\n",
        "        for idx, data in enumerate(self.dataloaders['test']):\n",
        "            \n",
        "            inputs, labels = data\n",
        "            inputs = inputs.to('cuda', dtype=torch.float if self.use_cuda else 'cpu')\n",
        "            labels = labels.to('cuda', dtype=torch.int64 if self.use_cuda else 'cpu')\n",
        "\n",
        "            outputs = self.model(inputs)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "            total += labels.shape[0]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "                \n",
        "        print(f'Accuracy: {100 * correct/total}%')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DwEGAf1ol8uS"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'basic' \n",
        "model_name = 'basic' \n",
        "\n",
        "dataloaders = {'train': encode_train_dataloader, 'val' : encode_val_dataloader, 'test': encode_train_dataloader, 'mapping': target_set}\n",
        "model = ConvBasicNet()\n",
        "classifier1 = Classifier(experiment_name, model, dataloaders, target_set, use_cuda=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1IeO1YnlRnI5",
        "outputId": "c061f84d-9c38-4cb8-d7bf-e565c7b9fd63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch Loss (Avg): 4.414685249328613\n",
            "Validation Epoch Accuracy:11.560257949247648\n",
            "save model /home/wh2500/models/basic/epoch_0.pt\n",
            "Train Epoch Loss (Avg): 4.1142897605896\n",
            "Validation Epoch Accuracy:14.84045671533458\n",
            "save model /home/wh2500/models/basic/epoch_1.pt\n",
            "Train Epoch Loss (Avg): 3.920497179031372\n",
            "Validation Epoch Accuracy:15.877092580702195\n",
            "save model /home/wh2500/models/basic/epoch_2.pt\n",
            "Train Epoch Loss (Avg): 3.8512961864471436\n",
            "Validation Epoch Accuracy:16.260480351376753\n",
            "save model /home/wh2500/models/basic/epoch_3.pt\n",
            "Train Epoch Loss (Avg): 3.8104710578918457\n",
            "Validation Epoch Accuracy:16.669923601611718\n",
            "save model /home/wh2500/models/basic/epoch_4.pt\n",
            "Train Epoch Loss (Avg): 3.7773847579956055\n",
            "Validation Epoch Accuracy:17.03376976261597\n",
            "save model /home/wh2500/models/basic/epoch_5.pt\n",
            "Train Epoch Loss (Avg): 3.747227907180786\n",
            "Validation Epoch Accuracy:17.44786577705815\n",
            "save model /home/wh2500/models/basic/epoch_6.pt\n",
            "Train Epoch Loss (Avg): 3.718804359436035\n",
            "Validation Epoch Accuracy:17.804267515330856\n",
            "save model /home/wh2500/models/basic/epoch_7.pt\n",
            "Train Epoch Loss (Avg): 3.6923160552978516\n",
            "Validation Epoch Accuracy:18.169974782018\n",
            "save model /home/wh2500/models/basic/epoch_8.pt\n",
            "Train Epoch Loss (Avg): 3.668530225753784\n",
            "Validation Epoch Accuracy:18.580348585094406\n",
            "save model /home/wh2500/models/basic/epoch_9.pt\n",
            "Train Epoch Loss (Avg): 3.6478898525238037\n",
            "Validation Epoch Accuracy:18.841833933539917\n",
            "save model /home/wh2500/models/basic/epoch_10.pt\n",
            "Train Epoch Loss (Avg): 3.6300599575042725\n",
            "Validation Epoch Accuracy:19.13402752575305\n",
            "save model /home/wh2500/models/basic/epoch_11.pt\n",
            "Train Epoch Loss (Avg): 3.6143910884857178\n",
            "Validation Epoch Accuracy:19.382485134418356\n",
            "save model /home/wh2500/models/basic/epoch_12.pt\n",
            "Train Epoch Loss (Avg): 3.600412130355835\n",
            "Validation Epoch Accuracy:19.58999841806017\n",
            "save model /home/wh2500/models/basic/epoch_13.pt\n",
            "Train Epoch Loss (Avg): 3.5878493785858154\n",
            "Validation Epoch Accuracy:19.76959511645869\n",
            "save model /home/wh2500/models/basic/epoch_14.pt\n",
            "Train Epoch Loss (Avg): 3.5764665603637695\n",
            "Validation Epoch Accuracy:19.883122563114746\n",
            "save model /home/wh2500/models/basic/epoch_15.pt\n",
            "Train Epoch Loss (Avg): 3.566075325012207\n",
            "Validation Epoch Accuracy:19.975247294417613\n",
            "save model /home/wh2500/models/basic/epoch_16.pt\n",
            "Train Epoch Loss (Avg): 3.5565860271453857\n",
            "Validation Epoch Accuracy:20.085052529707898\n",
            "save model /home/wh2500/models/basic/epoch_17.pt\n",
            "Train Epoch Loss (Avg): 3.5478224754333496\n",
            "Validation Epoch Accuracy:20.152052334291803\n",
            "save model /home/wh2500/models/basic/epoch_18.pt\n",
            "Train Epoch Loss (Avg): 3.5396361351013184\n",
            "Validation Epoch Accuracy:20.223704903082922\n",
            "save model /home/wh2500/models/basic/epoch_19.pt\n",
            "Train Epoch Loss (Avg): 3.5319833755493164\n",
            "Validation Epoch Accuracy:20.260927016740645\n",
            "save model /home/wh2500/models/basic/epoch_20.pt\n",
            "Train Epoch Loss (Avg): 3.524815082550049\n",
            "Validation Epoch Accuracy:20.300010236081256\n",
            "save model /home/wh2500/models/basic/epoch_21.pt\n",
            "Train Epoch Loss (Avg): 3.51806640625\n",
            "Validation Epoch Accuracy:20.378176674762475\n",
            "save model /home/wh2500/models/basic/epoch_22.pt\n",
            "Train Epoch Loss (Avg): 3.5116372108459473\n",
            "Validation Epoch Accuracy:20.422843211151744\n",
            "save model /home/wh2500/models/basic/epoch_23.pt\n",
            "Train Epoch Loss (Avg): 3.5054893493652344\n",
            "Validation Epoch Accuracy:20.47867638163833\n",
            "save model /home/wh2500/models/basic/epoch_24.pt\n",
            "Train Epoch Loss (Avg): 3.499633312225342\n",
            "Validation Epoch Accuracy:20.558703926002437\n",
            "save model /home/wh2500/models/basic/epoch_25.pt\n",
            "Train Epoch Loss (Avg): 3.4940667152404785\n",
            "Validation Epoch Accuracy:20.62291207206201\n",
            "save model /home/wh2500/models/basic/epoch_26.pt\n",
            "Train Epoch Loss (Avg): 3.488745927810669\n",
            "Validation Epoch Accuracy:20.681536901072928\n",
            "save model /home/wh2500/models/basic/epoch_27.pt\n",
            "Train Epoch Loss (Avg): 3.483642816543579\n",
            "Validation Epoch Accuracy:20.735508965876626\n",
            "save model /home/wh2500/models/basic/epoch_28.pt\n",
            "Train Epoch Loss (Avg): 3.4787099361419678\n",
            "Validation Epoch Accuracy:20.750397811339717\n",
            "save model /home/wh2500/models/basic/epoch_29.pt\n",
            "Train Epoch Loss (Avg): 3.473966121673584\n",
            "Validation Epoch Accuracy:20.81460595739929\n",
            "save model /home/wh2500/models/basic/epoch_30.pt\n",
            "Train Epoch Loss (Avg): 3.4694321155548096\n",
            "Validation Epoch Accuracy:20.87695299777598\n",
            "save model /home/wh2500/models/basic/epoch_31.pt\n",
            "Train Epoch Loss (Avg): 3.4650752544403076\n",
            "Validation Epoch Accuracy:20.95791109498153\n",
            "save model /home/wh2500/models/basic/epoch_32.pt\n",
            "Train Epoch Loss (Avg): 3.4608654975891113\n",
            "Validation Epoch Accuracy:21.021188688199658\n",
            "save model /home/wh2500/models/basic/epoch_33.pt\n",
            "Train Epoch Loss (Avg): 3.4568307399749756\n",
            "Validation Epoch Accuracy:21.09656346835655\n",
            "save model /home/wh2500/models/basic/epoch_34.pt\n",
            "Train Epoch Loss (Avg): 3.452937364578247\n",
            "Validation Epoch Accuracy:21.14774387463592\n",
            "save model /home/wh2500/models/basic/epoch_35.pt\n",
            "Train Epoch Loss (Avg): 3.449178695678711\n",
            "Validation Epoch Accuracy:21.193340963866632\n",
            "save model /home/wh2500/models/basic/epoch_36.pt\n",
            "Train Epoch Loss (Avg): 3.4455409049987793\n",
            "Validation Epoch Accuracy:21.24638247582889\n",
            "save model /home/wh2500/models/basic/epoch_37.pt\n",
            "Train Epoch Loss (Avg): 3.4420156478881836\n",
            "Validation Epoch Accuracy:21.278021272437954\n",
            "save model /home/wh2500/models/basic/epoch_38.pt\n",
            "Train Epoch Loss (Avg): 3.438626766204834\n",
            "Validation Epoch Accuracy:21.33385444292454\n",
            "save model /home/wh2500/models/basic/epoch_39.pt\n",
            "Train Epoch Loss (Avg): 3.4353573322296143\n",
            "Validation Epoch Accuracy:21.380382084996697\n",
            "save model /home/wh2500/models/basic/epoch_40.pt\n",
            "Train Epoch Loss (Avg): 3.432159900665283\n",
            "Validation Epoch Accuracy:21.412951434447205\n",
            "save model /home/wh2500/models/basic/epoch_41.pt\n",
            "Train Epoch Loss (Avg): 3.429065704345703\n",
            "Validation Epoch Accuracy:21.4538957594707\n",
            "save model /home/wh2500/models/basic/epoch_42.pt\n",
            "Train Epoch Loss (Avg): 3.426042318344116\n",
            "Validation Epoch Accuracy:21.481812344713994\n",
            "save model /home/wh2500/models/basic/epoch_43.pt\n",
            "Train Epoch Loss (Avg): 3.42313289642334\n",
            "Validation Epoch Accuracy:21.509728929957287\n",
            "save model /home/wh2500/models/basic/epoch_44.pt\n",
            "Train Epoch Loss (Avg): 3.420290946960449\n",
            "Validation Epoch Accuracy:21.521826116896047\n",
            "save model /home/wh2500/models/basic/epoch_45.pt\n",
            "Train Epoch Loss (Avg): 3.417510509490967\n",
            "Validation Epoch Accuracy:21.5618398890781\n",
            "save model /home/wh2500/models/basic/epoch_46.pt\n",
            "Train Epoch Loss (Avg): 3.414792537689209\n",
            "Validation Epoch Accuracy:21.591617580004282\n",
            "save model /home/wh2500/models/basic/epoch_47.pt\n",
            "Train Epoch Loss (Avg): 3.412114143371582\n",
            "Validation Epoch Accuracy:21.59720089705294\n",
            "save model /home/wh2500/models/basic/epoch_48.pt\n",
            "Train Epoch Loss (Avg): 3.409503698348999\n",
            "Validation Epoch Accuracy:21.641867433442208\n",
            "save model /home/wh2500/models/basic/epoch_49.pt\n",
            "Train Epoch Loss (Avg): 3.406938314437866\n",
            "Validation Epoch Accuracy:21.68095065278282\n",
            "save model /home/wh2500/models/basic/epoch_50.pt\n",
            "Train Epoch Loss (Avg): 3.4044244289398193\n",
            "Validation Epoch Accuracy:21.70514502666034\n",
            "save model /home/wh2500/models/basic/epoch_51.pt\n",
            "Train Epoch Loss (Avg): 3.4019522666931152\n",
            "Validation Epoch Accuracy:21.747019904525278\n",
            "save model /home/wh2500/models/basic/epoch_52.pt\n",
            "Train Epoch Loss (Avg): 3.399538278579712\n",
            "Validation Epoch Accuracy:21.773075384085686\n",
            "save model /home/wh2500/models/basic/epoch_53.pt\n",
            "Train Epoch Loss (Avg): 3.397148609161377\n",
            "Validation Epoch Accuracy:21.791686440914546\n",
            "save model /home/wh2500/models/basic/epoch_54.pt\n",
            "Train Epoch Loss (Avg): 3.394784450531006\n",
            "Validation Epoch Accuracy:21.802853075011864\n",
            "save model /home/wh2500/models/basic/epoch_55.pt\n",
            "Train Epoch Loss (Avg): 3.3924720287323\n",
            "Validation Epoch Accuracy:21.820533578999285\n",
            "save model /home/wh2500/models/basic/epoch_56.pt\n",
            "Train Epoch Loss (Avg): 3.3902008533477783\n",
            "Validation Epoch Accuracy:21.8251863432065\n",
            "save model /home/wh2500/models/basic/epoch_57.pt\n",
            "Train Epoch Loss (Avg): 3.3879594802856445\n",
            "Validation Epoch Accuracy:21.848450164242575\n",
            "save model /home/wh2500/models/basic/epoch_58.pt\n",
            "Train Epoch Loss (Avg): 3.3857500553131104\n",
            "Validation Epoch Accuracy:21.88288061937597\n",
            "save model /home/wh2500/models/basic/epoch_59.pt\n",
            "Train Epoch Loss (Avg): 3.383553981781006\n",
            "Validation Epoch Accuracy:21.90428333472916\n",
            "save model /home/wh2500/models/basic/epoch_60.pt\n",
            "Train Epoch Loss (Avg): 3.381404161453247\n",
            "Validation Epoch Accuracy:21.92754715576524\n",
            "save model /home/wh2500/models/basic/epoch_61.pt\n",
            "Train Epoch Loss (Avg): 3.3792734146118164\n",
            "Validation Epoch Accuracy:21.95732484669142\n",
            "save model /home/wh2500/models/basic/epoch_62.pt\n",
            "Train Epoch Loss (Avg): 3.3771800994873047\n",
            "Validation Epoch Accuracy:22.01222746433656\n",
            "save model /home/wh2500/models/basic/epoch_63.pt\n",
            "Train Epoch Loss (Avg): 3.3751258850097656\n",
            "Validation Epoch Accuracy:22.021532992750995\n",
            "save model /home/wh2500/models/basic/epoch_64.pt\n",
            "Train Epoch Loss (Avg): 3.373110771179199\n",
            "Validation Epoch Accuracy:22.05038013083573\n",
            "save model /home/wh2500/models/basic/epoch_65.pt\n",
            "Train Epoch Loss (Avg): 3.371143341064453\n",
            "Validation Epoch Accuracy:22.07178284618892\n",
            "save model /home/wh2500/models/basic/epoch_66.pt\n",
            "Train Epoch Loss (Avg): 3.369206666946411\n",
            "Validation Epoch Accuracy:22.114588276895304\n",
            "save model /home/wh2500/models/basic/epoch_67.pt\n",
            "Train Epoch Loss (Avg): 3.3672831058502197\n",
            "Validation Epoch Accuracy:22.125754910992622\n",
            "save model /home/wh2500/models/basic/epoch_68.pt\n",
            "Train Epoch Loss (Avg): 3.365377187728882\n",
            "Validation Epoch Accuracy:22.14343541498004\n",
            "save model /home/wh2500/models/basic/epoch_69.pt\n",
            "Train Epoch Loss (Avg): 3.363494873046875\n",
            "Validation Epoch Accuracy:22.165768683174672\n",
            "save model /home/wh2500/models/basic/epoch_70.pt\n",
            "Train Epoch Loss (Avg): 3.3616220951080322\n",
            "Validation Epoch Accuracy:22.20019913830807\n",
            "save model /home/wh2500/models/basic/epoch_71.pt\n",
            "Train Epoch Loss (Avg): 3.359768867492676\n",
            "Validation Epoch Accuracy:22.223462959344147\n",
            "save model /home/wh2500/models/basic/epoch_72.pt\n",
            "Train Epoch Loss (Avg): 3.3579659461975098\n",
            "Validation Epoch Accuracy:22.25417120311177\n",
            "save model /home/wh2500/models/basic/epoch_73.pt\n",
            "Train Epoch Loss (Avg): 3.3561618328094482\n",
            "Validation Epoch Accuracy:22.297907186659593\n",
            "save model /home/wh2500/models/basic/epoch_74.pt\n",
            "Train Epoch Loss (Avg): 3.3543901443481445\n",
            "Validation Epoch Accuracy:22.304421056549696\n",
            "save model /home/wh2500/models/basic/epoch_75.pt\n",
            "Train Epoch Loss (Avg): 3.3526318073272705\n",
            "Validation Epoch Accuracy:22.312796032122684\n",
            "save model /home/wh2500/models/basic/epoch_76.pt\n",
            "Train Epoch Loss (Avg): 3.3508572578430176\n",
            "Validation Epoch Accuracy:22.33512930031732\n",
            "save model /home/wh2500/models/basic/epoch_77.pt\n",
            "Train Epoch Loss (Avg): 3.3491060733795166\n",
            "Validation Epoch Accuracy:22.366768096926386\n",
            "save model /home/wh2500/models/basic/epoch_78.pt\n",
            "Train Epoch Loss (Avg): 3.3473687171936035\n",
            "Validation Epoch Accuracy:22.403059657742666\n",
            "save model /home/wh2500/models/basic/epoch_79.pt\n",
            "Train Epoch Loss (Avg): 3.3456311225891113\n",
            "Validation Epoch Accuracy:22.42818458446163\n",
            "save model /home/wh2500/models/basic/epoch_80.pt\n",
            "Train Epoch Loss (Avg): 3.343907356262207\n",
            "Validation Epoch Accuracy:22.44679564129049\n",
            "save model /home/wh2500/models/basic/epoch_81.pt\n",
            "Train Epoch Loss (Avg): 3.342224597930908\n",
            "Validation Epoch Accuracy:22.459823381070695\n",
            "save model /home/wh2500/models/basic/epoch_82.pt\n",
            "Train Epoch Loss (Avg): 3.3405303955078125\n",
            "Validation Epoch Accuracy:22.48867051915543\n",
            "save model /home/wh2500/models/basic/epoch_83.pt\n",
            "Train Epoch Loss (Avg): 3.338827610015869\n",
            "Validation Epoch Accuracy:22.504489917459964\n",
            "save model /home/wh2500/models/basic/epoch_84.pt\n",
            "Train Epoch Loss (Avg): 3.337146759033203\n",
            "Validation Epoch Accuracy:22.526823185654596\n",
            "save model /home/wh2500/models/basic/epoch_85.pt\n",
            "Train Epoch Loss (Avg): 3.335458517074585\n",
            "Validation Epoch Accuracy:22.53426760838614\n",
            "save model /home/wh2500/models/basic/epoch_86.pt\n",
            "Train Epoch Loss (Avg): 3.3337786197662354\n",
            "Validation Epoch Accuracy:22.54822590100779\n",
            "save model /home/wh2500/models/basic/epoch_87.pt\n",
            "Train Epoch Loss (Avg): 3.332097291946411\n",
            "Validation Epoch Accuracy:22.550087006690674\n",
            "save model /home/wh2500/models/basic/epoch_88.pt\n",
            "Train Epoch Loss (Avg): 3.3304286003112793\n",
            "Validation Epoch Accuracy:22.57893414477541\n",
            "save model /home/wh2500/models/basic/epoch_89.pt\n",
            "Train Epoch Loss (Avg): 3.3287558555603027\n",
            "Validation Epoch Accuracy:22.60871183570159\n",
            "save model /home/wh2500/models/basic/epoch_90.pt\n",
            "Train Epoch Loss (Avg): 3.3270883560180664\n",
            "Validation Epoch Accuracy:22.610572941384476\n",
            "save model /home/wh2500/models/basic/epoch_91.pt\n",
            "Train Epoch Loss (Avg): 3.325422525405884\n",
            "Validation Epoch Accuracy:22.633836762420554\n",
            "save model /home/wh2500/models/basic/epoch_92.pt\n",
            "Train Epoch Loss (Avg): 3.3237504959106445\n",
            "Validation Epoch Accuracy:22.660822794822405\n",
            "save model /home/wh2500/models/basic/epoch_93.pt\n",
            "Train Epoch Loss (Avg): 3.3220925331115723\n",
            "Validation Epoch Accuracy:22.670128323236835\n",
            "save model /home/wh2500/models/basic/epoch_94.pt\n",
            "Train Epoch Loss (Avg): 3.320436716079712\n",
            "Validation Epoch Accuracy:22.70083656700446\n",
            "save model /home/wh2500/models/basic/epoch_95.pt\n",
            "Train Epoch Loss (Avg): 3.318756341934204\n",
            "Validation Epoch Accuracy:22.718517070991876\n",
            "save model /home/wh2500/models/basic/epoch_96.pt\n",
            "Train Epoch Loss (Avg): 3.3170852661132812\n",
            "Validation Epoch Accuracy:22.748294761918057\n",
            "save model /home/wh2500/models/basic/epoch_97.pt\n",
            "Train Epoch Loss (Avg): 3.3154029846191406\n",
            "Validation Epoch Accuracy:22.779003005685677\n",
            "save model /home/wh2500/models/basic/epoch_98.pt\n",
            "Train Epoch Loss (Avg): 3.3137073516845703\n",
            "Validation Epoch Accuracy:22.790169639782995\n",
            "save model /home/wh2500/models/basic/epoch_99.pt\n",
            "Finish training!\n",
            "Accuracy: 20.88633105734816%\n"
          ]
        }
      ],
      "source": [
        "classifier1.train(epochs=100)\n",
        "classifier1.evaluate() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zz0oukOmRnI5",
        "outputId": "11f22d04-d0fe-4e97-cc67-fcde6d13e0a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[11.560257949247648, 14.84045671533458, 15.877092580702195, 16.260480351376753, 16.669923601611718, 17.03376976261597, 17.44786577705815, 17.804267515330856, 18.169974782018, 18.580348585094406, 18.841833933539917, 19.13402752575305, 19.382485134418356, 19.58999841806017, 19.76959511645869, 19.883122563114746, 19.975247294417613, 20.085052529707898, 20.152052334291803, 20.223704903082922, 20.260927016740645, 20.300010236081256, 20.378176674762475, 20.422843211151744, 20.47867638163833, 20.558703926002437, 20.62291207206201, 20.681536901072928, 20.735508965876626, 20.750397811339717, 20.81460595739929, 20.87695299777598, 20.95791109498153, 21.021188688199658, 21.09656346835655, 21.14774387463592, 21.193340963866632, 21.24638247582889, 21.278021272437954, 21.33385444292454, 21.380382084996697, 21.412951434447205, 21.4538957594707, 21.481812344713994, 21.509728929957287, 21.521826116896047, 21.5618398890781, 21.591617580004282, 21.59720089705294, 21.641867433442208, 21.68095065278282, 21.70514502666034, 21.747019904525278, 21.773075384085686, 21.791686440914546, 21.802853075011864, 21.820533578999285, 21.8251863432065, 21.848450164242575, 21.88288061937597, 21.90428333472916, 21.92754715576524, 21.95732484669142, 22.01222746433656, 22.021532992750995, 22.05038013083573, 22.07178284618892, 22.114588276895304, 22.125754910992622, 22.14343541498004, 22.165768683174672, 22.20019913830807, 22.223462959344147, 22.25417120311177, 22.297907186659593, 22.304421056549696, 22.312796032122684, 22.33512930031732, 22.366768096926386, 22.403059657742666, 22.42818458446163, 22.44679564129049, 22.459823381070695, 22.48867051915543, 22.504489917459964, 22.526823185654596, 22.53426760838614, 22.54822590100779, 22.550087006690674, 22.57893414477541, 22.60871183570159, 22.610572941384476, 22.633836762420554, 22.660822794822405, 22.670128323236835, 22.70083656700446, 22.718517070991876, 22.748294761918057, 22.779003005685677, 22.790169639782995]\n"
          ]
        }
      ],
      "source": [
        "cnn_val_accs = classifier1.epoch_accuracies \n",
        "print(cnn_val_accs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jfeut63jqMni",
        "outputId": "468d4d80-d38b-4e12-89e3-74b3b4a21008"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'iDeepS'...\n",
            "remote: Enumerating objects: 9858, done.\u001b[K\n",
            "remote: Total 9858 (delta 0), reused 0 (delta 0), pack-reused 9858\u001b[K\n",
            "Receiving objects: 100% (9858/9858), 547.92 MiB | 12.15 MiB/s, done.\n",
            "Resolving deltas: 100% (3603/3603), done.\n",
            "Checking out files: 100% (3530/3530), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/xypan1232/iDeepS "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpWo7r6O1kDp"
      },
      "source": [
        "### CNN with various input lengths (padded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vxMmUdxx0nN"
      },
      "outputs": [],
      "source": [
        "class VariedBedPeaksDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "    def __init__(self, eclip_data, genome, max_seq_len, target_to_idx):\n",
        "        super(VariedBedPeaksDataset, self).__init__()\n",
        "        self.eclip_data = eclip_data\n",
        "        self.genome = genome\n",
        "        self.max_seq_len = max_seq_len\n",
        "        self.target_to_idx = target_to_idx \n",
        "\n",
        "    def __iter__(self): \n",
        "        for i,row in enumerate(self.eclip_data.itertuples()):\n",
        "            midpoint = int(.5 * (row.start + row.end))\n",
        "            seq = self.genome[row.chr][row.start:row.end]\n",
        "            if row.strand == '-':\n",
        "              seq = strand_normalize(seq) \n",
        "            yield(pad_enc(one_hot(seq), self.max_seq_len), get_positive_label(row.target, self.target_to_idx)) # positive example \n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.eclip_data.shape[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SHjfAoF2xFWx"
      },
      "outputs": [],
      "source": [
        "encode_train_dataset = VariedBedPeaksDataset(encode_train, genome, max_seq_len, target_to_idx)\n",
        "encode_train_dataloader = torch.utils.data.DataLoader(encode_train_dataset, batch_size=1028, num_workers = 0) \n",
        "\n",
        "encode_val_dataset = VariedBedPeaksDataset(encode_val, genome, max_seq_len, target_to_idx)\n",
        "encode_val_dataloader = torch.utils.data.DataLoader(encode_val_dataset, batch_size=1028)\n",
        "\n",
        "encode_test_dataset = VariedBedPeaksDataset(encode_test, genome, max_seq_len, target_to_idx)\n",
        "encodetest_dataloader = torch.utils.data.DataLoader(encode_test_dataset, batch_size=1028) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "guxUXp8y3M_S"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'basic_pad'  #Provide name to model experiment\n",
        "model_name = 'basic_pad' \n",
        "\n",
        "dataloaders = {'train': encode_train_dataloader, 'val' : encode_val_dataloader, 'test': encode_train_dataloader, 'mapping': target_set}\n",
        "model = ConvBasicNet(padding=True)\n",
        "classifier2 = Classifier(experiment_name, model, dataloaders, target_set, use_cuda=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "amTeY8eTRnI6",
        "outputId": "dd0f5baf-83dc-4e35-f289-e6d662a5a4bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch Loss (Avg): 4.312549591064453\n",
            "Validation Epoch Accuracy:12.586657733359388\n",
            "save model /home/wh2500/models/basic_pad/epoch_0.pt\n",
            "Train Epoch Loss (Avg): 3.954946756362915\n",
            "Validation Epoch Accuracy:16.051105962052056\n",
            "save model /home/wh2500/models/basic_pad/epoch_1.pt\n",
            "Train Epoch Loss (Avg): 3.8185360431671143\n",
            "Validation Epoch Accuracy:16.807645422145296\n",
            "save model /home/wh2500/models/basic_pad/epoch_2.pt\n",
            "Train Epoch Loss (Avg): 3.7595598697662354\n",
            "Validation Epoch Accuracy:17.344574411657966\n",
            "save model /home/wh2500/models/basic_pad/epoch_3.pt\n",
            "Train Epoch Loss (Avg): 3.7169158458709717\n",
            "Validation Epoch Accuracy:17.6432818737612\n",
            "save model /home/wh2500/models/basic_pad/epoch_4.pt\n",
            "Train Epoch Loss (Avg): 3.680737018585205\n",
            "Validation Epoch Accuracy:17.617226394200795\n",
            "Train Epoch Loss (Avg): 3.6501357555389404\n",
            "Validation Epoch Accuracy:17.602337548737705\n",
            "Train Epoch Loss (Avg): 3.6250531673431396\n",
            "Validation Epoch Accuracy:17.548365483934006\n",
            "Train Epoch Loss (Avg): 3.605546474456787\n",
            "Validation Epoch Accuracy:17.67212901184594\n",
            "save model /home/wh2500/models/basic_pad/epoch_8.pt\n",
            "Train Epoch Loss (Avg): 3.5892043113708496\n",
            "Validation Epoch Accuracy:17.874989531280534\n",
            "save model /home/wh2500/models/basic_pad/epoch_9.pt\n",
            "Train Epoch Loss (Avg): 3.574911594390869\n",
            "Validation Epoch Accuracy:18.006197481924012\n",
            "save model /home/wh2500/models/basic_pad/epoch_10.pt\n",
            "Train Epoch Loss (Avg): 3.5622265338897705\n",
            "Validation Epoch Accuracy:18.205335789992834\n",
            "save model /home/wh2500/models/basic_pad/epoch_11.pt\n",
            "Train Epoch Loss (Avg): 3.5505757331848145\n",
            "Validation Epoch Accuracy:18.352363138940845\n",
            "save model /home/wh2500/models/basic_pad/epoch_12.pt\n",
            "Train Epoch Loss (Avg): 3.5398340225219727\n",
            "Validation Epoch Accuracy:18.481709983901435\n",
            "save model /home/wh2500/models/basic_pad/epoch_13.pt\n",
            "Train Epoch Loss (Avg): 3.5297904014587402\n",
            "Validation Epoch Accuracy:18.61198738170347\n",
            "save model /home/wh2500/models/basic_pad/epoch_14.pt\n",
            "Train Epoch Loss (Avg): 3.5206589698791504\n",
            "Validation Epoch Accuracy:18.661306682299955\n",
            "save model /home/wh2500/models/basic_pad/epoch_15.pt\n",
            "Train Epoch Loss (Avg): 3.5122909545898438\n",
            "Validation Epoch Accuracy:18.77111191759024\n",
            "save model /home/wh2500/models/basic_pad/epoch_16.pt\n",
            "Train Epoch Loss (Avg): 3.5043277740478516\n",
            "Validation Epoch Accuracy:18.892083786977842\n",
            "save model /home/wh2500/models/basic_pad/epoch_17.pt\n",
            "Train Epoch Loss (Avg): 3.4969162940979004\n",
            "Validation Epoch Accuracy:18.969319672817623\n",
            "save model /home/wh2500/models/basic_pad/epoch_18.pt\n",
            "Train Epoch Loss (Avg): 3.4899675846099854\n",
            "Validation Epoch Accuracy:19.03445837171864\n",
            "save model /home/wh2500/models/basic_pad/epoch_19.pt\n",
            "Train Epoch Loss (Avg): 3.483426570892334\n",
            "Validation Epoch Accuracy:19.133096972911606\n",
            "save model /home/wh2500/models/basic_pad/epoch_20.pt\n",
            "Train Epoch Loss (Avg): 3.477138042449951\n",
            "Validation Epoch Accuracy:19.20940230590994\n",
            "save model /home/wh2500/models/basic_pad/epoch_21.pt\n",
            "Train Epoch Loss (Avg): 3.4711668491363525\n",
            "Validation Epoch Accuracy:19.323860305407443\n",
            "save model /home/wh2500/models/basic_pad/epoch_22.pt\n",
            "Train Epoch Loss (Avg): 3.465550661087036\n",
            "Validation Epoch Accuracy:19.45134604468515\n",
            "save model /home/wh2500/models/basic_pad/epoch_23.pt\n",
            "Train Epoch Loss (Avg): 3.4601783752441406\n",
            "Validation Epoch Accuracy:19.50904032085462\n",
            "save model /home/wh2500/models/basic_pad/epoch_24.pt\n",
            "Train Epoch Loss (Avg): 3.455012559890747\n",
            "Validation Epoch Accuracy:19.608609474889032\n",
            "save model /home/wh2500/models/basic_pad/epoch_25.pt\n",
            "Train Epoch Loss (Avg): 3.450089931488037\n",
            "Validation Epoch Accuracy:19.67095651526572\n",
            "save model /home/wh2500/models/basic_pad/epoch_26.pt\n",
            "Train Epoch Loss (Avg): 3.4453866481781006\n",
            "Validation Epoch Accuracy:19.771456222141573\n",
            "save model /home/wh2500/models/basic_pad/epoch_27.pt\n",
            "Train Epoch Loss (Avg): 3.440810203552246\n",
            "Validation Epoch Accuracy:19.852414319347123\n",
            "save model /home/wh2500/models/basic_pad/epoch_28.pt\n",
            "Train Epoch Loss (Avg): 3.4364027976989746\n",
            "Validation Epoch Accuracy:19.924997440979688\n",
            "save model /home/wh2500/models/basic_pad/epoch_29.pt\n",
            "Train Epoch Loss (Avg): 3.4321277141571045\n",
            "Validation Epoch Accuracy:20.001302773978022\n",
            "save model /home/wh2500/models/basic_pad/epoch_30.pt\n",
            "Train Epoch Loss (Avg): 3.4279556274414062\n",
            "Validation Epoch Accuracy:20.07016368424481\n",
            "save model /home/wh2500/models/basic_pad/epoch_31.pt\n",
            "Train Epoch Loss (Avg): 3.423943519592285\n",
            "Validation Epoch Accuracy:20.10924690358542\n",
            "save model /home/wh2500/models/basic_pad/epoch_32.pt\n",
            "Train Epoch Loss (Avg): 3.420065402984619\n",
            "Validation Epoch Accuracy:20.1864827894252\n",
            "save model /home/wh2500/models/basic_pad/epoch_33.pt\n",
            "Train Epoch Loss (Avg): 3.416294574737549\n",
            "Validation Epoch Accuracy:20.240454854228897\n",
            "save model /home/wh2500/models/basic_pad/epoch_34.pt\n",
            "Train Epoch Loss (Avg): 3.4127089977264404\n",
            "Validation Epoch Accuracy:20.3139685287029\n",
            "save model /home/wh2500/models/basic_pad/epoch_35.pt\n",
            "Train Epoch Loss (Avg): 3.409092426300049\n",
            "Validation Epoch Accuracy:20.347468430994855\n",
            "save model /home/wh2500/models/basic_pad/epoch_36.pt\n",
            "Train Epoch Loss (Avg): 3.4056124687194824\n",
            "Validation Epoch Accuracy:20.401440495798553\n",
            "save model /home/wh2500/models/basic_pad/epoch_37.pt\n",
            "Train Epoch Loss (Avg): 3.4022536277770996\n",
            "Validation Epoch Accuracy:20.43307929240762\n",
            "save model /home/wh2500/models/basic_pad/epoch_38.pt\n",
            "Train Epoch Loss (Avg): 3.398827075958252\n",
            "Validation Epoch Accuracy:20.464718089016685\n",
            "save model /home/wh2500/models/basic_pad/epoch_39.pt\n",
            "Train Epoch Loss (Avg): 3.395662546157837\n",
            "Validation Epoch Accuracy:20.500079096991524\n",
            "save model /home/wh2500/models/basic_pad/epoch_40.pt\n",
            "Train Epoch Loss (Avg): 3.392489433288574\n",
            "Validation Epoch Accuracy:20.500079096991524\n",
            "Train Epoch Loss (Avg): 3.389406204223633\n",
            "Validation Epoch Accuracy:20.54195397485646\n",
            "save model /home/wh2500/models/basic_pad/epoch_42.pt\n",
            "Train Epoch Loss (Avg): 3.3863091468811035\n",
            "Validation Epoch Accuracy:20.602439909550263\n",
            "save model /home/wh2500/models/basic_pad/epoch_43.pt\n",
            "Train Epoch Loss (Avg): 3.3833870887756348\n",
            "Validation Epoch Accuracy:20.656411974353965\n",
            "save model /home/wh2500/models/basic_pad/epoch_44.pt\n",
            "Train Epoch Loss (Avg): 3.3803999423980713\n",
            "Validation Epoch Accuracy:20.67967579539004\n",
            "save model /home/wh2500/models/basic_pad/epoch_45.pt\n",
            "Train Epoch Loss (Avg): 3.3776440620422363\n",
            "Validation Epoch Accuracy:20.70573127495045\n",
            "save model /home/wh2500/models/basic_pad/epoch_46.pt\n",
            "Train Epoch Loss (Avg): 3.374756097793579\n",
            "Validation Epoch Accuracy:20.73364786019374\n",
            "save model /home/wh2500/models/basic_pad/epoch_47.pt\n",
            "Train Epoch Loss (Avg): 3.3720054626464844\n",
            "Validation Epoch Accuracy:20.753189469864047\n",
            "save model /home/wh2500/models/basic_pad/epoch_48.pt\n",
            "Train Epoch Loss (Avg): 3.3693413734436035\n",
            "Validation Epoch Accuracy:20.764356103961365\n",
            "save model /home/wh2500/models/basic_pad/epoch_49.pt\n",
            "Train Epoch Loss (Avg): 3.366583824157715\n",
            "Validation Epoch Accuracy:20.788550477838886\n",
            "save model /home/wh2500/models/basic_pad/epoch_50.pt\n",
            "Train Epoch Loss (Avg): 3.363942861557007\n",
            "Validation Epoch Accuracy:20.809022640350634\n",
            "save model /home/wh2500/models/basic_pad/epoch_51.pt\n",
            "Train Epoch Loss (Avg): 3.3613359928131104\n",
            "Validation Epoch Accuracy:20.85275862389846\n",
            "save model /home/wh2500/models/basic_pad/epoch_52.pt\n",
            "Train Epoch Loss (Avg): 3.358764886856079\n",
            "Validation Epoch Accuracy:20.865786363678662\n",
            "save model /home/wh2500/models/basic_pad/epoch_53.pt\n",
            "Train Epoch Loss (Avg): 3.356208562850952\n",
            "Validation Epoch Accuracy:20.870439127885877\n",
            "save model /home/wh2500/models/basic_pad/epoch_54.pt\n",
            "Train Epoch Loss (Avg): 3.353700637817383\n",
            "Validation Epoch Accuracy:20.890911290397625\n",
            "save model /home/wh2500/models/basic_pad/epoch_55.pt\n",
            "Train Epoch Loss (Avg): 3.351206064224243\n",
            "Validation Epoch Accuracy:20.904869583019273\n",
            "save model /home/wh2500/models/basic_pad/epoch_56.pt\n",
            "Train Epoch Loss (Avg): 3.348781108856201\n",
            "Validation Epoch Accuracy:20.91045290006793\n",
            "save model /home/wh2500/models/basic_pad/epoch_57.pt\n",
            "Train Epoch Loss (Avg): 3.346358299255371\n",
            "Validation Epoch Accuracy:20.916966769958034\n",
            "save model /home/wh2500/models/basic_pad/epoch_58.pt\n",
            "Train Epoch Loss (Avg): 3.343975067138672\n",
            "Validation Epoch Accuracy:20.93371672110401\n",
            "save model /home/wh2500/models/basic_pad/epoch_59.pt\n",
            "Train Epoch Loss (Avg): 3.341599702835083\n",
            "Validation Epoch Accuracy:20.948605566567096\n",
            "save model /home/wh2500/models/basic_pad/epoch_60.pt\n",
            "Train Epoch Loss (Avg): 3.3392446041107178\n",
            "Validation Epoch Accuracy:20.93464727394545\n",
            "Train Epoch Loss (Avg): 3.336907148361206\n",
            "Validation Epoch Accuracy:20.935577826786893\n",
            "Train Epoch Loss (Avg): 3.33461332321167\n",
            "Validation Epoch Accuracy:20.942091696676997\n",
            "Train Epoch Loss (Avg): 3.332310199737549\n",
            "Validation Epoch Accuracy:20.953258330774315\n",
            "save model /home/wh2500/models/basic_pad/epoch_64.pt\n",
            "Train Epoch Loss (Avg): 3.3300464153289795\n",
            "Validation Epoch Accuracy:20.972799940444617\n",
            "save model /home/wh2500/models/basic_pad/epoch_65.pt\n",
            "Train Epoch Loss (Avg): 3.327755928039551\n",
            "Validation Epoch Accuracy:20.978383257493277\n",
            "save model /home/wh2500/models/basic_pad/epoch_66.pt\n",
            "Train Epoch Loss (Avg): 3.3255386352539062\n",
            "Validation Epoch Accuracy:20.963494412030187\n",
            "Train Epoch Loss (Avg): 3.3232920169830322\n",
            "Validation Epoch Accuracy:20.984897127383377\n",
            "save model /home/wh2500/models/basic_pad/epoch_68.pt\n",
            "Train Epoch Loss (Avg): 3.3210599422454834\n",
            "Validation Epoch Accuracy:20.989549891590595\n",
            "save model /home/wh2500/models/basic_pad/epoch_69.pt\n",
            "Train Epoch Loss (Avg): 3.318821430206299\n",
            "Validation Epoch Accuracy:20.99141099727348\n",
            "save model /home/wh2500/models/basic_pad/epoch_70.pt\n",
            "Train Epoch Loss (Avg): 3.316641092300415\n",
            "Validation Epoch Accuracy:20.98210546885905\n",
            "Train Epoch Loss (Avg): 3.314448356628418\n",
            "Validation Epoch Accuracy:20.98861933874915\n",
            "Train Epoch Loss (Avg): 3.312277317047119\n",
            "Validation Epoch Accuracy:21.010952606943786\n",
            "save model /home/wh2500/models/basic_pad/epoch_73.pt\n",
            "Train Epoch Loss (Avg): 3.310147762298584\n",
            "Validation Epoch Accuracy:21.011883159785228\n",
            "save model /home/wh2500/models/basic_pad/epoch_74.pt\n",
            "Train Epoch Loss (Avg): 3.3079936504364014\n",
            "Validation Epoch Accuracy:21.013744265468116\n",
            "save model /home/wh2500/models/basic_pad/epoch_75.pt\n",
            "Train Epoch Loss (Avg): 3.305898904800415\n",
            "Validation Epoch Accuracy:21.008160948419455\n",
            "Train Epoch Loss (Avg): 3.303776979446411\n",
            "Validation Epoch Accuracy:21.022119241041104\n",
            "save model /home/wh2500/models/basic_pad/epoch_77.pt\n",
            "Train Epoch Loss (Avg): 3.30159068107605\n",
            "Validation Epoch Accuracy:21.01839702967533\n",
            "Train Epoch Loss (Avg): 3.299528121948242\n",
            "Validation Epoch Accuracy:21.011883159785228\n",
            "Train Epoch Loss (Avg): 3.2974138259887695\n",
            "Validation Epoch Accuracy:21.009091501260897\n",
            "Train Epoch Loss (Avg): 3.2953176498413086\n",
            "Validation Epoch Accuracy:21.035146980821306\n",
            "save model /home/wh2500/models/basic_pad/epoch_81.pt\n",
            "Train Epoch Loss (Avg): 3.2932119369506836\n",
            "Validation Epoch Accuracy:21.022119241041104\n",
            "Train Epoch Loss (Avg): 3.291147470474243\n",
            "Validation Epoch Accuracy:21.043521956394294\n",
            "save model /home/wh2500/models/basic_pad/epoch_83.pt\n",
            "Train Epoch Loss (Avg): 3.2890727519989014\n",
            "Validation Epoch Accuracy:21.045383062077182\n",
            "save model /home/wh2500/models/basic_pad/epoch_84.pt\n",
            "Train Epoch Loss (Avg): 3.2869420051574707\n",
            "Validation Epoch Accuracy:21.045383062077182\n",
            "Train Epoch Loss (Avg): 3.285006046295166\n",
            "Validation Epoch Accuracy:21.055619143333054\n",
            "save model /home/wh2500/models/basic_pad/epoch_86.pt\n",
            "Train Epoch Loss (Avg): 3.282870292663574\n",
            "Validation Epoch Accuracy:21.03700808650419\n",
            "Train Epoch Loss (Avg): 3.280850648880005\n",
            "Validation Epoch Accuracy:21.055619143333054\n",
            "Train Epoch Loss (Avg): 3.2787837982177734\n",
            "Validation Epoch Accuracy:21.02956366377265\n",
            "Train Epoch Loss (Avg): 3.276665210723877\n",
            "Validation Epoch Accuracy:21.040730297869963\n",
            "Train Epoch Loss (Avg): 3.274514675140381\n",
            "Validation Epoch Accuracy:21.062133013223157\n",
            "save model /home/wh2500/models/basic_pad/epoch_91.pt\n",
            "Train Epoch Loss (Avg): 3.272523880004883\n",
            "Validation Epoch Accuracy:21.02677200524832\n",
            "Train Epoch Loss (Avg): 3.270446538925171\n",
            "Validation Epoch Accuracy:21.055619143333054\n",
            "Train Epoch Loss (Avg): 3.2684309482574463\n",
            "Validation Epoch Accuracy:21.0630635660646\n",
            "save model /home/wh2500/models/basic_pad/epoch_94.pt\n",
            "Train Epoch Loss (Avg): 3.266378164291382\n",
            "Validation Epoch Accuracy:21.034216427979864\n",
            "Train Epoch Loss (Avg): 3.2643113136291504\n",
            "Validation Epoch Accuracy:21.04910527344295\n",
            "Train Epoch Loss (Avg): 3.2622053623199463\n",
            "Validation Epoch Accuracy:21.055619143333054\n",
            "Train Epoch Loss (Avg): 3.2601242065429688\n",
            "Validation Epoch Accuracy:21.062133013223157\n",
            "Train Epoch Loss (Avg): 3.258035898208618\n",
            "Validation Epoch Accuracy:21.077021858686244\n",
            "save model /home/wh2500/models/basic_pad/epoch_99.pt\n",
            "Finish training!\n",
            "Accuracy: 20.272784854243%\n"
          ]
        }
      ],
      "source": [
        "classifier2.train(epochs=100)\n",
        "classifier2.evaluate() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6EjFEFagRnI6",
        "outputId": "dc7a0ac0-a8ad-4ed1-f036-20b7957fa807"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12.586657733359388, 16.051105962052056, 16.807645422145296, 17.344574411657966, 17.6432818737612, 17.617226394200795, 17.602337548737705, 17.548365483934006, 17.67212901184594, 17.874989531280534, 18.006197481924012, 18.205335789992834, 18.352363138940845, 18.481709983901435, 18.61198738170347, 18.661306682299955, 18.77111191759024, 18.892083786977842, 18.969319672817623, 19.03445837171864, 19.133096972911606, 19.20940230590994, 19.323860305407443, 19.45134604468515, 19.50904032085462, 19.608609474889032, 19.67095651526572, 19.771456222141573, 19.852414319347123, 19.924997440979688, 20.001302773978022, 20.07016368424481, 20.10924690358542, 20.1864827894252, 20.240454854228897, 20.3139685287029, 20.347468430994855, 20.401440495798553, 20.43307929240762, 20.464718089016685, 20.500079096991524, 20.500079096991524, 20.54195397485646, 20.602439909550263, 20.656411974353965, 20.67967579539004, 20.70573127495045, 20.73364786019374, 20.753189469864047, 20.764356103961365, 20.788550477838886, 20.809022640350634, 20.85275862389846, 20.865786363678662, 20.870439127885877, 20.890911290397625, 20.904869583019273, 20.91045290006793, 20.916966769958034, 20.93371672110401, 20.948605566567096, 20.93464727394545, 20.935577826786893, 20.942091696676997, 20.953258330774315, 20.972799940444617, 20.978383257493277, 20.963494412030187, 20.984897127383377, 20.989549891590595, 20.99141099727348, 20.98210546885905, 20.98861933874915, 21.010952606943786, 21.011883159785228, 21.013744265468116, 21.008160948419455, 21.022119241041104, 21.01839702967533, 21.011883159785228, 21.009091501260897, 21.035146980821306, 21.022119241041104, 21.043521956394294, 21.045383062077182, 21.045383062077182, 21.055619143333054, 21.03700808650419, 21.055619143333054, 21.02956366377265, 21.040730297869963, 21.062133013223157, 21.02677200524832, 21.055619143333054, 21.0630635660646, 21.034216427979864, 21.04910527344295, 21.055619143333054, 21.062133013223157, 21.077021858686244]\n"
          ]
        }
      ],
      "source": [
        "cnn_padding_val_accs = classifier2.epoch_accuracies \n",
        "print(cnn_padding_val_accs) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### CNN + LSTM"
      ],
      "metadata": {
        "id": "qYjjgsCKR6ZB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sg5WsKAiRnI6"
      },
      "outputs": [],
      "source": [
        "class ConvLSTMNet(nn.Module): \n",
        "\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv_model = self.get_conv_layers()\n",
        "        self.final_max_pool = self.final_pool_layer()\n",
        "        self.lstm_model = self.lstm_layer()\n",
        "        self.fc_model = self.get_fc_layers()\n",
        "\n",
        "    def get_conv_layers(self):\n",
        "        \n",
        "        layers = nn.Sequential(\n",
        "            nn.Conv1d(4, 32, 5),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.MaxPool1d(2, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 16, 5),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.MaxPool1d(2, 2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def final_pool_layer(self):\n",
        "        \n",
        "        layer = nn.MaxPool1d(2, 2) \n",
        "        \n",
        "        return layer\n",
        "\n",
        "    def lstm_layer(self):\n",
        "        \n",
        "        layer = nn.LSTM(input_size=11, hidden_size=8, num_layers=2, batch_first=True) \n",
        "\n",
        "        return layer \n",
        "\n",
        "    def get_fc_layers(self):\n",
        "        \n",
        "        layers = nn.Sequential(\n",
        "            nn.Linear(in_features=128, out_features=256),\n",
        "            nn.Linear(in_features=256, out_features=150)\n",
        "        )\n",
        "\n",
        "        return layers \n",
        "\n",
        "    def register_grad_hook(self, grad):\n",
        "        self.grad = grad \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_model(x) \n",
        "        h = x.register_hook(self.register_grad_hook)\n",
        "\n",
        "        x = self.final_max_pool(x)\n",
        "        x = self.lstm_model(x)[0]\n",
        "        x = nn.Flatten()(x) \n",
        "        x = self.fc_model(x) \n",
        "\n",
        "        return x    \n",
        "\n",
        "    def get_gradient_activations(self):\n",
        "        return self.grad\n",
        "\n",
        "    def get_final_conv_layer(self, x):\n",
        "        return self.conv_model(x) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYuawSR-RnI6"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'cnn_lstm' \n",
        "model_name = 'cnn_lstm' \n",
        "\n",
        "dataloaders = {'train': encode_train_dataloader, 'val' : encode_val_dataloader, 'test': encode_train_dataloader, 'mapping': target_set}\n",
        "model = ConvLSTMNet()\n",
        "classifier3 = Classifier(experiment_name, model, dataloaders, target_set, use_cuda=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WBldGyI3RnI6",
        "outputId": "1df23c60-e422-4e18-d7a2-650fdcd2dbe8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch Loss (Avg): 4.68993616104126\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_0.pt\n",
            "Train Epoch Loss (Avg): 4.3687639236450195\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.349669456481934\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.345366477966309\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.343350887298584\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.341891765594482\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.3404459953308105\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.33860445022583\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.335755825042725\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.330350399017334\n",
            "Validation Epoch Accuracy:2.150507616575007\n",
            "Train Epoch Loss (Avg): 4.317098617553711\n",
            "Validation Epoch Accuracy:6.654383369159618\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_10.pt\n",
            "Train Epoch Loss (Avg): 4.281479358673096\n",
            "Validation Epoch Accuracy:8.384281101402344\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_11.pt\n",
            "Train Epoch Loss (Avg): 4.220861434936523\n",
            "Validation Epoch Accuracy:9.326931129784205\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_12.pt\n",
            "Train Epoch Loss (Avg): 4.154903411865234\n",
            "Validation Epoch Accuracy:10.35798367810316\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_13.pt\n",
            "Train Epoch Loss (Avg): 4.09088659286499\n",
            "Validation Epoch Accuracy:10.713454863534427\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_14.pt\n",
            "Train Epoch Loss (Avg): 4.04157018661499\n",
            "Validation Epoch Accuracy:11.942715167080763\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_15.pt\n",
            "Train Epoch Loss (Avg): 4.001756191253662\n",
            "Validation Epoch Accuracy:12.911420675023031\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_16.pt\n",
            "Train Epoch Loss (Avg): 3.960982322692871\n",
            "Validation Epoch Accuracy:13.659585159543285\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_17.pt\n",
            "Train Epoch Loss (Avg): 3.9161431789398193\n",
            "Validation Epoch Accuracy:14.633873984534212\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_18.pt\n",
            "Train Epoch Loss (Avg): 3.87441349029541\n",
            "Validation Epoch Accuracy:15.414607818504974\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_19.pt\n",
            "Train Epoch Loss (Avg): 3.840644121170044\n",
            "Validation Epoch Accuracy:15.904078613104046\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_20.pt\n",
            "Train Epoch Loss (Avg): 3.812725305557251\n",
            "Validation Epoch Accuracy:16.30235522924169\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_21.pt\n",
            "Train Epoch Loss (Avg): 3.7889647483825684\n",
            "Validation Epoch Accuracy:16.642937569209867\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_22.pt\n",
            "Train Epoch Loss (Avg): 3.768717050552368\n",
            "Validation Epoch Accuracy:16.980728250653712\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_23.pt\n",
            "Train Epoch Loss (Avg): 3.75128173828125\n",
            "Validation Epoch Accuracy:17.27385239570829\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_24.pt\n",
            "Train Epoch Loss (Avg): 3.7360312938690186\n",
            "Validation Epoch Accuracy:17.42367140318063\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_25.pt\n",
            "Train Epoch Loss (Avg): 3.7225990295410156\n",
            "Validation Epoch Accuracy:17.57349041065297\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_26.pt\n",
            "Train Epoch Loss (Avg): 3.710676908493042\n",
            "Validation Epoch Accuracy:17.743781580637055\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_27.pt\n",
            "Train Epoch Loss (Avg): 3.699949264526367\n",
            "Validation Epoch Accuracy:17.86754510854899\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_28.pt\n",
            "Train Epoch Loss (Avg): 3.690199613571167\n",
            "Validation Epoch Accuracy:18.016433563179884\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_29.pt\n",
            "Train Epoch Loss (Avg): 3.6812047958374023\n",
            "Validation Epoch Accuracy:18.145780408140475\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_30.pt\n",
            "Train Epoch Loss (Avg): 3.672853708267212\n",
            "Validation Epoch Accuracy:18.267682830369523\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_31.pt\n",
            "Train Epoch Loss (Avg): 3.665107011795044\n",
            "Validation Epoch Accuracy:18.352363138940845\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_32.pt\n",
            "Train Epoch Loss (Avg): 3.6578922271728516\n",
            "Validation Epoch Accuracy:18.43146013046351\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_33.pt\n",
            "Train Epoch Loss (Avg): 3.65116286277771\n",
            "Validation Epoch Accuracy:18.47426556116989\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_34.pt\n",
            "Train Epoch Loss (Avg): 3.6448888778686523\n",
            "Validation Epoch Accuracy:18.57941803225296\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_35.pt\n",
            "Train Epoch Loss (Avg): 3.6390221118927\n",
            "Validation Epoch Accuracy:18.639903966946765\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_36.pt\n",
            "Train Epoch Loss (Avg): 3.633563756942749\n",
            "Validation Epoch Accuracy:18.703181560164893\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_37.pt\n",
            "Train Epoch Loss (Avg): 3.628452777862549\n",
            "Validation Epoch Accuracy:18.755292519285707\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_38.pt\n",
            "Train Epoch Loss (Avg): 3.623652219772339\n",
            "Validation Epoch Accuracy:18.805542372723636\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_39.pt\n",
            "Train Epoch Loss (Avg): 3.619054079055786\n",
            "Validation Epoch Accuracy:18.837181169332702\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_40.pt\n",
            "Train Epoch Loss (Avg): 3.614734172821045\n",
            "Validation Epoch Accuracy:18.90325042107516\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_41.pt\n",
            "Train Epoch Loss (Avg): 3.610637903213501\n",
            "Validation Epoch Accuracy:18.92744479495268\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_42.pt\n",
            "Train Epoch Loss (Avg): 3.6067821979522705\n",
            "Validation Epoch Accuracy:18.97304188418339\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_43.pt\n",
            "Train Epoch Loss (Avg): 3.603090763092041\n",
            "Validation Epoch Accuracy:18.9990973637438\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_44.pt\n",
            "Train Epoch Loss (Avg): 3.5995914936065674\n",
            "Validation Epoch Accuracy:19.013055656365445\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_45.pt\n",
            "Train Epoch Loss (Avg): 3.5962889194488525\n",
            "Validation Epoch Accuracy:19.030736160352866\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_46.pt\n",
            "Train Epoch Loss (Avg): 3.5930747985839844\n",
            "Validation Epoch Accuracy:19.06516661548626\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_47.pt\n",
            "Train Epoch Loss (Avg): 3.5899789333343506\n",
            "Validation Epoch Accuracy:19.095874859253883\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_48.pt\n",
            "Train Epoch Loss (Avg): 3.587001085281372\n",
            "Validation Epoch Accuracy:19.126583103021506\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_49.pt\n",
            "Train Epoch Loss (Avg): 3.584139108657837\n",
            "Validation Epoch Accuracy:19.1610135581549\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_50.pt\n",
            "Train Epoch Loss (Avg): 3.581393003463745\n",
            "Validation Epoch Accuracy:19.2214994928487\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_51.pt\n",
            "Train Epoch Loss (Avg): 3.5787529945373535\n",
            "Validation Epoch Accuracy:19.273610451969514\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_52.pt\n",
            "Train Epoch Loss (Avg): 3.5761778354644775\n",
            "Validation Epoch Accuracy:19.33130472813899\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_53.pt\n",
            "Train Epoch Loss (Avg): 3.57368803024292\n",
            "Validation Epoch Accuracy:19.375971264528257\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_54.pt\n",
            "Train Epoch Loss (Avg): 3.571268081665039\n",
            "Validation Epoch Accuracy:19.387137898625575\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_55.pt\n",
            "Train Epoch Loss (Avg): 3.56890606880188\n",
            "Validation Epoch Accuracy:19.433665540697728\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_56.pt\n",
            "Train Epoch Loss (Avg): 3.566617965698242\n",
            "Validation Epoch Accuracy:19.49415147539153\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_57.pt\n",
            "Train Epoch Loss (Avg): 3.564365863800049\n",
            "Validation Epoch Accuracy:19.531373589049256\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_58.pt\n",
            "Train Epoch Loss (Avg): 3.5621485710144043\n",
            "Validation Epoch Accuracy:19.573248466914194\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_59.pt\n",
            "Train Epoch Loss (Avg): 3.5599770545959473\n",
            "Validation Epoch Accuracy:19.61698445046202\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_60.pt\n",
            "Train Epoch Loss (Avg): 3.5578155517578125\n",
            "Validation Epoch Accuracy:19.65048435275397\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_61.pt\n",
            "Train Epoch Loss (Avg): 3.5556936264038086\n",
            "Validation Epoch Accuracy:19.67374817379005\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_62.pt\n",
            "Train Epoch Loss (Avg): 3.553623676300049\n",
            "Validation Epoch Accuracy:19.718414710179317\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_63.pt\n",
            "Train Epoch Loss (Avg): 3.5515732765197754\n",
            "Validation Epoch Accuracy:19.750984059629825\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_64.pt\n",
            "Train Epoch Loss (Avg): 3.549548625946045\n",
            "Validation Epoch Accuracy:19.79378949033621\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_65.pt\n",
            "Train Epoch Loss (Avg): 3.547562837600708\n",
            "Validation Epoch Accuracy:19.806817230116412\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_66.pt\n",
            "Train Epoch Loss (Avg): 3.545597553253174\n",
            "Validation Epoch Accuracy:19.82728939262816\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_67.pt\n",
            "Train Epoch Loss (Avg): 3.54365873336792\n",
            "Validation Epoch Accuracy:19.858928189237226\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_68.pt\n",
            "Train Epoch Loss (Avg): 3.5417516231536865\n",
            "Validation Epoch Accuracy:19.871025376175986\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_69.pt\n",
            "Train Epoch Loss (Avg): 3.5398781299591064\n",
            "Validation Epoch Accuracy:19.90824748983371\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_70.pt\n",
            "Train Epoch Loss (Avg): 3.5380401611328125\n",
            "Validation Epoch Accuracy:19.931511310869787\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_71.pt\n",
            "Train Epoch Loss (Avg): 3.536245346069336\n",
            "Validation Epoch Accuracy:19.943608497808547\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_72.pt\n",
            "Train Epoch Loss (Avg): 3.534498691558838\n",
            "Validation Epoch Accuracy:19.951983473381535\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_73.pt\n",
            "Train Epoch Loss (Avg): 3.532783269882202\n",
            "Validation Epoch Accuracy:19.99292779840503\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_74.pt\n",
            "Train Epoch Loss (Avg): 3.5311031341552734\n",
            "Validation Epoch Accuracy:20.001302773978022\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_75.pt\n",
            "Train Epoch Loss (Avg): 3.529461145401001\n",
            "Validation Epoch Accuracy:20.026427700696985\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_76.pt\n",
            "Train Epoch Loss (Avg): 3.527862787246704\n",
            "Validation Epoch Accuracy:20.060858155830378\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_77.pt\n",
            "Train Epoch Loss (Avg): 3.5262932777404785\n",
            "Validation Epoch Accuracy:20.077608106976356\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_78.pt\n",
            "Train Epoch Loss (Avg): 3.524763345718384\n",
            "Validation Epoch Accuracy:20.111108009268307\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_79.pt\n",
            "Train Epoch Loss (Avg): 3.5232503414154053\n",
            "Validation Epoch Accuracy:20.12506630188995\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_80.pt\n",
            "Train Epoch Loss (Avg): 3.5217649936676025\n",
            "Validation Epoch Accuracy:20.128788513255724\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_81.pt\n",
            "Train Epoch Loss (Avg): 3.520322799682617\n",
            "Validation Epoch Accuracy:20.128788513255724\n",
            "Train Epoch Loss (Avg): 3.5188934803009033\n",
            "Validation Epoch Accuracy:20.13344127746294\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_83.pt\n",
            "Train Epoch Loss (Avg): 3.517505645751953\n",
            "Validation Epoch Accuracy:20.1455384644017\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_84.pt\n",
            "Train Epoch Loss (Avg): 3.5161385536193848\n",
            "Validation Epoch Accuracy:20.159496757023348\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_85.pt\n",
            "Train Epoch Loss (Avg): 3.5148000717163086\n",
            "Validation Epoch Accuracy:20.206954951936947\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_86.pt\n",
            "Train Epoch Loss (Avg): 3.5134782791137695\n",
            "Validation Epoch Accuracy:20.19671887068107\n",
            "Train Epoch Loss (Avg): 3.512181520462036\n",
            "Validation Epoch Accuracy:20.221843797400034\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_88.pt\n",
            "Train Epoch Loss (Avg): 3.510913848876953\n",
            "Validation Epoch Accuracy:20.225566008765806\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_89.pt\n",
            "Train Epoch Loss (Avg): 3.5096538066864014\n",
            "Validation Epoch Accuracy:20.2534825940091\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_90.pt\n",
            "Train Epoch Loss (Avg): 3.5084192752838135\n",
            "Validation Epoch Accuracy:20.274885309362293\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_91.pt\n",
            "Train Epoch Loss (Avg): 3.507204294204712\n",
            "Validation Epoch Accuracy:20.29535747187404\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_92.pt\n",
            "Train Epoch Loss (Avg): 3.5060160160064697\n",
            "Validation Epoch Accuracy:20.319551845751562\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_93.pt\n",
            "Train Epoch Loss (Avg): 3.5048389434814453\n",
            "Validation Epoch Accuracy:20.329787927007434\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_94.pt\n",
            "Train Epoch Loss (Avg): 3.5036780834198\n",
            "Validation Epoch Accuracy:20.345607325311967\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_95.pt\n",
            "Train Epoch Loss (Avg): 3.5025370121002197\n",
            "Validation Epoch Accuracy:20.366079487823715\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_96.pt\n",
            "Train Epoch Loss (Avg): 3.5014030933380127\n",
            "Validation Epoch Accuracy:20.372593357713818\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_97.pt\n",
            "Train Epoch Loss (Avg): 3.500279426574707\n",
            "Validation Epoch Accuracy:20.40330160148144\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_98.pt\n",
            "Train Epoch Loss (Avg): 3.4991815090179443\n",
            "Validation Epoch Accuracy:20.41819044694453\n",
            "save model /home/wh2500/models/cnn_lstm/epoch_99.pt\n",
            "Finish training!\n",
            "Accuracy: 18.014074134686197%\n"
          ]
        }
      ],
      "source": [
        "classifier3.train(epochs=100)\n",
        "classifier3.evaluate() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-gUNMiUQRnI6",
        "outputId": "b19ba0ac-8da4-44a1-b310-04acf4fc9131"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 6.654383369159618, 8.384281101402344, 9.326931129784205, 10.35798367810316, 10.713454863534427, 11.942715167080763, 12.911420675023031, 13.659585159543285, 14.633873984534212, 15.414607818504974, 15.904078613104046, 16.30235522924169, 16.642937569209867, 16.980728250653712, 17.27385239570829, 17.42367140318063, 17.57349041065297, 17.743781580637055, 17.86754510854899, 18.016433563179884, 18.145780408140475, 18.267682830369523, 18.352363138940845, 18.43146013046351, 18.47426556116989, 18.57941803225296, 18.639903966946765, 18.703181560164893, 18.755292519285707, 18.805542372723636, 18.837181169332702, 18.90325042107516, 18.92744479495268, 18.97304188418339, 18.9990973637438, 19.013055656365445, 19.030736160352866, 19.06516661548626, 19.095874859253883, 19.126583103021506, 19.1610135581549, 19.2214994928487, 19.273610451969514, 19.33130472813899, 19.375971264528257, 19.387137898625575, 19.433665540697728, 19.49415147539153, 19.531373589049256, 19.573248466914194, 19.61698445046202, 19.65048435275397, 19.67374817379005, 19.718414710179317, 19.750984059629825, 19.79378949033621, 19.806817230116412, 19.82728939262816, 19.858928189237226, 19.871025376175986, 19.90824748983371, 19.931511310869787, 19.943608497808547, 19.951983473381535, 19.99292779840503, 20.001302773978022, 20.026427700696985, 20.060858155830378, 20.077608106976356, 20.111108009268307, 20.12506630188995, 20.128788513255724, 20.128788513255724, 20.13344127746294, 20.1455384644017, 20.159496757023348, 20.206954951936947, 20.19671887068107, 20.221843797400034, 20.225566008765806, 20.2534825940091, 20.274885309362293, 20.29535747187404, 20.319551845751562, 20.329787927007434, 20.345607325311967, 20.366079487823715, 20.372593357713818, 20.40330160148144, 20.41819044694453]\n"
          ]
        }
      ],
      "source": [
        "cnn_rnn_val_accs = classifier3.epoch_accuracies\n",
        "print(cnn_rnn_val_accs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mH6tax6yRnI6"
      },
      "outputs": [],
      "source": [
        "cnn_val_accs = [11.560257949247648, 14.84045671533458, 15.877092580702195, 16.260480351376753, 16.669923601611718, 17.03376976261597, 17.44786577705815, 17.804267515330856, 18.169974782018, 18.580348585094406, 18.841833933539917, 19.13402752575305, 19.382485134418356, 19.58999841806017, 19.76959511645869, 19.883122563114746, 19.975247294417613, 20.085052529707898, 20.152052334291803, 20.223704903082922, 20.260927016740645, 20.300010236081256, 20.378176674762475, 20.422843211151744, 20.47867638163833, 20.558703926002437, 20.62291207206201, 20.681536901072928, 20.735508965876626, 20.750397811339717, 20.81460595739929, 20.87695299777598, 20.95791109498153, 21.021188688199658, 21.09656346835655, 21.14774387463592, 21.193340963866632, 21.24638247582889, 21.278021272437954, 21.33385444292454, 21.380382084996697, 21.412951434447205, 21.4538957594707, 21.481812344713994, 21.509728929957287, 21.521826116896047, 21.5618398890781, 21.591617580004282, 21.59720089705294, 21.641867433442208, 21.68095065278282, 21.70514502666034, 21.747019904525278, 21.773075384085686, 21.791686440914546, 21.802853075011864, 21.820533578999285, 21.8251863432065, 21.848450164242575, 21.88288061937597, 21.90428333472916, 21.92754715576524, 21.95732484669142, 22.01222746433656, 22.021532992750995, 22.05038013083573, 22.07178284618892, 22.114588276895304, 22.125754910992622, 22.14343541498004, 22.165768683174672, 22.20019913830807, 22.223462959344147, 22.25417120311177, 22.297907186659593, 22.304421056549696, 22.312796032122684, 22.33512930031732, 22.366768096926386, 22.403059657742666, 22.42818458446163, 22.44679564129049, 22.459823381070695, 22.48867051915543, 22.504489917459964, 22.526823185654596, 22.53426760838614, 22.54822590100779, 22.550087006690674, 22.57893414477541, 22.60871183570159, 22.610572941384476, 22.633836762420554, 22.660822794822405, 22.670128323236835, 22.70083656700446, 22.718517070991876, 22.748294761918057, 22.779003005685677, 22.790169639782995]\n",
        "cnn_padding_val_accs = [12.586657733359388, 16.051105962052056, 16.807645422145296, 17.344574411657966, 17.6432818737612, 17.617226394200795, 17.602337548737705, 17.548365483934006, 17.67212901184594, 17.874989531280534, 18.006197481924012, 18.205335789992834, 18.352363138940845, 18.481709983901435, 18.61198738170347, 18.661306682299955, 18.77111191759024, 18.892083786977842, 18.969319672817623, 19.03445837171864, 19.133096972911606, 19.20940230590994, 19.323860305407443, 19.45134604468515, 19.50904032085462, 19.608609474889032, 19.67095651526572, 19.771456222141573, 19.852414319347123, 19.924997440979688, 20.001302773978022, 20.07016368424481, 20.10924690358542, 20.1864827894252, 20.240454854228897, 20.3139685287029, 20.347468430994855, 20.401440495798553, 20.43307929240762, 20.464718089016685, 20.500079096991524, 20.500079096991524, 20.54195397485646, 20.602439909550263, 20.656411974353965, 20.67967579539004, 20.70573127495045, 20.73364786019374, 20.753189469864047, 20.764356103961365, 20.788550477838886, 20.809022640350634, 20.85275862389846, 20.865786363678662, 20.870439127885877, 20.890911290397625, 20.904869583019273, 20.91045290006793, 20.916966769958034, 20.93371672110401, 20.948605566567096, 20.93464727394545, 20.935577826786893, 20.942091696676997, 20.953258330774315, 20.972799940444617, 20.978383257493277, 20.963494412030187, 20.984897127383377, 20.989549891590595, 20.99141099727348, 20.98210546885905, 20.98861933874915, 21.010952606943786, 21.011883159785228, 21.013744265468116, 21.008160948419455, 21.022119241041104, 21.01839702967533, 21.011883159785228, 21.009091501260897, 21.035146980821306, 21.022119241041104, 21.043521956394294, 21.045383062077182, 21.045383062077182, 21.055619143333054, 21.03700808650419, 21.055619143333054, 21.02956366377265, 21.040730297869963, 21.062133013223157, 21.02677200524832, 21.055619143333054, 21.0630635660646, 21.034216427979864, 21.04910527344295, 21.055619143333054, 21.062133013223157, 21.077021858686244]\n",
        "cnn_rnn_val_accs = [2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 2.150507616575007, 6.654383369159618, 8.384281101402344, 9.326931129784205, 10.35798367810316, 10.713454863534427, 11.942715167080763, 12.911420675023031, 13.659585159543285, 14.633873984534212, 15.414607818504974, 15.904078613104046, 16.30235522924169, 16.642937569209867, 16.980728250653712, 17.27385239570829, 17.42367140318063, 17.57349041065297, 17.743781580637055, 17.86754510854899, 18.016433563179884, 18.145780408140475, 18.267682830369523, 18.352363138940845, 18.43146013046351, 18.47426556116989, 18.57941803225296, 18.639903966946765, 18.703181560164893, 18.755292519285707, 18.805542372723636, 18.837181169332702, 18.90325042107516, 18.92744479495268, 18.97304188418339, 18.9990973637438, 19.013055656365445, 19.030736160352866, 19.06516661548626, 19.095874859253883, 19.126583103021506, 19.1610135581549, 19.2214994928487, 19.273610451969514, 19.33130472813899, 19.375971264528257, 19.387137898625575, 19.433665540697728, 19.49415147539153, 19.531373589049256, 19.573248466914194, 19.61698445046202, 19.65048435275397, 19.67374817379005, 19.718414710179317, 19.750984059629825, 19.79378949033621, 19.806817230116412, 19.82728939262816, 19.858928189237226, 19.871025376175986, 19.90824748983371, 19.931511310869787, 19.943608497808547, 19.951983473381535, 19.99292779840503, 20.001302773978022, 20.026427700696985, 20.060858155830378, 20.077608106976356, 20.111108009268307, 20.12506630188995, 20.128788513255724, 20.128788513255724, 20.13344127746294, 20.1455384644017, 20.159496757023348, 20.206954951936947, 20.19671887068107, 20.221843797400034, 20.225566008765806, 20.2534825940091, 20.274885309362293, 20.29535747187404, 20.319551845751562, 20.329787927007434, 20.345607325311967, 20.366079487823715, 20.372593357713818, 20.40330160148144, 20.41819044694453]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OXt1ob8RnI6",
        "outputId": "5bf27602-e1e6-47bf-e525-e04000fbb43f"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(cnn_val_accs, label='CNN')\n",
        "plt.plot(cnn_padding_val_accs, label=\"CNN with padding\")\n",
        "plt.plot(cnn_rnn_val_accs, color = 'pink', label='CNN + LSTM')\n",
        "plt.plot()\n",
        "plt.legend() \n",
        "#plt.grid(which='both') \n",
        "\n",
        "plt.title('Validation Accuracies of different CNN models')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Val Accs') \n",
        "\n",
        "plt.savefig('val_accs_CNN.png', dpi=300)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Binary Classification"
      ],
      "metadata": {
        "id": "N7_VgXI5SD3M"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q41Ctv-SRnI6"
      },
      "outputs": [],
      "source": [
        "class BinaryConvBasicNet(nn.Module): \n",
        "\n",
        "    def __init__(self, padding=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.padding = padding\n",
        "        self.conv_model = self.get_conv_layers()\n",
        "        self.final_max_pool = self.final_pool_layer()\n",
        "        self.fc_model = self.get_fc_layers()\n",
        "\n",
        "    def get_conv_layers(self):\n",
        "        \n",
        "        layers = nn.Sequential(\n",
        "            nn.Conv1d(4, 32, 5),\n",
        "            nn.BatchNorm1d(32),\n",
        "            nn.MaxPool1d(2, 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Conv1d(32, 16, 5),\n",
        "            nn.BatchNorm1d(16),\n",
        "            nn.MaxPool1d(2, 2),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def final_pool_layer(self):\n",
        "        \n",
        "        layer = nn.MaxPool1d(2, 2) \n",
        "        \n",
        "        return layer\n",
        "\n",
        "    def get_fc_layers(self):\n",
        "        \n",
        "        if self.padding==False:\n",
        "          layers = nn.Sequential(\n",
        "              nn.Linear(176, 512),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(512, 1028),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(1028, 2)\n",
        "          )\n",
        "\n",
        "        elif self.padding:\n",
        "          layers = nn.Sequential(\n",
        "              nn.Linear(912, 1024),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(1024, 2048),\n",
        "              nn.ReLU(),\n",
        "              nn.Linear(2048, 2)\n",
        "          )\n",
        "\n",
        "        return layers\n",
        "\n",
        "    def register_grad_hook(self, grad):\n",
        "        self.grad = grad \n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.conv_model(x) \n",
        "        h = x.register_hook(self.register_grad_hook)\n",
        "\n",
        "        x = self.final_max_pool(x)\n",
        "        x = nn.Flatten()(x) \n",
        "        x = self.fc_model(x)\n",
        "\n",
        "        return x    \n",
        "\n",
        "    def get_gradient_activations(self):\n",
        "        return self.grad\n",
        "\n",
        "    def get_final_conv_layer(self, x):\n",
        "        return self.conv_model(x) \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Negative Sampling"
      ],
      "metadata": {
        "id": "Pw8K83ORSg_g"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fALwi4xcRnI6"
      },
      "outputs": [],
      "source": [
        "class BinaryBedPeaksDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "    def __init__(self, eclip_data, genome, context_length, negative_samples):\n",
        "        super(BinaryBedPeaksDataset, self).__init__()\n",
        "        self.eclip_data = eclip_data\n",
        "        self.genome = genome\n",
        "        self.context_length = context_length\n",
        "        self.negative_samples = negative_samples \n",
        "\n",
        "    def __iter__(self): \n",
        "        \n",
        "        for i,row in enumerate(self.eclip_data.itertuples()):\n",
        "            rand = random.random()\n",
        "            if rand <= 0.5:\n",
        "                midpoint = int(.5 * (row.start + row.end))\n",
        "                seq = self.genome[row.chr][midpoint - self.context_length//2 : midpoint + self.context_length//2]\n",
        "                \n",
        "                if row.strand == '-':\n",
        "                    seq = strand_normalize(seq)\n",
        "                \n",
        "                yield(one_hot(seq), np.int64(1)) \n",
        "            \n",
        "            else:\n",
        "                chrom, neg_sample = get_negative_sample(self.negative_samples, self.context_length)\n",
        "                start, end = neg_sample \n",
        "                seq = self.genome[chrom][start:end]\n",
        "                \n",
        "                yield(one_hot(seq), np.int64(0)) \n",
        "\n",
        "    def __len__(self):\n",
        "        return self.eclip_data.shape[0] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWnp7uQeRnI6"
      },
      "outputs": [],
      "source": [
        "context_length = 100\n",
        "\n",
        "encode_train_dataset = BinaryBedPeaksDataset(encode_train, genome, context_length, train_negative_samples)\n",
        "encode_train_dataloader = torch.utils.data.DataLoader(encode_train_dataset, batch_size=128, num_workers = 0) \n",
        "\n",
        "encode_val_dataset = BinaryBedPeaksDataset(encode_val, genome, context_length, val_negative_samples)\n",
        "encode_val_dataloader = torch.utils.data.DataLoader(encode_val_dataset, batch_size=128)\n",
        "\n",
        "encode_test_dataset = BinaryBedPeaksDataset(encode_test, genome, context_length, test_negative_samples)\n",
        "encodetest_dataloader = torch.utils.data.DataLoader(encode_test_dataset, batch_size=128)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s1tELPgFRnI6"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'basic_binary'  #Provide name to model experiment\n",
        "model_name = 'basic_binary' \n",
        "\n",
        "dataloaders = {'train': encode_train_dataloader, 'val' : encode_val_dataloader, 'test': encode_train_dataloader, 'mapping': target_set}\n",
        "model = ConvBasicNet()\n",
        "classifier4 = Classifier(experiment_name, model, dataloaders, target_set, use_cuda=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "spU63tPpRnI7",
        "outputId": "936b0a3e-1942-4083-c528-d613b1235161"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch Loss (Avg): 0.4795885384082794\n",
            "Validation Epoch Accuracy:75.20169732838279\n",
            "save model /home/wh2500/models/basic_binary/epoch_0.pt\n",
            "Train Epoch Loss (Avg): 0.41699284315109253\n",
            "Validation Epoch Accuracy:75.6334738468124\n",
            "save model /home/wh2500/models/basic_binary/epoch_1.pt\n",
            "Train Epoch Loss (Avg): 0.4030297100543976\n",
            "Validation Epoch Accuracy:76.55006839563384\n",
            "save model /home/wh2500/models/basic_binary/epoch_2.pt\n",
            "Train Epoch Loss (Avg): 0.3952251672744751\n",
            "Validation Epoch Accuracy:76.84970641057852\n",
            "save model /home/wh2500/models/basic_binary/epoch_3.pt\n",
            "Train Epoch Loss (Avg): 0.38812756538391113\n",
            "Validation Epoch Accuracy:76.84784530489564\n",
            "Train Epoch Loss (Avg): 0.38417261838912964\n",
            "Validation Epoch Accuracy:77.12049728743847\n",
            "save model /home/wh2500/models/basic_binary/epoch_5.pt\n",
            "Train Epoch Loss (Avg): 0.38003629446029663\n",
            "Validation Epoch Accuracy:76.94090058903996\n",
            "Train Epoch Loss (Avg): 0.3757695257663727\n",
            "Validation Epoch Accuracy:77.4601490745652\n",
            "save model /home/wh2500/models/basic_binary/epoch_7.pt\n",
            "Train Epoch Loss (Avg): 0.3724781274795532\n",
            "Validation Epoch Accuracy:77.54017661892931\n",
            "save model /home/wh2500/models/basic_binary/epoch_8.pt\n",
            "Train Epoch Loss (Avg): 0.36996957659721375\n",
            "Validation Epoch Accuracy:77.4257186194318\n",
            "Train Epoch Loss (Avg): 0.3670445382595062\n",
            "Validation Epoch Accuracy:77.85005071512985\n",
            "save model /home/wh2500/models/basic_binary/epoch_10.pt\n",
            "Train Epoch Loss (Avg): 0.3651740849018097\n",
            "Validation Epoch Accuracy:77.79142588611894\n",
            "Train Epoch Loss (Avg): 0.3630589246749878\n",
            "Validation Epoch Accuracy:77.89006448731192\n",
            "save model /home/wh2500/models/basic_binary/epoch_12.pt\n",
            "Train Epoch Loss (Avg): 0.360066682100296\n",
            "Validation Epoch Accuracy:78.03523073057704\n",
            "save model /home/wh2500/models/basic_binary/epoch_13.pt\n",
            "Train Epoch Loss (Avg): 0.35927891731262207\n",
            "Validation Epoch Accuracy:77.90309222709212\n",
            "Train Epoch Loss (Avg): 0.35611221194267273\n",
            "Validation Epoch Accuracy:77.88913393447046\n",
            "Train Epoch Loss (Avg): 0.35438114404678345\n",
            "Validation Epoch Accuracy:77.93007825949397\n",
            "Train Epoch Loss (Avg): 0.3537136912345886\n",
            "Validation Epoch Accuracy:78.06593897434466\n",
            "save model /home/wh2500/models/basic_binary/epoch_17.pt\n",
            "Train Epoch Loss (Avg): 0.3505122661590576\n",
            "Validation Epoch Accuracy:78.13852209597722\n",
            "save model /home/wh2500/models/basic_binary/epoch_18.pt\n",
            "Train Epoch Loss (Avg): 0.349265992641449\n",
            "Validation Epoch Accuracy:77.9524115276886\n",
            "Train Epoch Loss (Avg): 0.346868097782135\n",
            "Validation Epoch Accuracy:77.77560648781441\n",
            "Train Epoch Loss (Avg): 0.34579429030418396\n",
            "Validation Epoch Accuracy:77.66114848831691\n",
            "Train Epoch Loss (Avg): 0.34398940205574036\n",
            "Validation Epoch Accuracy:77.98032811293189\n",
            "Train Epoch Loss (Avg): 0.3421388566493988\n",
            "Validation Epoch Accuracy:78.28834110344955\n",
            "save model /home/wh2500/models/basic_binary/epoch_23.pt\n",
            "Train Epoch Loss (Avg): 0.34144261479377747\n",
            "Validation Epoch Accuracy:78.27438281082792\n",
            "Train Epoch Loss (Avg): 0.3404841125011444\n",
            "Validation Epoch Accuracy:78.08827224253929\n",
            "Train Epoch Loss (Avg): 0.3395688533782959\n",
            "Validation Epoch Accuracy:78.46793780184808\n",
            "save model /home/wh2500/models/basic_binary/epoch_26.pt\n",
            "Train Epoch Loss (Avg): 0.3376429080963135\n",
            "Validation Epoch Accuracy:78.17295255111061\n",
            "Train Epoch Loss (Avg): 0.33628883957862854\n",
            "Validation Epoch Accuracy:77.67882899230433\n",
            "Train Epoch Loss (Avg): 0.3366226553916931\n",
            "Validation Epoch Accuracy:77.89006448731192\n",
            "Train Epoch Loss (Avg): 0.33425575494766235\n",
            "Validation Epoch Accuracy:77.62113471613486\n",
            "Train Epoch Loss (Avg): 0.33451032638549805\n",
            "Validation Epoch Accuracy:78.21389687613411\n",
            "Train Epoch Loss (Avg): 0.33309105038642883\n",
            "Validation Epoch Accuracy:77.8100369429478\n",
            "Train Epoch Loss (Avg): 0.3334365785121918\n",
            "Validation Epoch Accuracy:77.96264760894448\n",
            "Train Epoch Loss (Avg): 0.33263257145881653\n",
            "Validation Epoch Accuracy:77.89006448731192\n",
            "Train Epoch Loss (Avg): 0.33148518204689026\n",
            "Validation Epoch Accuracy:77.8509812679713\n",
            "Train Epoch Loss (Avg): 0.33000069856643677\n",
            "Validation Epoch Accuracy:78.46049337911653\n",
            "Train Epoch Loss (Avg): 0.3289591073989868\n",
            "Validation Epoch Accuracy:77.93659212938407\n",
            "Train Epoch Loss (Avg): 0.330626517534256\n",
            "Validation Epoch Accuracy:78.14968873007454\n",
            "Train Epoch Loss (Avg): 0.32964760065078735\n",
            "Validation Epoch Accuracy:78.12642490903846\n",
            "Train Epoch Loss (Avg): 0.3285295069217682\n",
            "Validation Epoch Accuracy:77.61834305761053\n",
            "Train Epoch Loss (Avg): 0.32745084166526794\n",
            "Validation Epoch Accuracy:77.39594092850562\n",
            "Train Epoch Loss (Avg): 0.3257291913032532\n",
            "Validation Epoch Accuracy:77.15492774257186\n",
            "Train Epoch Loss (Avg): 0.32565322518348694\n",
            "Validation Epoch Accuracy:77.60624587067177\n",
            "Train Epoch Loss (Avg): 0.32600581645965576\n",
            "Validation Epoch Accuracy:77.9244949424453\n",
            "Train Epoch Loss (Avg): 0.325137197971344\n",
            "Validation Epoch Accuracy:77.4796906842355\n",
            "Train Epoch Loss (Avg): 0.32439547777175903\n",
            "Validation Epoch Accuracy:77.80073141453337\n",
            "Train Epoch Loss (Avg): 0.3231133818626404\n",
            "Validation Epoch Accuracy:78.23250793296297\n",
            "Train Epoch Loss (Avg): 0.32333508133888245\n",
            "Validation Epoch Accuracy:77.73931492699813\n",
            "Train Epoch Loss (Avg): 0.32194212079048157\n",
            "Validation Epoch Accuracy:77.90867554414078\n",
            "Finish training!\n",
            "Accuracy: 78.18327287274182%\n"
          ]
        }
      ],
      "source": [
        "classifier4.train(epochs=50)\n",
        "classifier4.evaluate() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V6qAMtlqRnI7"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'basic_binary'  #Provide name to model experiment\n",
        "model_name = 'basic_binary' \n",
        "\n",
        "dataloaders = {'train': encode_train_dataloader, 'val' : encode_val_dataloader, 'test': encode_train_dataloader, 'mapping': target_set}\n",
        "model = BinaryConvBasicNet()\n",
        "classifier4 = Classifier(experiment_name, model, dataloaders, target_set, use_cuda=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CV1QWhd_RnI7",
        "outputId": "51f48c36-331e-4554-cab9-b2bed9a4622e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch Loss (Avg): 0.3373083174228668\n",
            "Validation Epoch Accuracy:77.83888408103255\n",
            "save model /home/wh2500/models/basic_binary/epoch_0.pt\n",
            "Train Epoch Loss (Avg): 0.3365228772163391\n",
            "Validation Epoch Accuracy:78.05570289308878\n",
            "save model /home/wh2500/models/basic_binary/epoch_1.pt\n",
            "Train Epoch Loss (Avg): 0.3363921642303467\n",
            "Validation Epoch Accuracy:77.91984217823808\n",
            "Train Epoch Loss (Avg): 0.3344653248786926\n",
            "Validation Epoch Accuracy:78.00917525101663\n",
            "Train Epoch Loss (Avg): 0.33275577425956726\n",
            "Validation Epoch Accuracy:78.05756399877167\n",
            "save model /home/wh2500/models/basic_binary/epoch_4.pt\n",
            "Train Epoch Loss (Avg): 0.33314377069473267\n",
            "Validation Epoch Accuracy:77.86214790206861\n",
            "Train Epoch Loss (Avg): 0.3316868841648102\n",
            "Validation Epoch Accuracy:78.27903557503512\n",
            "save model /home/wh2500/models/basic_binary/epoch_6.pt\n",
            "Train Epoch Loss (Avg): 0.3318841755390167\n",
            "Validation Epoch Accuracy:77.71512055312061\n",
            "Train Epoch Loss (Avg): 0.33097517490386963\n",
            "Validation Epoch Accuracy:77.63695411443939\n",
            "Train Epoch Loss (Avg): 0.3303573727607727\n",
            "Validation Epoch Accuracy:78.19249416078092\n",
            "Train Epoch Loss (Avg): 0.3290344774723053\n",
            "Validation Epoch Accuracy:78.02592520216261\n",
            "Train Epoch Loss (Avg): 0.32868629693984985\n",
            "Validation Epoch Accuracy:77.92356438960387\n",
            "Train Epoch Loss (Avg): 0.3284304738044739\n",
            "Validation Epoch Accuracy:77.8184119185208\n",
            "Train Epoch Loss (Avg): 0.3278995752334595\n",
            "Validation Epoch Accuracy:77.13724723858444\n",
            "Train Epoch Loss (Avg): 0.3266667425632477\n",
            "Validation Epoch Accuracy:77.86959232480017\n",
            "Train Epoch Loss (Avg): 0.3265845775604248\n",
            "Validation Epoch Accuracy:77.88727282878759\n",
            "Train Epoch Loss (Avg): 0.32481154799461365\n",
            "Validation Epoch Accuracy:78.13386933177\n",
            "Train Epoch Loss (Avg): 0.32473233342170715\n",
            "Validation Epoch Accuracy:77.79887030885048\n",
            "Train Epoch Loss (Avg): 0.3251633644104004\n",
            "Validation Epoch Accuracy:77.80724528442347\n",
            "Train Epoch Loss (Avg): 0.32272279262542725\n",
            "Validation Epoch Accuracy:78.01661967374817\n",
            "Train Epoch Loss (Avg): 0.3243705928325653\n",
            "Validation Epoch Accuracy:78.1208415919898\n",
            "Train Epoch Loss (Avg): 0.3222898244857788\n",
            "Validation Epoch Accuracy:78.22041074602421\n",
            "Train Epoch Loss (Avg): 0.3214927017688751\n",
            "Validation Epoch Accuracy:78.25763285968193\n",
            "Train Epoch Loss (Avg): 0.32095885276794434\n",
            "Validation Epoch Accuracy:77.4927184240157\n",
            "Train Epoch Loss (Avg): 0.3208617866039276\n",
            "Validation Epoch Accuracy:77.67138456957278\n",
            "Train Epoch Loss (Avg): 0.32029297947883606\n",
            "Validation Epoch Accuracy:77.32894112392172\n",
            "Train Epoch Loss (Avg): 0.319902241230011\n",
            "Validation Epoch Accuracy:77.44991299330933\n",
            "Train Epoch Loss (Avg): 0.31986841559410095\n",
            "Validation Epoch Accuracy:77.53645440756354\n",
            "Train Epoch Loss (Avg): 0.3181752860546112\n",
            "Validation Epoch Accuracy:76.98556712542921\n",
            "Train Epoch Loss (Avg): 0.31733277440071106\n",
            "Validation Epoch Accuracy:78.19807747782959\n",
            "Train Epoch Loss (Avg): 0.31836462020874023\n",
            "Validation Epoch Accuracy:78.09385555958795\n",
            "Train Epoch Loss (Avg): 0.3173879384994507\n",
            "Validation Epoch Accuracy:77.96636982031025\n",
            "Train Epoch Loss (Avg): 0.31648820638656616\n",
            "Validation Epoch Accuracy:78.09013334822218\n",
            "Train Epoch Loss (Avg): 0.31552842259407043\n",
            "Validation Epoch Accuracy:77.4796906842355\n",
            "Train Epoch Loss (Avg): 0.3154178261756897\n",
            "Validation Epoch Accuracy:77.83050910545956\n",
            "Train Epoch Loss (Avg): 0.31422755122184753\n",
            "Validation Epoch Accuracy:77.22006644147288\n",
            "Train Epoch Loss (Avg): 0.31480497121810913\n",
            "Validation Epoch Accuracy:78.15806370564752\n",
            "Train Epoch Loss (Avg): 0.3135390877723694\n",
            "Validation Epoch Accuracy:78.02685575500405\n",
            "Train Epoch Loss (Avg): 0.3133932054042816\n",
            "Validation Epoch Accuracy:77.22564975852154\n",
            "Train Epoch Loss (Avg): 0.3133539855480194\n",
            "Validation Epoch Accuracy:77.81934247136223\n",
            "Train Epoch Loss (Avg): 0.3125164806842804\n",
            "Validation Epoch Accuracy:77.88913393447046\n",
            "Train Epoch Loss (Avg): 0.31254151463508606\n",
            "Validation Epoch Accuracy:78.00359193396797\n",
            "Train Epoch Loss (Avg): 0.31019166111946106\n",
            "Validation Epoch Accuracy:77.98498087713911\n",
            "Train Epoch Loss (Avg): 0.310793399810791\n",
            "Validation Epoch Accuracy:77.69092617924309\n",
            "Train Epoch Loss (Avg): 0.30975738167762756\n",
            "Validation Epoch Accuracy:78.15248038859886\n",
            "Train Epoch Loss (Avg): 0.3108364939689636\n",
            "Validation Epoch Accuracy:77.64346798432949\n",
            "Train Epoch Loss (Avg): 0.30954742431640625\n",
            "Validation Epoch Accuracy:77.81748136567936\n",
            "Train Epoch Loss (Avg): 0.3095134198665619\n",
            "Validation Epoch Accuracy:77.64719019569526\n",
            "Train Epoch Loss (Avg): 0.3069833219051361\n",
            "Validation Epoch Accuracy:77.97195313735891\n",
            "Train Epoch Loss (Avg): 0.3090139925479889\n",
            "Validation Epoch Accuracy:78.03336962489415\n",
            "Finish training!\n",
            "Accuracy: 78.44496570869208%\n"
          ]
        }
      ],
      "source": [
        "classifier4.train(epochs=50)\n",
        "classifier4.evaluate() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP-SavftRnI7",
        "outputId": "f3a88a14-fb7a-4a1a-d925-ff7cc9140b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[77.83888408103255, 78.05570289308878, 77.91984217823808, 78.00917525101663, 78.05756399877167, 77.86214790206861, 78.27903557503512, 77.71512055312061, 77.63695411443939, 78.19249416078092, 78.02592520216261, 77.92356438960387, 77.8184119185208, 77.13724723858444, 77.86959232480017, 77.88727282878759, 78.13386933177, 77.79887030885048, 77.80724528442347, 78.01661967374817, 78.1208415919898, 78.22041074602421, 78.25763285968193, 77.4927184240157, 77.67138456957278, 77.32894112392172, 77.44991299330933, 77.53645440756354, 76.98556712542921, 78.19807747782959, 78.09385555958795, 77.96636982031025, 78.09013334822218, 77.4796906842355, 77.83050910545956, 77.22006644147288, 78.15806370564752, 78.02685575500405, 77.22564975852154, 77.81934247136223, 77.88913393447046, 78.00359193396797, 77.98498087713911, 77.69092617924309, 78.15248038859886, 77.64346798432949, 77.81748136567936, 77.64719019569526, 77.97195313735891, 78.03336962489415]\n"
          ]
        }
      ],
      "source": [
        "binary_cnn_val_accs = classifier4.epoch_accuracies \n",
        "print(binary_cnn_val_accs) "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bed Peaks"
      ],
      "metadata": {
        "id": "jVeo_yvjSnII"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVTKryFURnI7"
      },
      "outputs": [],
      "source": [
        "class OrBinaryBedPeaksDataset(torch.utils.data.IterableDataset):\n",
        "\n",
        "    def __init__(self, eclip_data, genome, context_length):\n",
        "        super(OrBinaryBedPeaksDataset, self).__init__()\n",
        "        self.context_length = context_length\n",
        "        self.eclip_data = eclip_data\n",
        "        self.genome = genome\n",
        "\n",
        "    def __iter__(self): \n",
        "        prev_end = 0\n",
        "        prev_chr = \"\"\n",
        "        for i,row in enumerate(self.eclip_data.itertuples()):\n",
        "            midpoint = int(.5 * (row.start + row.end))\n",
        "            seq = self.genome[row.chr][ midpoint - self.context_length//2:midpoint + self.context_length//2]\n",
        "            yield(one_hot(seq), np.float32(1)) # positive example\n",
        "\n",
        "            if prev_chr == row.chr and prev_end < row.start: \n",
        "                midpoint = int(.5 * (prev_end + row.start))\n",
        "                seq = self.genome[row.chr][ midpoint - self.context_length//2:midpoint + self.context_length//2]\n",
        "                yield(one_hot(seq), np.float32(0)) # negative example midway inbetween peaks, could randomize\n",
        "            \n",
        "            prev_chr = row.chr\n",
        "            prev_end = row.end \n",
        "    \n",
        "    def __len__(self):\n",
        "        return self.eclip_data.shape[0]\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg1Rpug8RnI7"
      },
      "outputs": [],
      "source": [
        "context_length = 100\n",
        "\n",
        "encode_train_dataset = OrBinaryBedPeaksDataset(encode_train, genome, context_length)\n",
        "encode_train_dataloader = torch.utils.data.DataLoader(encode_train_dataset, batch_size=128, num_workers = 0) \n",
        "\n",
        "encode_val_dataset = OrBinaryBedPeaksDataset(encode_val, genome, context_length)\n",
        "encode_val_dataloader = torch.utils.data.DataLoader(encode_val_dataset, batch_size=128)\n",
        "\n",
        "encode_test_dataset = OrBinaryBedPeaksDataset(encode_test, genome, context_length)\n",
        "encodetest_dataloader = torch.utils.data.DataLoader(encode_test_dataset, batch_size=128)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlnQtdKFRnI7"
      },
      "outputs": [],
      "source": [
        "experiment_name = 'basic_binary_woneg'  #Provide name to model experiment\n",
        "model_name = 'basic_binary_woneg' \n",
        "\n",
        "dataloaders = {'train': encode_train_dataloader, 'val' : encode_val_dataloader, 'test': encode_train_dataloader, 'mapping': target_set}\n",
        "model = BinaryConvBasicNet()\n",
        "classifier5 = Classifier(experiment_name, model, dataloaders, target_set, use_cuda=True) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFQ0QJSyRnI7",
        "outputId": "2f436242-b4b0-4745-858a-2ac076a93329"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch Loss (Avg): 0.7492435574531555\n",
            "Validation Epoch Accuracy:73.76994680851064\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_0.pt\n",
            "Train Epoch Loss (Avg): 0.7238492369651794\n",
            "Validation Epoch Accuracy:74.35726950354609\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_1.pt\n",
            "Train Epoch Loss (Avg): 0.7136561274528503\n",
            "Validation Epoch Accuracy:74.7177461410096\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_2.pt\n",
            "Train Epoch Loss (Avg): 0.707180380821228\n",
            "Validation Epoch Accuracy:74.9165623696287\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_3.pt\n",
            "Train Epoch Loss (Avg): 0.7030606269836426\n",
            "Validation Epoch Accuracy:75.04693366708385\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_4.pt\n",
            "Train Epoch Loss (Avg): 0.7001104950904846\n",
            "Validation Epoch Accuracy:75.11081560283688\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_5.pt\n",
            "Train Epoch Loss (Avg): 0.6976220011711121\n",
            "Validation Epoch Accuracy:75.15383813099707\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_6.pt\n",
            "Train Epoch Loss (Avg): 0.6954572796821594\n",
            "Validation Epoch Accuracy:75.20403108051731\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_7.pt\n",
            "Train Epoch Loss (Avg): 0.693445086479187\n",
            "Validation Epoch Accuracy:75.21837192323738\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_8.pt\n",
            "Train Epoch Loss (Avg): 0.6915497183799744\n",
            "Validation Epoch Accuracy:75.22749791405924\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_9.pt\n",
            "Train Epoch Loss (Avg): 0.6897826194763184\n",
            "Validation Epoch Accuracy:75.26726115978306\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_10.pt\n",
            "Train Epoch Loss (Avg): 0.6880476474761963\n",
            "Validation Epoch Accuracy:75.31615039632874\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_11.pt\n",
            "Train Epoch Loss (Avg): 0.686437726020813\n",
            "Validation Epoch Accuracy:75.32332081768878\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_12.pt\n",
            "Train Epoch Loss (Avg): 0.6848400831222534\n",
            "Validation Epoch Accuracy:75.34287651230704\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_13.pt\n",
            "Train Epoch Loss (Avg): 0.6832488775253296\n",
            "Validation Epoch Accuracy:75.34092094284523\n",
            "Train Epoch Loss (Avg): 0.6816840767860413\n",
            "Validation Epoch Accuracy:75.34613579474343\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_15.pt\n",
            "Train Epoch Loss (Avg): 0.6801275610923767\n",
            "Validation Epoch Accuracy:75.3467876512307\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_16.pt\n",
            "Train Epoch Loss (Avg): 0.6785844564437866\n",
            "Validation Epoch Accuracy:75.35265435961618\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_17.pt\n",
            "Train Epoch Loss (Avg): 0.6770417094230652\n",
            "Validation Epoch Accuracy:75.39698060075094\n",
            "save model /home/wh2500/models/basic_binary_woneg/epoch_18.pt\n",
            "Train Epoch Loss (Avg): 0.6754263639450073\n",
            "Validation Epoch Accuracy:75.37155819774718\n",
            "Train Epoch Loss (Avg): 0.6738390922546387\n",
            "Validation Epoch Accuracy:75.36503963287443\n",
            "Train Epoch Loss (Avg): 0.6721845269203186\n",
            "Validation Epoch Accuracy:75.33831351689612\n",
            "Train Epoch Loss (Avg): 0.6704872846603394\n",
            "Validation Epoch Accuracy:75.31354297037964\n",
            "Train Epoch Loss (Avg): 0.6687585711479187\n",
            "Validation Epoch Accuracy:75.252920317063\n",
            "Train Epoch Loss (Avg): 0.6669692993164062\n",
            "Validation Epoch Accuracy:75.1936013767209\n",
            "Train Epoch Loss (Avg): 0.6651009321212769\n",
            "Validation Epoch Accuracy:75.10234146850229\n",
            "Train Epoch Loss (Avg): 0.6631690859794617\n",
            "Validation Epoch Accuracy:75.03324468085107\n",
            "Train Epoch Loss (Avg): 0.6611450910568237\n",
            "Validation Epoch Accuracy:74.97979244889446\n",
            "Train Epoch Loss (Avg): 0.6590291857719421\n",
            "Validation Epoch Accuracy:74.88657697121401\n",
            "Train Epoch Loss (Avg): 0.6568183898925781\n",
            "Validation Epoch Accuracy:74.75555381727159\n",
            "Train Epoch Loss (Avg): 0.6544967293739319\n",
            "Validation Epoch Accuracy:74.63235294117646\n",
            "Train Epoch Loss (Avg): 0.6520317792892456\n",
            "Validation Epoch Accuracy:74.43614413850646\n",
            "Train Epoch Loss (Avg): 0.6494891047477722\n",
            "Validation Epoch Accuracy:74.30446912807676\n",
            "Train Epoch Loss (Avg): 0.6467702388763428\n",
            "Validation Epoch Accuracy:74.11673445974134\n",
            "Train Epoch Loss (Avg): 0.6439487934112549\n",
            "Validation Epoch Accuracy:73.90162181894034\n",
            "Train Epoch Loss (Avg): 0.6409592628479004\n",
            "Validation Epoch Accuracy:73.56135273258239\n",
            "Train Epoch Loss (Avg): 0.637876033782959\n",
            "Validation Epoch Accuracy:73.29148414685022\n",
            "Train Epoch Loss (Avg): 0.6346032619476318\n",
            "Validation Epoch Accuracy:72.95838548185232\n",
            "Train Epoch Loss (Avg): 0.6311343908309937\n",
            "Validation Epoch Accuracy:72.62202753441802\n",
            "Train Epoch Loss (Avg): 0.6275182366371155\n",
            "Validation Epoch Accuracy:72.19115039632874\n",
            "Train Epoch Loss (Avg): 0.6237579584121704\n",
            "Validation Epoch Accuracy:71.7674436795995\n",
            "Train Epoch Loss (Avg): 0.6198274493217468\n",
            "Validation Epoch Accuracy:71.34308510638297\n",
            "Train Epoch Loss (Avg): 0.6156864166259766\n",
            "Validation Epoch Accuracy:70.8665780141844\n",
            "Train Epoch Loss (Avg): 0.6113579869270325\n",
            "Validation Epoch Accuracy:70.24340321234877\n",
            "Train Epoch Loss (Avg): 0.6068934202194214\n",
            "Validation Epoch Accuracy:69.74212557363371\n",
            "Train Epoch Loss (Avg): 0.6022178530693054\n",
            "Validation Epoch Accuracy:69.2095588235294\n",
            "Train Epoch Loss (Avg): 0.5973945260047913\n",
            "Validation Epoch Accuracy:68.534887359199\n",
            "Train Epoch Loss (Avg): 0.5923619866371155\n",
            "Validation Epoch Accuracy:67.92996453900709\n",
            "Train Epoch Loss (Avg): 0.5871251821517944\n",
            "Validation Epoch Accuracy:67.4482425949103\n",
            "Train Epoch Loss (Avg): 0.5817656517028809\n",
            "Validation Epoch Accuracy:66.71229662077597\n",
            "Finish training!\n",
            "Accuracy: 76.76385515170041%\n"
          ]
        }
      ],
      "source": [
        "classifier5.train(epochs=50)\n",
        "classifier5.evaluate() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "krkViWltRnI7",
        "outputId": "cc04c361-f7f6-4455-8df0-db656a9525a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[73.76994680851064, 74.35726950354609, 74.7177461410096, 74.9165623696287, 75.04693366708385, 75.11081560283688, 75.15383813099707, 75.20403108051731, 75.21837192323738, 75.22749791405924, 75.26726115978306, 75.31615039632874, 75.32332081768878, 75.34287651230704, 75.34092094284523, 75.34613579474343, 75.3467876512307, 75.35265435961618, 75.39698060075094, 75.37155819774718, 75.36503963287443, 75.33831351689612, 75.31354297037964, 75.252920317063, 75.1936013767209, 75.10234146850229, 75.03324468085107, 74.97979244889446, 74.88657697121401, 74.75555381727159, 74.63235294117646, 74.43614413850646, 74.30446912807676, 74.11673445974134, 73.90162181894034, 73.56135273258239, 73.29148414685022, 72.95838548185232, 72.62202753441802, 72.19115039632874, 71.7674436795995, 71.34308510638297, 70.8665780141844, 70.24340321234877, 69.74212557363371, 69.2095588235294, 68.534887359199, 67.92996453900709, 67.4482425949103, 66.71229662077597]\n"
          ]
        }
      ],
      "source": [
        "binary_bedpeaks_val_accs = classifier5.epoch_accuracies \n",
        "print(binary_bedpeaks_val_accs) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7Ewc-F8RnI7"
      },
      "outputs": [],
      "source": [
        "binary_cnn_val_accs = [77.83888408103255, 78.05570289308878, 77.91984217823808, 78.00917525101663, 78.05756399877167, 77.86214790206861, 78.27903557503512, 77.71512055312061, 77.63695411443939, 78.19249416078092, 78.02592520216261, 77.92356438960387, 77.8184119185208, 77.13724723858444, 77.86959232480017, 77.88727282878759, 78.13386933177, 77.79887030885048, 77.80724528442347, 78.01661967374817, 78.1208415919898, 78.22041074602421, 78.25763285968193, 77.4927184240157, 77.67138456957278, 77.32894112392172, 77.44991299330933, 77.53645440756354, 76.98556712542921, 78.19807747782959, 78.09385555958795, 77.96636982031025, 78.09013334822218, 77.4796906842355, 77.83050910545956, 77.22006644147288, 78.15806370564752, 78.02685575500405, 77.22564975852154, 77.81934247136223, 77.88913393447046, 78.00359193396797, 77.98498087713911, 77.69092617924309, 78.15248038859886, 77.64346798432949, 77.81748136567936, 77.64719019569526, 77.97195313735891, 78.03336962489415]\n",
        "binary_bedpeaks_val_accs = [73.76994680851064, 74.35726950354609, 74.7177461410096, 74.9165623696287, 75.04693366708385, 75.11081560283688, 75.15383813099707, 75.20403108051731, 75.21837192323738, 75.22749791405924, 75.26726115978306, 75.31615039632874, 75.32332081768878, 75.34287651230704, 75.34092094284523, 75.34613579474343, 75.3467876512307, 75.35265435961618, 75.39698060075094, 75.37155819774718, 75.36503963287443, 75.33831351689612, 75.31354297037964, 75.252920317063, 75.1936013767209, 75.10234146850229, 75.03324468085107, 74.97979244889446, 74.88657697121401, 74.75555381727159, 74.63235294117646, 74.43614413850646, 74.30446912807676, 74.11673445974134, 73.90162181894034, 73.56135273258239, 73.29148414685022, 72.95838548185232, 72.62202753441802, 72.19115039632874, 71.7674436795995, 71.34308510638297, 70.8665780141844, 70.24340321234877, 69.74212557363371, 69.2095588235294, 68.534887359199, 67.92996453900709, 67.4482425949103, 66.71229662077597]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b_y0gI07RnI7",
        "outputId": "14f60f70-7060-470e-e6dc-aa455d6c5dff"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(binary_cnn_val_accs, label='Negative Sampling', color='orange')\n",
        "plt.plot(binary_bedpeaks_val_accs, label=\"Bed Peaks\", color='green')\n",
        "plt.plot()\n",
        "plt.legend() \n",
        "\n",
        "plt.title('Validation Accuracies of CNN models using Variations of Sampling')\n",
        "plt.xlabel('Number of Epochs')\n",
        "plt.ylabel('Val Accs') \n",
        "\n",
        "plt.savefig('binary_val_accs_CNN.png', dpi=300) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZLk8A2IjRnI7"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Project_RBP_CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}